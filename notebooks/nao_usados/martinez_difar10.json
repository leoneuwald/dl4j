{"paragraphs":[{"text":"%spark.dep\nz.reset()\nz.load(\"org.nd4j:nd4j-native-platform:0.9.1\")\nz.load(\"org.deeplearning4j:deeplearning4j-core:0.9.1\")\nz.load(\"org.datavec:datavec-spark_2.11:0.9.1_spark_2\")\nz.load(\"org.deeplearning4j:dl4j-spark_2.11:0.9.1_spark_2\")\nz.load(\"org.deeplearning4j:deeplearning4j-zoo:0.9.1\")","dateUpdated":"2019-09-01T16:26:31+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@24583248\n"}]},"apps":[],"jobName":"paragraph_1567353809536_-1369611479","id":"20190813-010616_2021083357","dateCreated":"2019-09-01T16:03:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1231","user":"anonymous","dateFinished":"2019-09-01T16:26:41+0000","dateStarted":"2019-09-01T16:26:31+0000"},{"text":"import scala.collection.JavaConversions._\n\nimport org.deeplearning4j.datasets.iterator._\nimport org.deeplearning4j.datasets.iterator.impl._\nimport org.deeplearning4j.nn.api._\nimport org.deeplearning4j.nn.multilayer._\nimport org.deeplearning4j.nn.graph._\nimport org.deeplearning4j.nn.conf._\nimport org.deeplearning4j.nn.conf.inputs._\nimport org.deeplearning4j.nn.conf.layers._\nimport org.deeplearning4j.nn.weights._\nimport org.deeplearning4j.spark.api.TrainingMaster\nimport org.deeplearning4j.spark.impl.multilayer.SparkDl4jMultiLayer\nimport org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster\nimport org.deeplearning4j.optimize.listeners._\nimport org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.zoo.model.VGG16\n\nimport org.nd4j.linalg.learning.config._ // for different updaters like Adam, Nesterovs, etc.\nimport org.nd4j.linalg.activations.Activation // defines different activation functions like RELU, SOFTMAX, etc.\nimport org.nd4j.linalg.lossfunctions.LossFunctions // mean squared error, multiclass cross entropy, etc.\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.api.java.JavaRDD\nimport org.apache.spark.api.java.JavaSparkContext\nimport org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.conf.MultiLayerConfiguration\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration\nimport org.deeplearning4j.nn.conf.Updater\nimport org.deeplearning4j.nn.conf.layers.DenseLayer\nimport org.deeplearning4j.nn.conf.layers.OutputLayer\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.deeplearning4j.spark.api.TrainingMaster\nimport org.deeplearning4j.spark.impl.multilayer.SparkDl4jMultiLayer\nimport org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.dataset.DataSet\nimport org.nd4j.linalg.dataset.api.iterator.DataSetIterator\nimport org.nd4j.linalg.lossfunctions.LossFunctions\nimport org.datavec.image.loader.CifarLoader\nimport org.deeplearning4j.datasets.iterator.impl.CifarDataSetIterator\n\nimport java.io.File\n\nimport org.apache.commons.io.FilenameUtils\nimport org.datavec.image.loader.CifarLoader\nimport org.deeplearning4j.datasets.iterator.impl.CifarDataSetIterator\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.conf._\nimport org.deeplearning4j.nn.conf.inputs.InputType\nimport org.deeplearning4j.nn.conf.layers._\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.deeplearning4j.optimize.listeners.ScoreIterationListener\nimport org.deeplearning4j.util.ModelSerializer\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.api.buffer.DataBuffer\nimport org.nd4j.linalg.api.buffer.util.DataTypeUtil\nimport org.nd4j.linalg.lossfunctions.LossFunctions","dateUpdated":"2019-09-01T16:26:31+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import scala.collection.JavaConversions._\nimport org.deeplearning4j.datasets.iterator._\nimport org.deeplearning4j.datasets.iterator.impl._\nimport org.deeplearning4j.nn.api._\nimport org.deeplearning4j.nn.multilayer._\nimport org.deeplearning4j.nn.graph._\nimport org.deeplearning4j.nn.conf._\nimport org.deeplearning4j.nn.conf.inputs._\nimport org.deeplearning4j.nn.conf.layers._\nimport org.deeplearning4j.nn.weights._\nimport org.deeplearning4j.spark.api.TrainingMaster\nimport org.deeplearning4j.spark.impl.multilayer.SparkDl4jMultiLayer\nimport org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster\nimport org.deeplearning4j.optimize.listeners._\nimport org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.zoo.model.VGG16\nimport org.nd4j.linalg.learning.config._\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.lossfunctions.LossFunctions\nimport org.apache.spark.SparkConf\nimport org.apache.spark.api.java.JavaRDD\nimport org.apache.spark.api.java.JavaSparkContext\nimport org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.conf.MultiLayerConfiguration\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration\nimport org.deeplearning4j.nn.conf.Updater\nimport org.deeplearning4j.nn.conf.layers.DenseLayer\nimport org.deeplearning4j.nn.conf.layers.OutputLayer\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.deeplearning4j.spark.api.TrainingMaster\nimport org.deeplearning4j.spark.impl.multilayer.SparkDl4jMultiLayer\nimport org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.dataset.DataSet\nimport org.nd4j.linalg.dataset.api.iterator.DataSetIterator\nimport org.nd4j.linalg.lossfunctions.LossFunctions\nimport org.datavec.image.loader.CifarLoader\nimport org.deeplearning4j.datasets.iterator.impl.CifarDataSetIterator\nimport java.io.File\nimport org.apache.commons.io.FilenameUtils\nimport org.datavec.image.loader.CifarLoader\nimport org.deeplearning4j.datasets.iterator.impl.CifarDataSetIterator\nimport org.deeplearning4j.eval.Evaluation\nimport org.deeplearning4j.nn.api.OptimizationAlgorithm\nimport org.deeplearning4j.nn.conf._\nimport org.deeplearning4j.nn.conf.inputs.InputType\nimport org.deeplearning4j.nn.conf.layers._\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork\nimport org.deeplearning4j.nn.weights.WeightInit\nimport org.deeplearning4j.optimize.listeners.ScoreIterationListener\nimport org.deeplearning4j.util.ModelSerializer\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.api.buffer.DataBuffer\nimport org.nd4j.linalg.api.buffer.util.DataTypeUtil\nimport org.nd4j.linalg.lossfunctions.LossFunctions\n"}]},"apps":[],"jobName":"paragraph_1567353809537_-1369996228","id":"20190813-010626_1430679682","dateCreated":"2019-09-01T16:03:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1232","user":"anonymous","dateFinished":"2019-09-01T16:27:54+0000","dateStarted":"2019-09-01T16:26:33+0000"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1567353977856_-872269069","id":"20190901-160617_1025838460","dateCreated":"2019-09-01T16:06:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2047","text":"val height = 32\nval width = 32\nval channels = 3\n\nval batchSize = 32\nval iterations = 1\nval printStatisticsFrequency = 50\nval randomSeed = 42\nval preProcessCifar = false\nval numberOfEpochs = 15\nval learningRate = 0.001\nval dropOut = 0.2\n\nval biasLearningRate = 2 * learningRate","dateUpdated":"2019-09-01T16:26:42+0000","dateFinished":"2019-09-01T16:27:58+0000","dateStarted":"2019-09-01T16:26:42+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"height: Int = 32\nwidth: Int = 32\nchannels: Int = 3\nbatchSize: Int = 32\niterations: Int = 1\nprintStatisticsFrequency: Int = 50\nrandomSeed: Int = 42\npreProcessCifar: Boolean = false\nnumberOfEpochs: Int = 15\nlearningRate: Double = 0.001\ndropOut: Double = 0.2\nbiasLearningRate: Double = 0.002\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1567354262603_-1299175071","id":"20190901-161102_1589299524","dateCreated":"2019-09-01T16:11:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2247","text":"val numberOfLabels = CifarLoader.NUM_LABELS\nval numberOfSamples = 10000\nval numberOfTestSamples = CifarLoader.NUM_TEST_IMAGES","dateUpdated":"2019-09-01T16:27:55+0000","dateFinished":"2019-09-01T16:27:59+0000","dateStarted":"2019-09-01T16:27:55+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"numberOfLabels: Int = 10\nnumberOfSamples: Int = 10000\nnumberOfTestSamples: Int = 10000\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1567353899447_1792978507","id":"20190901-160459_1639520468","dateCreated":"2019-09-01T16:04:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1991","text":"def getModel = {\n    val firstConvolutionLayer = new ConvolutionLayer\n      .Builder(Array(4, 4), Array(1, 1), Array(0, 0))\n      .name(\"cnn1\")\n      .convolutionMode(ConvolutionMode.Same)\n      .nIn(3)\n      .nOut(64)\n      .weightInit(WeightInit.XAVIER_UNIFORM)\n      .activation(Activation.RELU).learningRate(learningRate)\n      .biasInit(1e-2)\n      .biasLearningRate(biasLearningRate)\n      .build()\n\n    val secondConvolutionLayer = new ConvolutionLayer\n      .Builder(Array(4, 4), Array(1, 1), Array(0, 0))\n      .name(\"cnn2\")\n      .convolutionMode(ConvolutionMode.Same)\n      .nOut(64)\n      .weightInit(WeightInit.XAVIER_UNIFORM)\n      .activation(Activation.RELU)\n      .learningRate(learningRate)\n      .biasInit(1e-2)\n      .biasLearningRate(biasLearningRate)\n      .build()\n\n    val firstMaxPoolLayer = new SubsamplingLayer\n      .Builder(PoolingType.MAX, Array(2, 2))\n      .name(\"maxpool2\")\n      .build()\n\n    val thirdConvolutionLayer = new ConvolutionLayer\n      .Builder(Array(4, 4), Array(1, 1), Array(0, 0))\n      .name(\"cnn3\")\n      .convolutionMode(ConvolutionMode.Same)\n      .nOut(96)\n      .weightInit(WeightInit.XAVIER_UNIFORM)\n      .activation(Activation.RELU)\n      .learningRate(learningRate)\n      .biasInit(1e-2)\n      .biasLearningRate(biasLearningRate)\n      .build()\n\n    val fourthConvolutionLayer = new ConvolutionLayer.\n      Builder(Array(4, 4), Array(1, 1), Array(0, 0))\n      .name(\"cnn4\")\n      .convolutionMode(ConvolutionMode.Same)\n      .nOut(96)\n      .weightInit(WeightInit.XAVIER_UNIFORM)\n      .activation(Activation.RELU)\n      .learningRate(learningRate)\n      .biasInit(1e-2)\n      .biasLearningRate(biasLearningRate)\n      .build()\n\n    val fifthConvolutionLayer = new ConvolutionLayer\n      .Builder(Array(3, 3), Array(1, 1), Array(0, 0))\n      .name(\"cnn5\")\n      .convolutionMode(ConvolutionMode.Same)\n      .nOut(128)\n      .weightInit(WeightInit.XAVIER_UNIFORM)\n      .activation(Activation.RELU)\n      .learningRate(learningRate)\n      .biasInit(1e-2)\n      .biasLearningRate(biasLearningRate)\n      .build()\n\n    val sixthConvolutionLayer = new ConvolutionLayer\n      .Builder(Array(3, 3), Array(1, 1), Array(0, 0))\n      .name(\"cnn6\")\n      .convolutionMode(ConvolutionMode.Same)\n      .nOut(128)\n      .weightInit(WeightInit.XAVIER_UNIFORM)\n      .activation(Activation.RELU)\n      .learningRate(learningRate)\n      .biasInit(1e-2)\n      .biasLearningRate(biasLearningRate)\n      .build()\n\n    val seventhConvolutionLayer = new ConvolutionLayer\n      .Builder(Array(2, 2), Array(1, 1), Array(0, 0))\n      .name(\"cnn7\")\n      .convolutionMode(ConvolutionMode.Same)\n      .nOut(256)\n      .weightInit(WeightInit.XAVIER_UNIFORM)\n      .activation(Activation.RELU)\n      .learningRate(learningRate)\n      .biasInit(1e-2)\n      .biasLearningRate(biasLearningRate)\n      .build()\n\n    val eighthConvolutionLayer = new ConvolutionLayer\n      .Builder(Array(2, 2), Array(1, 1), Array(0, 0))\n      .name(\"cnn8\")\n      .convolutionMode(ConvolutionMode.Same)\n      .nOut(256)\n      .weightInit(WeightInit.XAVIER_UNIFORM)\n      .activation(Activation.RELU)\n      .learningRate(learningRate)\n      .biasInit(1e-2)\n      .biasLearningRate(biasLearningRate)\n      .build()\n\n    val secondMaxPoolLayer = new SubsamplingLayer\n      .Builder(PoolingType.MAX, Array(2, 2))\n      .name(\"maxpool18\")\n      .build()\n\n    val firstFullyConnectedLayer = new DenseLayer\n      .Builder()\n      .name(\"ffn1\")\n      .nOut(1024)\n      .learningRate(1e-3)\n      .biasInit(1e-3)\n      .biasLearningRate(1e-3 * 2)\n      .build()\n\n    val firstDropOutLayer = new DropoutLayer\n      .Builder()\n      .name(\"dropout1\")\n      .dropOut(dropOut)\n      .build()\n\n    val secondFullyConnectedLayer = new DenseLayer\n      .Builder()\n      .name(\"ffn2\")\n      .nOut(1024)\n      .learningRate(learningRate)\n      .biasInit(1e-2)\n      .biasLearningRate(biasLearningRate)\n      .build()\n\n    val secondDropOutLayer = new DropoutLayer\n      .Builder()\n      .name(\"dropout2\")\n      .dropOut(dropOut)\n      .build()\n\n    val outputLayer = new OutputLayer\n      .Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n      .name(\"output\")\n      .nOut(numberOfLabels)\n      .activation(Activation.SOFTMAX)\n      .build()\n\n    val layers = List(\n      firstConvolutionLayer,\n      secondConvolutionLayer,\n      firstMaxPoolLayer,\n      thirdConvolutionLayer,\n      fourthConvolutionLayer,\n      fifthConvolutionLayer,\n      sixthConvolutionLayer,\n      seventhConvolutionLayer,\n      eighthConvolutionLayer,\n      secondMaxPoolLayer,\n      firstFullyConnectedLayer,\n      firstDropOutLayer,\n      secondFullyConnectedLayer,\n      secondDropOutLayer,\n      outputLayer)\n\n    val configuration =\n      new NeuralNetConfiguration.Builder()\n        .seed(randomSeed)\n        .cacheMode(CacheMode.DEVICE)\n        .updater(Updater.ADAM)\n        .iterations(iterations)\n        .gradientNormalization(GradientNormalization.RenormalizeL2PerLayer)\n        .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n        .regularization(true)\n        .l1(1e-4)\n        .l2(5 * 1e-4)\n        .list(layers:_*)\n        .backprop(true)\n        .pretrain(false)\n        .setInputType(InputType.convolutional(height, width, channels))\n        .build()\n\n    val model = new MultiLayerNetwork(configuration)\n    model.init()\n\n    model\n  }","dateUpdated":"2019-09-01T16:27:59+0000","dateFinished":"2019-09-01T16:28:15+0000","dateStarted":"2019-09-01T16:27:59+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"getModel: org.deeplearning4j.nn.multilayer.MultiLayerNetwork\n"}]}},{"text":"import org.datavec.image.loader.BaseImageLoader\nimport collection.JavaConverters._\nimport java.io.File\n\nval states = Map(\"filesFilename\" -> \"cifar-10-binary.tar.gz\", \"filesURL\" -> \"https://storage.googleapis.com/ufrgsneuwald/~kriz/cifar-10-binary.tar.gz\", \"filesFilenameUnzipped\" -> \"cifar-10-batches-bin\")\n\nBaseImageLoader.downloadAndUntar(states, new File(new File(System.getProperty(\"user.home\")), \"cifar\"))\n\nval trainingDataSet = new CifarDataSetIterator(batchSize, numberOfSamples, true)\nval testDataSet = new CifarDataSetIterator(batchSize, numberOfTestSamples, false)\nimport scala.collection.mutable.ListBuffer\n\nvar trainDataList = new ListBuffer[DataSet]()\nwhile (trainingDataSet.hasNext()) {\n  trainDataList += trainingDataSet.next()\n}\n\nval testDataList = new ListBuffer[DataSet]()\nwhile (testDataSet.hasNext()) {\n  testDataList += testDataSet.next()\n}\nval trainData = sc.parallelize(trainDataList)\nval testData = sc.parallelize(testDataList)","dateUpdated":"2019-09-01T16:26:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.datavec.image.loader.BaseImageLoader\nimport collection.JavaConverters._\nimport java.io.File\nstates: scala.collection.immutable.Map[String,String] = Map(filesFilename -> cifar-10-binary.tar.gz, filesURL -> https://storage.googleapis.com/ufrgsneuwald/~kriz/cifar-10-binary.tar.gz, filesFilenameUnzipped -> cifar-10-batches-bin)\ntrainingDataSet: org.deeplearning4j.datasets.iterator.impl.CifarDataSetIterator = org.deeplearning4j.datasets.iterator.impl.CifarDataSetIterator@5ede1756\ntestDataSet: org.deeplearning4j.datasets.iterator.impl.CifarDataSetIterator = org.deeplearning4j.datasets.iterator.impl.CifarDataSetIterator@7bfbcf67\nimport scala.collection.mutable.ListBuffer\ntrainDataList: scala.collection.mutable.ListBuffer[org.nd4j.linalg.dataset.DataSet] = ListBuffer()\ntestDataList: scala.collection.mutable.ListBuffer[org.nd4j.linalg.dataset.DataSet] = ListBuffer()\ntrainData: org.apache.spark.rdd.RDD[org.nd4j.linalg.dataset.DataSet] = ParallelCollectionRDD[0] at parallelize at <console>:121\ntestData: org.apache.spark.rdd.RDD[org.nd4j.linalg.dataset.DataSet] = ParallelCollectionRDD[1] at parallelize at <console>:121\n"}]},"apps":[],"jobName":"paragraph_1567353809537_-1369996228","id":"20190828-044805_1310907596","dateCreated":"2019-09-01T16:03:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1233","user":"anonymous","dateFinished":"2019-09-01T16:28:30+0000","dateStarted":"2019-09-01T16:27:59+0000"},{"text":"val tm = new ParameterAveragingTrainingMaster.Builder(batchSize)    //Each DataSet object: contains (by default) 32 examples\n  .workerPrefetchNumBatches(0)\n  .saveUpdater(true)\n  .averagingFrequency(5)                            //Do 5 minibatch fit operations per worker, then average and redistribute parameters\n  .batchSizePerWorker(batchSize)     //Number of examples that each worker uses per fit operation\n  .build()\n  \nval sparkNet = new SparkDl4jMultiLayer(sc, getModel, tm)","dateUpdated":"2019-09-01T16:26:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{"0":{"graph":{"mode":"table","height":424,"optionOpen":false}}},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"tm: org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster = ParameterAveragingTrainingMaster(saveUpdater=true, numWorkers=null, rddDataSetNumExamples=32, averagingFrequency=5, aggregationDepth=2, prefetchNumBatches=0, iterationCount=0, trainingHookList=null)\nsparkNet: org.deeplearning4j.spark.impl.multilayer.SparkDl4jMultiLayer = org.deeplearning4j.spark.impl.multilayer.SparkDl4jMultiLayer@14794bfb\n"}]},"apps":[],"jobName":"paragraph_1567353809538_-1368841982","id":"20190831-215135_666155718","dateCreated":"2019-09-01T16:03:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1235","user":"anonymous","dateFinished":"2019-09-01T16:28:32+0000","dateStarted":"2019-09-01T16:28:16+0000"},{"text":"  val trained = sparkNet.fit(trainData)\n","dateUpdated":"2019-09-01T16:28:59+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1567353809538_-1368841982","id":"20190901-152458_948950979","dateCreated":"2019-09-01T16:03:29+0000","status":"RUNNING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1236","user":"anonymous","dateFinished":"2019-09-01T16:26:08+0000","dateStarted":"2019-09-01T16:47:06+0000"},{"text":"    val numEpochs = 1\nfor (i <- 0 to numEpochs) {\n  val trained = sparkNet.fit(trainData)\n}","dateUpdated":"2019-09-01T16:26:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"numEpochs: Int = 1\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 40.0 failed 4 times, most recent failure: Lost task 4.3 in stage 40.0 (TID 277, emnist-cluster-w-0.us-central1-b.c.hidden-analyzer-249419.internal): ExecutorLostFailure (executor 30 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 9.1 GB of 9 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936)\n  at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1002)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n  at org.apache.spark.rdd.RDD.reduce(RDD.scala:984)\n  at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1127)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n  at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1104)\n  at org.apache.spark.api.java.JavaRDDLike$class.treeAggregate(JavaRDDLike.scala:438)\n  at org.apache.spark.api.java.AbstractJavaRDDLike.treeAggregate(JavaRDDLike.scala:45)\n  at org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster.processResults(ParameterAveragingTrainingMaster.java:801)\n  at org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster.doIterationPaths(ParameterAveragingTrainingMaster.java:712)\n  at org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster.executeTrainingPathsHelper(ParameterAveragingTrainingMaster.java:432)\n  at org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster.executeTraining(ParameterAveragingTrainingMaster.java:317)\n  at org.deeplearning4j.spark.impl.multilayer.SparkDl4jMultiLayer.fit(SparkDl4jMultiLayer.java:218)\n  at org.deeplearning4j.spark.impl.multilayer.SparkDl4jMultiLayer.fit(SparkDl4jMultiLayer.java:205)\n  at $$$$c550adb942e23da546dd2ad2a59b37b$$$$$anonfun$1.apply$mcVI$sp(<console>:153)\n  at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n  ... 76 elided\n"}]},"apps":[],"jobName":"paragraph_1567353809538_-1368841982","id":"20190813-015330_1330142053","dateCreated":"2019-09-01T16:03:29+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:1237","user":"anonymous","dateFinished":"2019-09-01T16:45:16+0000","dateStarted":"2019-09-01T16:28:31+0000"},{"text":"val resultado = sparkNet.doEvaluation(testData, 64, new Evaluation(10))(0)","dateUpdated":"2019-09-01T16:26:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"resultado: org.deeplearning4j.eval.Evaluation =\n\nExamples labeled as 0 classified by model as 0: 724 times\nExamples labeled as 0 classified by model as 6: 136 times\nExamples labeled as 0 classified by model as 7: 52 times\nExamples labeled as 0 classified by model as 8: 88 times\nExamples labeled as 1 classified by model as 0: 296 times\nExamples labeled as 1 classified by model as 6: 438 times\nExamples labeled as 1 classified by model as 7: 126 times\nExamples labeled as 1 classified by model as 8: 137 times\nExamples labeled as 1 classified by model as 9: 3 times\nExamples labeled as 2 classified by model as 0: 343 times\nExamples labeled as 2 classified by model as 6: 521 times\nExamples labeled as 2 classified by model as 7: 120 times\nExamples labeled as 2 classified by model as 8: 16 times..."}]},"apps":[],"jobName":"paragraph_1567353809538_-1368841982","id":"20190813-021401_2110373941","dateCreated":"2019-09-01T16:03:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1238","user":"anonymous","dateFinished":"2019-09-01T16:47:06+0000","dateStarted":"2019-09-01T16:28:32+0000"},{"text":"println(resultado)","dateUpdated":"2019-09-01T16:26:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nExamples labeled as 0 classified by model as 0: 724 times\nExamples labeled as 0 classified by model as 6: 136 times\nExamples labeled as 0 classified by model as 7: 52 times\nExamples labeled as 0 classified by model as 8: 88 times\nExamples labeled as 1 classified by model as 0: 296 times\nExamples labeled as 1 classified by model as 6: 438 times\nExamples labeled as 1 classified by model as 7: 126 times\nExamples labeled as 1 classified by model as 8: 137 times\nExamples labeled as 1 classified by model as 9: 3 times\nExamples labeled as 2 classified by model as 0: 343 times\nExamples labeled as 2 classified by model as 6: 521 times\nExamples labeled as 2 classified by model as 7: 120 times\nExamples labeled as 2 classified by model as 8: 16 times\nExamples labeled as 3 classified by model as 0: 238 times\nExamples labeled as 3 classified by model as 6: 595 times\nExamples labeled as 3 classified by model as 7: 151 times\nExamples labeled as 3 classified by model as 8: 16 times\nExamples labeled as 4 classified by model as 0: 163 times\nExamples labeled as 4 classified by model as 6: 678 times\nExamples labeled as 4 classified by model as 7: 139 times\nExamples labeled as 4 classified by model as 8: 20 times\nExamples labeled as 5 classified by model as 0: 246 times\nExamples labeled as 5 classified by model as 3: 1 times\nExamples labeled as 5 classified by model as 6: 555 times\nExamples labeled as 5 classified by model as 7: 178 times\nExamples labeled as 5 classified by model as 8: 20 times\nExamples labeled as 6 classified by model as 0: 126 times\nExamples labeled as 6 classified by model as 6: 757 times\nExamples labeled as 6 classified by model as 7: 109 times\nExamples labeled as 6 classified by model as 8: 8 times\nExamples labeled as 7 classified by model as 0: 172 times\nExamples labeled as 7 classified by model as 6: 414 times\nExamples labeled as 7 classified by model as 7: 380 times\nExamples labeled as 7 classified by model as 8: 34 times\nExamples labeled as 8 classified by model as 0: 540 times\nExamples labeled as 8 classified by model as 6: 171 times\nExamples labeled as 8 classified by model as 7: 52 times\nExamples labeled as 8 classified by model as 8: 235 times\nExamples labeled as 8 classified by model as 9: 2 times\nExamples labeled as 9 classified by model as 0: 334 times\nExamples labeled as 9 classified by model as 6: 246 times\nExamples labeled as 9 classified by model as 7: 267 times\nExamples labeled as 9 classified by model as 8: 150 times\nExamples labeled as 9 classified by model as 9: 3 times\n\nWarning: 4 classes were never predicted by the model and were excluded from average precision\nClasses excluded from average precision: [1, 2, 4, 5]\n\n==========================Scores========================================\n # of classes:    10\n Accuracy:        0.2099\n Precision:       0.2227\t(4 classes excluded from average)\n Recall:          0.2099\n F1 Score:        0.1991\t(4 classes excluded from average)\nPrecision, recall & F1: macro-averaged (equally weighted avg. of 10 classes)\n========================================================================\n"}]},"apps":[],"jobName":"paragraph_1567353809539_-1369226730","id":"20190828-032002_1964617380","dateCreated":"2019-09-01T16:03:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1239","user":"anonymous","dateFinished":"2019-09-01T16:47:06+0000","dateStarted":"2019-09-01T16:45:17+0000"},{"dateUpdated":"2019-09-01T16:03:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1567353809539_-1369226730","id":"20190828-032119_912714771","dateCreated":"2019-09-01T16:03:29+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1240"}],"name":"martinez_difar10","id":"2EMF2NKYP","angularObjects":{"2ENB41NWM:shared_process":[],"2EKFEJQXZ:shared_process":[],"2ENF29KB8:shared_process":[],"2EP26U3CT:shared_process":[],"2EN3K2UAH:shared_process":[],"2EMMPASRN:shared_process":[],"2EKEHHAFH:shared_process":[],"2EMJBFZUG:shared_process":[],"2EKRWVC7R:shared_process":[],"2EK9UUBUA:shared_process":[],"2EKEDSX5M:shared_process":[],"2EKJ4JZZ5:shared_process":[],"2EJZ8VA14:shared_process":[],"2EMVTZMPS:shared_process":[],"2EKYR214R:shared_process":[],"2EP3Y2MES:shared_process":[],"2EPCZX4QX:shared_process":[],"2EN2YJ54W:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}