    1  exit
    2  ls -l
    3  cd Projetos
    4  ls -l
    5  cd horizon-read
    6  ls -l
    7  git status
    8  cd ..
    9  cd horizon_event_stream
   10  ls -l
   11  ssh 
   12  ls -l
   13  exit
   14  scala
   15  ssh hadoop06
   16  ssh hadoop6.cmal08be-1200.cp.globoi.com
   17  ssh hadoop5.cmal08be-1200.cp.globoi.com
   18  go
   19  go -version
   20  go version
   21  cd ..
   22  ls -l
   23  cd leonardo.neuwald/n
   24  cd leonardo.neuwald/
   25  ls -l
   26  cd Projetos
   27  ls -l
   28  cd horizon-legacy-event-stream
   29  ls -l
   30  code .
   31  go version
   32  exit
   33  go version
   34  cd..
   35  ls -l
   36  cd ..
   37  ls -l
   38  cd go
   39  ls -l
   40  cd ..
   41  ls -l
   42  cd ..
   43  ls -l
   44  cd leonardo.neuwald
   45  ls -l
   46  cd $HOME/go
   47  vi ~/.bash_profile
   48  echo $GOPATH
   49  ls -l
   50  mkdir go
   51  ls -l
   52  cd go
   53  mkdir -p src/go-course
   54  cd src/go-course
   55  mkdir 01-hello-world
   56  vi ~/.bash_profile
   57  \nsource ~/.bash_profile\n
   58  echo $GOHOME
   59  echo GOHOME
   60  echo $GOHOME
   61  source ~/.bash_profile
   62  echo $GOHOME
   63  vi ~/.bash_profile
   64  echo $GOPATH
   65  ls -l
   66  cd 01-hello-world
   67  ls -l
   68  go run main.go
   69  ls -l
   70  go run name.go
   71  go run main.go
   72  go
   73  go build
   74  ls -l
   75  ./01-hello-world
   76  go build -o hello
   77  ./hello
   78  go build -v
   79  ls -l
   80  rm -rf 01-hello-world
   81  go build -v
   82  ls -
   83  ls l
   84  ls -l
   85  rm -rf 01-hello-world hello
   86  go build -v
   87  go build -v -a
   88  ls -l
   89  GOOS=windows go build
   90  ls -l
   91  gp env
   92  go env
   93  go fmt
   94  goimports
   95  go get golang.org/x/tools/cmd/goimports
   96  goimports
   97  history | grep vi
   98  vi ~/.bash_profile
   99  history | grep source
  100  source ~/.bash_profile
  101  goimports main.go
  102  ls -l ˜/
  103  ls -l
  104  cd ..
  105  l s-l
  106  ls -l
  107  cd ..
  108  ls -l
  109  cd golang.org
  110  ls -l
  111  cd ..
  112  ls -l
  113  cd go-course
  114  ls -l
  115  mkdir 02-variables
  116  cd 02-variables
  117  go run main.go
  118  cd ..
  119  cd 03-type-conversion
  120  go run
  121  go run main.go
  122  cd ..
  123  cd 04-arrays
  124  go run main.go
  125  cd ..
  126  ls -l
  127  cd 05-slices
  128  go run main.go
  129  cd ..
  130  cd 06-maps
  131  go run main.go
  132  cd ..
  133  ls -l
  134  cd 07-functions-1
  135  ls -l
  136  go tun main.go
  137  go run main.go
  138  cd ..
  139  cd 07-functions-2
  140  go run main.go
  141  cd ..
  142  cd 07-functions-3
  143  go run main.go
  144  cd .
  145  cd ..
  146  cd 07-functions-4
  147  ls -l
  148  go run main.go
  149  cd ..
  150  cd 08-pointers
  151  go run main.go
  152  cd ..
  153  cd 09-if-else
  154  go run main.go
  155  cd ..
  156  cd 10-swith
  157  go run main.go
  158  cd ..
  159  cd 11-for
  160  go run main.go
  161  cd .
  162  cd ..
  163  cd 12-struct
  164  go run main.go
  165  cd ..
  166  cd 12-struct
  167  go run main.go
  168  cd ..
  169  cd 13-method
  170  cd ..
  171  cd 14-interfaces
  172  go run main.go
  173  cd ..
  174  ls-l
  175  ls -l
  176  cd 15-erros
  177  ls -l
  178  go run main.go 
  179  cd ..
  180  ls -l
  181  cd 16-defer
  182  go run main.go
  183  cd ../18-gorotines1
  184  go run main.go
  185  cd ../18-gorotines2
  186  go run main.go
  187  cd ..
  188  cd 18-gorotines20
  189  go run main.go
  190  ls -l
  191  cd ..
  192  cd 19-data-race
  193  go run main.go
  194  cd ..
  195  cd 20-channel
  196  go run main.go
  197  cd ..
  198  cd ˜
  199  ls -l
  200  pwd
  201  cd ˜/
  202  cd ~/
  203  ls -l
  204  cd configs
  205  ls-l
  206  ls -l
  207  cd conf-qa
  208  ls -l
  209  mv ~/Downloads/hadoop-2.7.3 ~/
  210  ls -l
  211  cd ..
  212  ls -l
  213  alias hadoop-use-qa='export HADOOP_CONF_DIR=~/Tools/hadoop/configs/conf-qa'
  214  alias hadoop-use-prod='export HADOOP_CONF_DIR=~/Tools/hadoop/configs/conf-prod'
  215  alias hadoop-use-prod='export HADOOP_CONF_DIR=~/configs/conf-prod'
  216  hadoop-use-prod
  217  cd hadoop-2.7.3
  218  ./bin/yarn application -list
  219  ./bin/yarn application -kill application_1539207608922_129580
  220  ls -l
  221  pwd
  222  cd ..
  223  ls -l
  224  cd projetos
  225  ls -l
  226  cd horizon-read
  227  ls -l
  228  sbt clean compile
  229  hdfs dfs -ls 
  230  hdfs dfs -ls /
  231  ls -l
  232  history
  233  alias hadoop-use-prod='export HADOOP_CONF_DIR=~/configs/conf-prod'
  234  hadoop-use-prod
  235  ls -l
  236  cd hadoop-2.7.3
  237  ls -l
  238  cd bin
  239  ls -l
  240  ./hdfs dfs -ls /
  241  ./hdfs dfs -ls /user
  242  ./hdfs dfs -ls /user/actions/stream
  243  ./hdfs dfs -ls /user/actions/stream/tenant=g1
  244  ./hdfs dfs -ls /user/actions/stream/tenant=g1/home-api
  245  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent
  246  history
  247  vi ~/.bash_profile
  248  hadoop-use-qa
  249  source ~/.bash_profile
  250  hadoop-use-qa
  251  hadoop-use-prod
  252  history
  253  pwd
  254  cd hadoop-2.7.3
  255  ls -l 
  256  hadoop-use-prod
  257  exit
  258  history
  259  hadoop-2.7.3
  260  hadoop-use-prod
  261  vi ~/.bash_profile
  262  alias hadoop-use-prod='export HADOOP_CONF_DIR=~/configs/conf-prod'
  263  hadoop-use-prod
  264  ./bin/hdfs dfs -ls /parquet
  265  ./bin/hdfs dfs -ls /parquet/horizon-pushtokenevent
  266  ./bin/hdfs dfs -ls /parquet
  267  ./bin/hdfs dfs -ls /parquet/pageview
  268  ./bin/hdfs dfs -ls /parquet/horizon-pushtokenevent
  269  ./bin/hdfs dfs -ls /parquet/videowatch/2019031907/201903190760
  270  ./bin/hdfs dfs -ls /parquet/videowatch
  271  ./bin/hdfs dfs -ls /parquet/videowatch/2019031908
  272  ./bin/hdfs dfs -ls /parquet/horizon-pushtokenevent
  273  ./bin/hdfs dfs -ls /parquet/horizon-pushtokenevent/2019031909
  274  ./bin/hdfs dfs -ls /parquet
  275  ./bin/hdfs dfs -ls /parquet/videowatch
  276  ./bin/hdfs dfs -ls /parquet/horizon-pushtokenevent
  277  ./bin/yarn application -kill application_1539207608922_162456
  278  ./bin/yarn application -kill application_1539207608922_160801
  279  cd projetos
  280  ls -l
  281  git clone gitlab@gitlab.globoi.com:BigDataPipeline/horizon_avro_stream.git
  282  ./bin/hdfs dfs -ls /parquet/horizon-pushtokenevent
  283  ./bin/hdfs dfs -ls /parquet
  284  ./bin/hdfs dfs -ls /parquet/click/201911*
  285  ./bin/hdfs dfs -ls /parquet/click/201811*
  286  ./bin/hdfs dfs -ls /parquet/click | grep 20181104
  287  ./bin/hdfs dfs -ls /parquet/click | grep 20181105
  288  ./bin/hdfs dfs -ls /parquet/click | grep 20190216
  289  java -version
  290  scala
  291  ./bin/hdfs dfs -ls /parquet/
  292  ./bin/hdfs dfs -ls /user/actions/stream
  293  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/
  294  ./bin/hdfs dfs -ls /user/actions/stream/tenant=player
  295  ./bin/hdfs dfs -ls /user/actions/stream/tenant=player/actionsContentType=video
  296  ./bin/hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video
  297  ./bin/yarn application -kill application_1539207608922_173874
  298  ./bin/yarn application -kill application_1539207608922_173618
  299  ./bin/yarn application -kill application_1539207608922_173617
  300  ./bin/yarn application -kill application_1539207608922_173613
  301  ./bin/yarn application -kill application_1539207608922_173610
  302  ./bin/yarn application -kill application_1539207608922_173515
  303  ./bin/yarn application -kill application_1539207608922_173514
  304  ./bin/yarn application -kill application_1539207608922_174074\t
  305  ./bin/yarn application -kill application_1539207608922_174072
  306  ./bin/hdfs dfs -ls /parquet/videowatchlive/2019031922
  307  ./bin/hdfs dfs -ls /parquet/videowatchlive
  308  ./bin/yarn application -kill application_1539207608922_161731
  309  ./bin/yarn application -kill application_1539207608922_152364
  310  ls -l
  311  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-schemas-service.git
  312  cd horizon-schemas-service
  313  git status
  314  git loh
  315  git log
  316  cat hzs/version.go
  317  git tag v0.14.0
  318  git push
  319  git push --tags
  320  ls -l
  321  vi Makefile
  322  vi tasks/tsuru.mk
  323  pdw
  324  pwd
  325  make tsuru-deploy-dev
  326  echo $GO_PATH
  327  echo $GOPATH
  328  history | pro
  329  history | grep pro
  330  vi ~/.bash_profile
  331  cd ..
  332  ls -l
  333  mv horizon-schemas-service ~/go
  334  cd ~/go
  335  ls -l
  336  cd src
  337  ls -l
  338  cd ..
  339  ls -l
  340  mv horizon-schemas-service src/gitlab.globoi.com/bigdata/pipeline
  341  mkdir -p src/gitlab.globoi.com/bigdata/pipeline
  342  mv horizon-schemas-service src/gitlab.globoi.com/bigdata/pipeline
  343  cd src/gitlab.globoi.com/bigdata/pipeline
  344  ls -l
  345  cd horizon-schemas-service
  346  make test
  347  make tools
  348  brew tap tsuru/homebrew-tsuru
  349  brew install tsuru
  350  tsuru target-add default https://tsuru.globoi.com -s
  351  tsuru login
  352  tsuru team list
  353  tsuru app list
  354  tsuru key-add leonardo ~/.ssh/id_rsa.pub
  355  make tsuru-add-remotes
  356  make tsuru-deploy-dev
  357  tsuru app info -a horizon-schemas-dev
  358  history | grep make
  359  make tsuru-deploy-qa
  360  tsuru app info -a horizon-schemas-qa
  361  make tsuru-deploy-prod
  362  tsuru app info -a horizon-schemas-prod
  363  ls -l
  364  cd Projetos
  365  ls -l
  366  cd horizon-read
  367  sbt clean compile
  368  sbt
  369  scala
  370  history
  371  vi ~/.bash_profile
  372  source ~/.bash_profile
  373  sbt clean compile
  374  ./bin/hdfs dfs -ls /user/actions/stream/tenant=oglobo/actionContentType=pes/actionId=pes-sync-id/actionVersion=1.0/year=2019/month=3/day=19
  375  ./bin/hdfs dfs -ls /user/actions/stream/tenant=oglobo/actionContentType=pes/actionId=pes-sync-id/actionVersion=1.0/year=2019/month=3
  376  ./bin/hdfs dfs -ls /user/actions/stream/tenant=oglobo/actionContentType=pes/actionId=pes-sync-id/actionVersion=1.0/year=2019/month=3/day=18
  377  ./bin/hdfs dfs -ls /user/actions/stream/tenant=oglobo/actionContentType=pes/actionId=pes-sync-id/actionVersion=1.0/year=2019/month=3/day=20
  378  sbt clean compile
  379  scala
  380  sbt test
  381  sbt clean test
  382  cd ..
  383  ls -l
  384  cd ~/Projetps
  385  cd ~/Projetos
  386  ls -l
  387  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/azkaban/pipeline-document-ingest.git
  388  cd pipeline-document-ingest
  389  ls -l
  390  code
  391  code .
  392  cd ..
  393  mkdir pipeline-queue-swap
  394  cd pipeline-
  395  cd pipeline-queue-swap
  396  ls -l
  397  code .
  398  cd ..
  399  ls -l
  400  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/azkaban/pipeline-horizon-stream-ingest.git
  401  cd pipeline-horizon-stream-ingest
  402  ls -l
  403  code .
  404  cd ..
  405  ls -l
  406  cd pipeline-queue-swap
  407  ls -l
  408  cp ../pipeline-horizon-stream-ingest/Makefile .
  409  cp ../pipeline-horizon-stream-ingest/README.md .
  410  make zip
  411  ls -l
  412  cd jobs
  413  ls -l
  414  ./swap_list.sh
  415  chmod +x swap_list.sh
  416  ls -l
  417  cd ..
  418  make zip
  419  ls -l
  420  ls -l jobs
  421  chmod -777 swap_list.sh
  422  chmod 777 swap_list.sh
  423  chmod 777 jobs/swap_list.sh
  424  ls -l jobs
  425  make zip
  426  ls -l
  427  cd dist
  428  ls -l
  429  cd ..
  430  ls -l
  431  make zip
  432  ./bin/hdfs dfs -ls /user/actions/stream/tenant=oglobo/actionContentType=pes/actionId=pes-sync-id/actionVersion=1.0/year=2019/month=3/day=20
  433  cd bin
  434  ls -l
  435  applications=`yarn application -appStates "RUNNING" -list`
  436  applications=`.\yarn application -appStates "RUNNING" -list`
  437  applications=`./yarn application -appStates "RUNNING" -list`
  438  applications=(`echo ${applications}`)
  439  for application in "${applications[@]}" do echo "App $application" done\n\n\n\n\n\n\ndone
  440  for application in "${applications[@]}" \ndo \n    echo "App $application" \ndone
  441  echo ${applications}
  442  make zip
  443  ls -l
  444  ls -l jobs
  445  echo ${applications}
  446  make zip
  447  applications=`./yarn application -appStates "RUNNING" -list | sed -e 's/.*\(application[_0-9]*\).*/\1/'`; applications=(`echo ${applications}`); for application in "${applications[@]}";do;echo "App $application";done
  448  make zip
  449  for application in "`echo ./yarn application -appStates "RUNNING" -list | sed -e 's/.*\(application[_0-9]*\).*/\1/'`";do;echo "App $application";done
  450  applications=`echo ./yarn application -appStates "RUNNING" -list | sed -e 's/.*\(application[_0-9]*\).*/\1/'`
  451  for application in "${applications[@]}";do;echo "App $application";done
  452  make zip
  453  ./yarn application -appStates "ACCEPTED" -list
  454  make zip
  455  ./yarn application -list
  456  ./yarn application -kill application_1539207608922_152355
  457  ls -l
  458  git status
  459  cd ..
  460  ls -l
  461  cd pipeline-queue-swap
  462  ls -l
  463  cd jobs
  464  ls -l
  465  vi swap.sh
  466  ls -l
  467  cd ..
  468  ls -l
  469  cd ..
  470  ls -l
  471  cd pipeline-document-ingest
  472  ls -l
  473  ll
  474  defaults write com.apple.finder AppleShowAllFiles YES
  475  ls -l
  476  defaults write com.apple.finder AppleShowAllFiles YES
  477  ls -l
  478  ls -a
  479  cd ..
  480  ls -l
  481  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/azkaban/pipeline-disk-usage.git
  482  ls -l
  483  cd pipeline-swa
  484  cd pipeline-queue-swap
  485  ls -l
  486  ls -a
  487  cd ..
  488  ls -l
  489  cp pipeline-document-ingest/.gitignore pipeline-queue-swap
  490  cp pipeline-document-ingest/.editorconfig pipeline-queue-swap
  491  cd pipeline-queue-swap
  492  ls -l
  493  ls -a
  494  git config --global user.name "leonardo.neuwald"
  495  git config --global user.email "leonardo.neuwald@corp.globo.com"
  496  git init
  497  git remote add origin gitlab@gitlab.globoi.com:bigdata/pipeline/azkaban/pipeline-queue-swap.git
  498  git add .
  499  git commit -m "feat: first release"
  500  git push -u origin master
  501  history | grep hdfs
  502  ./hdfs dfs -ls /user/actions/stream/tenant=g1/
  503  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent
  504  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-view
  505  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-view/actionVersion=4.0
  506  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-view/actionVersion=4.0/year=2019
  507  ls -l
  508  cd ..
  509  ls -l
  510  cd ..
  511  ls -l
  512  cd ..
  513  ls -l
  514  git clone gitlab@gitlab.globoi.com:BigDataPipeline/horizon_event_stream.git
  515  mv ~/Downloads/spark-2.4.0-bin-hadoop2.7 ~/
  516  ls -l
  517  cd spark-2.4.0-bin-hadoop2.7
  518  ls -l
  519  ./bin/spark-shell -master local[2]
  520  cd bin
  521  ls -l
  522  ./spark-shell --master local[2
  523  ./spark-shell --master local[2]
  524  ./spark-shell --master local 2
  525  git clone gitlab@gitlab.globoi.com:BigDataPipeline/azkaban-gcp-billing.git
  526  cd azkaban-gcp-billing
  527  ls -l
  528  python -version
  529  python --version
  530  brew update
  531  brew install pyenv
  532  echo -e 'if command -v pyenv 1>/dev/null 2>&1; then\n  eval "$(pyenv init -)"\nfi' >> ~/.bash_profile
  533  source ~/.bash_profile
  534  pyenv
  535  pyenv install --list
  536  pyenv install 3.6.8
  537  pyenv
  538  pyenv shell
  539  pyenv shell 3.6.8
  540  python versiony
  541  python version
  542  pyenv version
  543  python --version
  544  which pythtn
  545  which python
  546  vi ~/.bash_profile
  547  source ~/.bash_profile
  548  which python
  549  vi ~/.bash_profile
  550  source ~/.bash_profile
  551  which python
  552  python --version
  553  pip install virtualenv
  554  virtualenv .venv
  555  source .venv/bin/activate
  556  deactivate
  557  source .venv/bin/activate
  558  pip install -r requirements.txt
  559  python billing-gcs-companies-ga.py 2019 03 23 y
  560  deactivate
  561  history
  562  sbt clean test
  563  source .venv/bin/activate
  564  pip install -r requirements.txt
  565  python billing-gcs-companies-ga.py 2019 03 25 y
  566  ./spark-shell --master local 2
  567  sbt clean testOnly com.globo.bigdata.horizonread.HorizonReaderTest 
  568  ls -l
  569  history
  570  deactivate
  571  cd ..
  572  git clone gitlab@gitlab.globoi.com:globoid/horizon-client-ios.git
  573  git clone gitlab@gitlab.globoi.com:globoid/horizon-client-android.git
  574  gem
  575  sudo gem install cocopods
  576  sudo gem install cocoapods
  577  ls -l
  578  cd horizon-client-ios
  579  ls -l
  580  cd HorizonClient
  581  ls -l
  582  pod install
  583  htop
  584  top
  585  open HorizonClient.xcodeproj
  586  open HorizonClient.xcworkspace
  587  pod install
  588  open HorizonClient.xcworkspace
  589  tsuru app info
  590  tsuru app-info -a horizon-track-prod
  591  tsuru app-info -a horizon-track-service-prod
  592  tsuru app-info -a horizon-track-prod
  593  tsuru unit-add 
  594  tsuru unit-add 80 -a horizon-track-service-prod
  595  tsuru unit-add 39 -a horizon-track-service-prod
  596  tsuru unit-add 40 -a horizon-track-service-prod
  597  tsuru unit-add 20 -a horizon-track-service-prod
  598  tsuru app-info -a horizon-track-service-prod
  599  tsuru unit-add 20 -a horizon-track-service-prod
  600  cd ..
  601  ls -l
  602  mkdir scripts
  603  ls -l
  604  cd ..
  605  ls -l
  606  mv ~/Downloads/kafka-consumer.py Projetos/scripts
  607  ls -l
  608  ls -l scripts
  609  cd Projetos
  610  l -sl
  611  cd scripts
  612  cd ..
  613  ls -l
  614  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-track-service.git
  615  cd horizon-track-service
  616  cd ..
  617  ls -l
  618  cd ..
  619  ls -l
  620  cd go
  621  ls -l
  622  cd src/gitlab.globoi.com/bigdata/pipeline/
  623  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-track-service.git
  624  pwd
  625  l s-l
  626  ls -l
  627  cd horizon-track-service
  628  code .
  629  source ~/.bash_profile
  630  code .
  631  tsuru unit-remove 60 -a horizon-track-service-prod
  632  tsuru unit-remove 19 -a horizon-track-service-prod
  633  tsuru
  634  tsuru app-log -a horizon-track-service-prod
  635  tsuru app-log
  636  tsuru app-log -a horizon-track-service-prod
  637  tsuru app-log -f -a horizon-track-service-prod
  638  tsuru app-log -f -a horizon-track-service-prod | grep kafka
  639  ls -l
  640  cd ..
  641  ls -l
  642  pwd
  643  cd ..
  644  ls -l
  645  cd hadoop-2.7.3
  646  ls -l
  647  cd bin
  648  ls -l
  649  ./yarn application -list
  650  ./yarn application -list | grep application_1539207608922_173831
  651  ./yarn application -kill application_1539207608922_173831
  652  cd ..
  653  ls -l
  654  mkdir azkaban
  655  mv horizon-legacy-event-stream azkaban
  656  mv azkaban/horizon-legacy-event-stream .
  657  l s-l
  658  ls -l
  659  cd azkaban
  660  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/azkaban/pipeline-horizon-stream-ingest.git
  661  cd pipeline-horizon-stream-ingest
  662  make zip
  663  ./yarn application -kill application_1539207608922_149702
  664  ./yarn application -kill application_1539207608922_184469
  665  git status
  666  git diff
  667  cd ..
  668  ls -l
  669  cd ..
  670  ls -l
  671  cd pipeline-disk-usage
  672  ls -l
  673  cd ..
  674  ls -l
  675  mv pipeline-disk-usage azkaban/
  676  mv pipeline-queue-swap azkaban/
  677  ls -l
  678  cd pipeline-document-ingest
  679  ls -l
  680  cd ..
  681  mv pipeline-document-ingest azkaban/
  682  cd pipeline-horizon-stream-ingest
  683  l s-l
  684  ls -l
  685  cd ..
  686  cd azkaban
  687  ls -l
  688  cd pipeline-horizon-stream-ingest
  689  git status
  690  git diff
  691  git status
  692  git diff
  693  git status
  694  git diff
  695  git status
  696  git checkout -b fix/player-stream-delayed
  697  git status
  698  git add .
  699  git commit -m "fix: increase player's resources"
  700  git status
  701  git push origin fix/player-stream-delayed 
  702  history | grep tsuru
  703  tsuru app-log -f -a horizon-track-service-prod
  704  tsuru app-log -f -a horizon-track-service-prod | grep kafka
  705  tsuru app-log -f -a horizon-track-service-prod
  706  tsuru app-log -f -a horizon-track-prod | grep kafka
  707  tsuru app-info
  708  tsuru app-info -a horizon-track-prod
  709  tsuru app-info -a horizon-track-service-prod
  710  tsuru app-info -a horizon-track-service-prod | grep kafka
  711  tsuru app-log -f -a horizon-track-prod | grep kafka
  712  tsuru app-log -f -a horizon-track-service-prod
  713  tsuru app-log -f -a horizon-track-service-prod | grep kafka
  714  ping www.terra.com.br
  715  tsuru app-log -f -a horizon-track-service-prod | grep kafka
  716  tsuru app-log -f -a horizon-track-prod | grep kafka
  717  echo eyJob3Jpem9uQ2xpZW50VVVJRCI6ImJlZDQwM2RhLWY3NDUtNDM2MC04YTIzLTQwYWEyYWIyODMzOSIsImhvcml6b25DbGllbnRUZW5hbnQiOiJnMSIsImhvcml6b25DbGllbnRUcyI6MTU1Mzg5NTYzOTc2NCwiaG9yaXpvbkNsaWVudFR5cGUiOiJqcyIsImhvcml6b25DbGllbnREZXZpY2VHcm91cCI6ImRlc2t0b3AiLCJob3Jpem9uRGlzcGF0Y2hOdW1iZXIiOjUsImhvcml6b25BY3Rpb25Db3VudGVyIjoxMCwiaG9yaXpvbkVudmlyb25tZW50Ijoid2ViIiwiYWN0aW9ucyI6W3siaWQiOiJtdWx0aWNvbnRlbnQtdmlldyIsInZlcnNpb24iOiI0LjAiLCJwcm9wZXJ0aWVzIjp7ImZlZWRTZWVuIjpmYWxzZSwidGltZU9uTXVsdGljb250ZW50IjoxOTUwM30sInVybCI6Imh0dHBzOi8vZzEuZ2xvYm8uY29tL2NpZW5jaWEtZS1zYXVkZS92aXZhLXZvY2UvcXVpei92b2NlLXNhYmUtY3VpZGFyLWRvLXJvc3RvLWNvbW8tZGV2ZXJpYS1mYWNhLW8tcXVpei1lLWRlc2N1YnJhLmdodG1sIiwiYWN0aW9uVHMiOjE1NTM4OTU2Mzk2MDMsImhvcml6b25DbGllbnRWZXJzaW9uIjoiMS4wLjMiLCJob3Jpem9uQ2xpZW50UmVmZXJlciI6IiIsImNvbnRlbnRUeXBlIjoibXVsdGljb250ZW50In1dfQ== | base64 -D
  718  history
  719  pwd
  720  cd ..
  721  ls -l
  722  cd ..
  723  l s-l
  724  ls -l
  725  cd scripts
  726  ls -l
  727  cd .
  728  ls -l
  729  cd ..
  730  ls -l
  731  mv azkaban-gcp-billing azkaban
  732  ls -l
  733  cd azkaban
  734  ls -l
  735  cd azkaban-gcp-billing
  736  ls -l
  737  history
  738  source .venv/bin/activate
  739  pip install -r requirements.txt
  740  python billing-gcs-companies-ga.py 2019 03 30 y
  741  ls -l
  742  cd ..
  743  ls -l
  744  cd ..
  745  ls -l
  746  cd ..
  747  ls -l
  748  pwd
  749  cd ..
  750  ls -l
  751  cd gitlab.globoi.com
  752  ls -l
  753  cd bin
  754  cd bigdata
  755  ls -l 
  756  cd pipeline
  757  ls -l
  758  cd horizon-track-service
  759  cd ..
  760  ls -l
  761  pwd
  762  cd horizon-schemas-service
  763  git status
  764  git pull
  765  git log
  766  cd ..
  767  ls -l
  768  cd horizon-track-service
  769  git status
  770  git pull
  771  git log
  772  code .
  773  source ~/.bash_profile
  774  code .
  775  pwd
  776  cd /Users/leonardo.neuwald/go/src/gitlab.globoi.com/bigdata/pipeline/horizon-track-service
  777  code .
  778  ls -l
  779  make test
  780  history | grep log
  781  tsuru app-log -f -a horizon-track-prod
  782  make test
  783  git pull
  784  git checkout chore/create-app-in-the-new-pool 
  785  git stash
  786  git checkout chore/create-app-in-the-new-pool 
  787  git pukl
  788  git pull
  789  git stash pop
  790  git status
  791  git stash list
  792  git reset 
  793  git checkout .
  794  git status
  795  git pull
  796  git stash pop
  797  make test
  798  tsuru app-deploy -a horizon-track-service-prod main.go tsuru.yaml vendor hzt
  799  tsuru app-log -f -a horizon-track-service-prod
  800  tsuru app-log -f -a horizon-track-prod
  801  tsuru app-log -f -a horizon-track-service-prod
  802  tsuru app-log -f -a horizon-track-service-prod | grep -v healthcheck
  803  tsuru app-log -f -a horizon-track-service-prod | grep -v leo
  804  tsuru app-log -f -a horizon-track-service-prod | grep -v healthcheck
  805  tsuru app-log -f -a horizon-track-service-prod 
  806  tsuru app-log -f -a horizon-track-service-prod | grep -v status=200
  807  tsuru app-log -f -a horizon-track-service-prod | grep status=200
  808  tsuru app-log -f -a horizon-track-service-prod | grep -v status=200
  809  tsuru app-log -f -a horizon-track-service-prod | grep -v status=400
  810  tsuru app-log -f -a horizon-track-service-prod | grep -v status=200
  811  deactivate
  812  ls -l
  813  cd ..
  814  ls -l
  815  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-schemas.git
  816  ls -l
  817  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-schemas-service.git
  818  cd horizon-schemas-service
  819  ls -l
  820  ls -l hzs
  821  make submodule-update
  822  ls -l hzs
  823  ls -l hzs/schemas
  824  ls -l hzs/schemas/bastian
  825  git status
  826  git diff
  827  git add hzs/schemas
  828  git stauts
  829  git status
  830  git log
  831  git log --graph
  832  git checkout -b feat/update-bastian-schemas
  833  git status
  834  git commit -m "chore: update horizon-schemas submodule"
  835  ls -l
  836  code
  837  exit
  838  ks 0k
  839  ls -l
  840  cd Projetos/horizon-schemas-service
  841  code
  842  code .
  843  git status
  844  make test
  845  ls -l
  846  cd ..
  847  ls -l
  848  mv horizon-schemas-service ~/go/src/gitlab.globoi.com/bigdata/pipeline
  849  cd ~/go/src/gitlab.globoi.com/bigdata/pipeline
  850  ls -l
  851  cd horizon-schemas-service
  852  git status
  853  cd ..
  854  rm -rf horizon-schemas-service
  855  mv horizon-schemas-service ~/go/src/gitlab.globoi.com/bigdata/pipeline
  856  ls -l
  857  cd horizon-schemas-service
  858  ls -l
  859  git status
  860  make test
  861  git status
  862  git diff
  863  git log
  864  git log --grafh
  865  git log --graph
  866  git add .
  867  git commit -m "version: bump to 0.15.0"
  868  git status
  869  git push origin feat/update-bastian-schemas 
  870  git checkout master
  871  git status
  872  git pull
  873  git status
  874  git tag 
  875  git tag v0.15.0
  876  git status
  877  git log
  878  git push --tags
  879  make tsuru-add-remotes
  880  make tsuru-deploy-dev
  881  make tsuru-deploy-qa
  882  tsuru app-info -a horizon-schemas-qa
  883  make tsuru-deploy-prod
  884  tsuru app-info -a horizon-schemas-prod
  885  cd hzs
  886  ls -l
  887  cd schemas
  888  ls -l
  889  git fetch origin merge-requests/52/head:playkit
  890  git checkout playkit
  891  git merge master
  892  git log
  893  cd ..
  894  ls -l
  895  cd ..
  896  make testg
  897  make test
  898  vi tasks/tsuru.mk
  899  make tsuru-deploy-qa
  900  tsuru app-info -a horizon-schemas-qa
  901  history
  902  tsuru app-log -f -a horizon-track-service-prod
  903  tsuru app-log -f -a horizon-track-service-prod | grep -v status=200
  904  l s-l
  905  ls -l
  906  cd ..
  907  ls -l
  908  cd spark-2.4.0-bin-hadoop2.7
  909  cd ..
  910  cd hadoop-2.7.3/bin
  911  ls -l
  912  vi ~/.bash_profile
  913  export HADOOP_CONF_DIR=~/configs/conf-prod
  914  yarn application -list
  915  ./yarn application -list
  916  ./hdfs dfs -ls /parquet
  917  cd ..
  918  ls -l
  919  cd ..
  920  ls -l
  921  pwd
  922  cd ~/projetos
  923  ls -l
  924  cd horizon-read
  925  ls -l
  926  sbt clean compile
  927  sbt
  928  scala
  929  echo $PATH\n
  930  ls -a
  931  ls -a ~
  932  ls -a ~/.bash_profile
  933  vi ~/.bash_profile
  934  source ~/.bash_profile
  935  sbt clean compile
  936  ./hdfs dfs -ls /parquet/postview
  937  ./hdfs dfs -ls /parquet/postview/2019040217
  938  history | grep tsuru
  939  tsuru app-log -f -a horizon-track-prod
  940  sbt clean compile
  941  sbt clean test
  942  sbt clean compile
  943  sbt dependency tree
  944  sbt clean dependencyTree
  945  sbt clean dependencyTree > file.txt
  946  sbt clean test
  947  cd 
  948  ls -l
  949  mkdir git-test
  950  ls -l
  951  cd git-test
  952  touch file
  953  vi file
  954  git init
  955  git remote add origin gitlab@gitlab.globoi.com:leonardo.neuwald/git-test.git
  956  git status
  957  git checkout -b feat/test
  958  git add .
  959  git commit -m "feat: testes"
  960  git push origin feat/test 
  961  cd ..
  962  ls -l
  963  cd Projetos
  964  ls -l
  965  cd horizon-read
  966  sbt clean test
  967  hdfs dfs -ls /parquet/postview
  968  ./hdfs dfs -ls /parquet/postview
  969  date
  970  scala
  971  ./hdfs dfs -ls /user/actions/stream/tenant=g1
  972  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent
  973  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=performance-browser-load
  974  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=performance-browser-load/actionVersion=1.0
  975  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=performance-browser-load/actionVersion=1.0/vl_year=2019/vl_month=4
  976  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=performance-browser-load/actionVersion=1.0/vl_year=2019/vl_month=04
  977  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=performance-browser-load/actionVersion=1.0/year=2019
  978  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=performance-browser-load/actionVersion=1.0/year=2019/month=4
  979  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=performance-browser-load/actionVersion=1.0/year=2019/month=4/day=3
  980  sbt clean test
  981  cd ,,
  982  cd ..
  983  ls -l
  984  cp horizon-read horizon-read2
  985  cp -R horizon-read horizon-read2
  986  ls -l 
  987  mv horizon-read2 horizon-storage
  988  ls -l
  989  cd horizon-s
  990  cd horizon-storage
  991  sbt clean compile
  992  scala
  993  ls -l ~/.sbt/
  994  sbt clean test
  995  cleart
  996  clear
  997  sbt clean test
  998  ./yarn application -list
  999  ./yarn application -kill application_1539207608922_178232
 1000  sbt clean test
 1001  git status
 1002  git init
 1003  git remote add origin gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-storage.git
 1004  git add .
 1005  git commit -m "feat: first version of horizon storage"
 1006  git push origin master
 1007  make
 1008  make release
 1009  git status
 1010  git pull
 1011  git push origin 
 1012  git push --set-upstream origin HEAD
 1013  git status
 1014  git pull
 1015  make release
 1016  ls -l
 1017  touch ~/.sbt/.credentials
 1018  vi ~/.sbt/.credentials
 1019  make release
 1020  git statud
 1021  git status
 1022  git diff
 1023  git checkout src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonReader.scala
 1024  make release
 1025  sbt release
 1026  git status
 1027  git checkout project/*
 1028  git status
 1029  git checkout project/Resolvers.scala
 1030  git status
 1031  git add 
 1032  git add .
 1033  git status
 1034  git add .
 1035  git commit -m "chore: publish snapshot versions"
 1036  git push origin master
 1037  make release
 1038  sbt clean testg
 1039  sbt clean test
 1040  sbt clean publishLocal
 1041  git status
 1042  git add build.sbt
 1043  git commit -m "chore: remove deprecated methods"
 1044  git diff
 1045  git add .
 1046  git commit -m "fix: close hdfs ouput stream"
 1047  git push origin master
 1048  make release
 1049  cd ..
 1050  ls -l
 1051  git clone gitlab@gitlab.globoi.com:bigdata/hydrogen.git
 1052  ls -l
 1053  cd ..
 1054  ls -l
 1055  ls -l 
 1056  ls -l ~/Downloads
 1057  ls -l
 1058  mkdir gradle
 1059  mv ~/Downloads/gradle-2.14 gradle
 1060  cd gradle
 1061  ls -l
 1062  cd gradle-2.14/
 1063  ls l
 1064  ls -l
 1065  cd ..
 1066  ls -l
 1067  cd ..
 1068  ls -l
 1069  cd Projetos
 1070  ls -l
 1071  cd hydrogen
 1072  ls -l
 1073  cd hydrogen.warehouse
 1074  ls -l
 1075  cd ..
 1076  ~/gradle/gradle-2.14/bin/gradle clean build
 1077  cd ..
 1078  ls -l
 1079  cd ..
 1080  cd Downloads
 1081  ls -l
 1082  mv tcc-EBD ../eclipse-workspace
 1083  exit
 1084  cd hadoop-2.7.3
 1085  ls -l
 1086  cd bin
 1087  history | grep use
 1088  export HADOOP_CONF_DIR=~/configs/conf-prod
 1089  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view/actionVersion=1.0/year=2019/month=4
 1090  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view/actionVersion=1.0/year=2019/month=4/day=3
 1091  ls -l
 1092  cd Projetos
 1093  ls -l
 1094  cd scripts
 1095  ls -l
 1096  cd ..
 1097  cd azkaban
 1098  ls -l
 1099  cd azkaban-gcp-billing
 1100  history
 1101  source .venv/bin/activate
 1102  pip install -r requirements.txt
 1103  whitch python
 1104  history | grep pip
 1105  pip
 1106  history | grep python
 1107  python --version
 1108  python billing-gcs-companies-ga.py 2019 04 06 y
 1109  l s-l
 1110  ls -l
 1111  pip install -r requirements.txt
 1112  python --version
 1113  pip --version
 1114  vi ~/.bash_profile
 1115  source ~/.bash_profile
 1116  pip --version
 1117  pip install -r requirements.txt
 1118  deactivate
 1119  source ~/.bash_profile
 1120  whith python
 1121  which python
 1122  cd /Users/leonardo.neuwald/.pyenv/shims/
 1123  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view
 1124  ls -l
 1125  which pip
 1126  ls -l
 1127  cd ~/Projetos/azkaban/azkaban-gcp-billing
 1128  ls -l /Users/leonardo.neuwald/.pyenv/shims/pip
 1129  ls -l
 1130  history
 1131  source .venv/bin/activate
 1132  /Users/leonardo.neuwald/.pyenv/shims/pip install -r requirements.txt
 1133  ./Users/leonardo.neuwald/.pyenv/shims/pip install -r requirements.txt
 1134  vi ~/.bash_profile
 1135  history | grep pyenv
 1136  pyenv
 1137  ./Users/leonardo.neuwald/.pyenv/shims/pip install -r requirements.txt
 1138  pip install -r requirements.txt
 1139  vi ~/.bash_profile
 1140  pyenv init -
 1141  pip install -r requirements.txt
 1142  deactivate
 1143  pyenv init -
 1144  echo $PATH
 1145  pip --version
 1146  pip -version
 1147  pyenv init
 1148  eval "$(pyenv init -)"
 1149  pip --version
 1150  source .venv/bin/activate
 1151  pip install -r requirements.txt
 1152  python -m ensurepip
 1153  deactivate
 1154  echo 'export PYENV_ROOT="$HOME/.pyenv"' >> ~/.bash_profile
 1155  echo 'export PATH="$PYENV_ROOT/bin:$PATH"' >> ~/.bash_profile
 1156  eval "$(pyenv init -)"
 1157  exec "$SHELL"
 1158  source .venv/bin/activate
 1159  pip install -r requirements.txt
 1160  pyenv versions
 1161  python --version
 1162  quit
 1163  deactivate
 1164  history
 1165  history | py
 1166  history | grep py
 1167  python --version
 1168  which python
 1169  pip
 1170  pip2
 1171  pip27
 1172  pip.27
 1173  history | grep pip
 1174  pip install virtualenv
 1175  witch pip
 1176  which pip
 1177  pyenv help which
 1178  pyenv which pip
 1179  witch pytohn
 1180  witch python
 1181  history
 1182  witch pip
 1183  vi ~/.bash_
 1184  vi ~/.bash_profile
 1185  pyenv version
 1186  pyenv versions
 1187  history | use
 1188  history | grep use
 1189  pip
 1190  pyenv activate 
 1191  pyenv virtualenvs
 1192  pyenv
 1193  pyenv versions
 1194  history | grep activate
 1195  pyenv activate 3.6.8
 1196  pyenv activate
 1197  pyenv which pip
 1198  pyenv activate
 1199  pyenv version
 1200  pyenv virtualenvs
 1201  eval "$(pyenv init -)"
 1202  eval "$(pyenv virtualenv-init -)"
 1203  brew install pyenv-virtualenv
 1204  source .venv/bin/activate
 1205  pip install -r requirements.txt
 1206  deactivate
 1207  ls -l 
 1208  eval "$(pyenv virtualenv-init -)"\n
 1209  pyenv virtualenv
 1210  pyenv version
 1211  python --version
 1212  witch python
 1213  pyenv virtualenvs
 1214  pyenv virtualenv 3.6.8 my-virtual-env-3.6.8
 1215  pyenv version
 1216  pyenv versions
 1217  pyenv virtualenv my-virtual-env-3.6.8
 1218  pyenv shell my-virtual-env-3.6.8
 1219  pip install -r requirements.txt
 1220  history | grep python
 1221  python billing-gcs-companies-ga.py 2019 04 06 y
 1222  pyenv deactivate
 1223  exit
 1224  history | grep gradle
 1225  gradle
 1226  ls -l
 1227  cd ..
 1228  ls -l
 1229  cd Projetos
 1230  ls l
 1231  ls -l
 1232  cd hydrogen/hydrogen.warehouse
 1233  ls -l
 1234  git status
 1235  git diff
 1236  ~/gradle/gradle-2.14/bin/gradle clean build
 1237  scala
 1238  git status
 1239  git diff src/main/scala/hydrogen/warehouse/utils/PartitionByUtils.scala
 1240  git diff
 1241  ~/gradle/gradle-2.14/bin/gradle clean build
 1242  git diff
 1243  git status
 1244  git diff src/main/scala/hydrogen/warehouse/utils/PartitionByUtils.scala
 1245  ~/gradle/gradle-2.14/bin/gradle clean build
 1246  ls -l\\ncd ~/Projetos/hydrogen/
 1247  ~/gradle/gradle-2.14/bin/gradle clean build
 1248  pwd
 1249  cd ~/Projetos/hydrogen/
 1250  ~/gradle/gradle-2.14/bin/gradle clean build
 1251  git status
 1252  git diff
 1253  git status
 1254  git log
 1255  git log --graph
 1256  git checkout -b feat/use-horizon-storage-api
 1257  git status
 1258  git add -p
 1259  git status
 1260  git add -i
 1261  git status
 1262  git commit -m "feat: use horizon storage api"
 1263  git push origin feat/use-horizon-storage-api 
 1264  ~/gradle/gradle-2.14/bin/gradle clean build
 1265  git status
 1266  git diff
 1267  git add .
 1268  git commit -m "fix: add missing tsFormat"
 1269  git push origin feat/use-horizon-storage-api 
 1270  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view/actionVersion=1.0
 1271  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view/actionVersion=1.0/year=2019
 1272  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view/actionVersion=1.0/year=2019/month=4
 1273  cd ..
 1274  ls -l
 1275  cd horizon-client-ios
 1276  git status
 1277  git diff
 1278  git remote -v
 1279  git remote set-url origin gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client-ios.git
 1280  git remote -v
 1281  git status
 1282  git pull
 1283  git diff
 1284  git checkout HorizonClient/Podfile.lock
 1285  git checkout HorizonClient/HorizonClient.xcodeproj/project.pbxproj
 1286  git status
 1287  git pull
 1288  git status
 1289  git pull
 1290  git checkout feat/adjust-protocol-fields 
 1291  git status
 1292  ./hdfs dfs -ls /user/actions/stream/tenant=g1
 1293  ./hdfs dfs -ls /user/actions/stream
 1294  ./hdfs dfs -ls /user/actions/stream/tenant=globoplay
 1295  ./hdfs dfs -ls /user/actions/stream/tenant=globoplay/actionContentType=pes
 1296  ./hdfs dfs -ls /user/actions/stream/tenant=globoplay/actionContentType=pes/actionId=pes-sync-id
 1297  git status
 1298  git add -p
 1299  git status
 1300  git diff
 1301  git log
 1302  git commit -m "refactor: rename constants to the same as other clients"
 1303  git stash 
 1304  git stash pop
 1305  git diff HorizonClient/HorizonClient/Sources/HorizonClient.swift
 1306  git diff
 1307  cd ..
 1308  ls -l\\nls -l
 1309  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client.git
 1310  cd horizon-client-ios
 1311  ls -l
 1312  cd HorizonClient
 1313  ls -l
 1314  pod install
 1315  cd HorizonClientTests
 1316  pod install
 1317  git status 
 1318  git pull
 1319  git status
 1320  git checkout HorizonAPITests.swift
 1321  git status
 1322  git diff
 1323  git status
 1324  git diff
 1325  git add -p
 1326  git status
 1327  git commit -m "fix: deviceGroup"
 1328  git status
 1329  git diff
 1330  git commit -m "feat: add referer field to events"
 1331  git add .
 1332  git commit -m "feat: add referer field to events"
 1333  git push origin feat/adjust-protocol-fields 
 1334  git status
 1335  git diff
 1336  git gui
 1337  history
 1338  git add -p
 1339  git status
 1340  git commit -m "feat: add referer field to events"
 1341  git push origin feat/adjust-protocol-fields 
 1342  git status
 1343  git diff
 1344  git diff --staged
 1345  git status
 1346  git add .
 1347  git commit -m "feat: add horizonEnvironment field to protocol"
 1348  git push origin feat/adjust-protocol-fields 
 1349  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view/actionVersion=1.0/year=2019/month=4
 1350  git status
 1351  cd ..
 1352  ls -l
 1353  git status
 1354  git add .
 1355  git commit -m "feat: add horizonEnvironment field to protocol"
 1356  git push origin feat/adjust-protocol-fields 
 1357  history | grep tsuru
 1358  history | grep make
 1359  ls -l
 1360  cd go/src/gitlab.globoi.com/bigdata/pipeline/horizon-track-service
 1361  git status
 1362  git pull
 1363  git diff
 1364  git add .
 1365  git commit -m "WIP"
 1366  git push origin chore/create-app-in-the-new-pool 
 1367  git status
 1368  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view/actionVersion=1.0/year=2019/month=4
 1369  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view/actionVersion=1.0/year=2019/month=4/day=10
 1370  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=feed/actionId=stories-slide-view/actionVersion=1.0/year=2019/month=4
 1371  git status
 1372  git diff
 1373  git diff HorizonClient/Sources/HorizonClient.swift
 1374  git status
 1375  vi HorizonClientTests/HorizonClientTests.swift
 1376  tsuru app-log -f -a horizon-track-prod
 1377  tsuru app-log -f -a horizon-track-service-prod
 1378  history
 1379  cd ..
 1380  ls -l
 1381  cd ..
 1382  ls -l
 1383  cd ..
 1384  cd ~/
 1385  ls -l
 1386  cd Projetos
 1387  ls -l
 1388  cd azkaban
 1389  ls -l
 1390  cd azkaban-gcp-billing
 1391  ls -l
 1392  pyenv virtualenvs
 1393  pyenv shell my-virtual-env-3.6.8
 1394  pyenv virtualenv my-virtual-env-3.6.8
 1395  pyenv shell my-virtual-env-3.6.8
 1396  pyenv init
 1397  pyenv shell my-virtual-env-3.6.8
 1398  eval "$(pyenv init -)"
 1399  pyenv shell my-virtual-env-3.6.8
 1400  pyenv virtualenv my-virtual-env-3.6.8
 1401  pip install -r requirements.txt
 1402  python billing-gcs-companies-ga.py 2019 04 12 y
 1403  pyenv deactivate
 1404  history | grep yarn
 1405  ./yarn application -list
 1406  ./yarn application -kill application_1539207608922_190524
 1407  git status
 1408  pwd
 1409  cd ..
 1410  git status
 1411  rm -rf HorizonClient/HorizonClientTests/HorizonClientTests.swift
 1412  git status
 1413  ls -l
 1414  ls -l HorizonClient/HorizonClientTests/HorizonClientTests.swift
 1415  ls -l
 1416  cd HorizonClient
 1417  ls -l
 1418  cd HorizonClientTests
 1419  ls -l
 1420  git status
 1421  cd ..
 1422  ls -l
 1423  git diff
 1424  git status
 1425  git diff HorizonClient/HorizonClientTests/TickerTests.swift
 1426  git checkout HorizonClient/HorizonClientTests/TickerTests.swift
 1427  git status
 1428  git diff
 1429  git add .
 1430  git status
 1431  git commit -m "feat: add flush function"
 1432  git status
 1433  git push origin feat/adjust-protocol-fields 
 1434  ./hdfs dfs -ls /
 1435  ./hdfs dfs -ls /user/actions/stream
 1436  ./hdfs dfs -ls /user/actions/stream/tenant=g1
 1437  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=notícia
 1438  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=not�cia
 1439  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=not�cia/actionId=quiz-personality-interaction
 1440  ./hdfs dfs -rm -rf /user/actions/stream/tenant=g1/actionContentType=not�cia
 1441  ./hdfs dfs -rm -r /user/actions/stream/tenant=g1/actionContentType=not�cia
 1442  ./hdfs dfs -ls /user/actions/stream
 1443  ./hdfs dfs -ls /user/actions/stream/tenant=player
 1444  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video
 1445  ./hdfs dfs -ls /user/actions/stream/tenant=g1
 1446  ./hdfs dfs -ls /user/actions/stream/tenant=player/
 1447  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=monitoring
 1448  ./hdfs dfs -ls /parquet
 1449  ./hdfs dfs -ls /parquet/videowatch
 1450  ./hdfs dfs -ls /parquet/videowatch/2019041420/
 1451  ./hdfs dfs -ls /parquet/videowatch/2019041420/201904142060
 1452  echo eyJob3Jpem9uQ2xpZW50VVVJRCI6IjM5YzI3Y2NlLTI4YWQtNGMzNy05ZWU5LTc5YTZlYWNlYzczMiIsImhvcml6b25DbGllbnRUZW5hbnQiOiJnMSIsImhvcml6b25DbGllbnRUcyI6MTU1NTM1NDUxMjUzNSwiaG9yaXpvbkNsaWVudFR5cGUiOiJqcyIsImhvcml6b25DbGllbnREZXZpY2VHcm91cCI6ImRlc2t0b3AiLCJob3Jpem9uRGlzcGF0Y2hOdW1iZXIiOjgsImhvcml6b25BY3Rpb25Db3VudGVyIjozMiwiaG9yaXpvbkVudmlyb25tZW50Ijoid2ViIiwiYWN0aW9ucyI6W3siaWQiOiJtdWx0aWNvbnRlbnQtY2h1bmstdmlldyIsInZlcnNpb24iOiIzLjAiLCJwcm9wZXJ0aWVzIjp7ImNodW5rVHlwZSI6InBhcmFncmFwaCIsImNodW5rUG9zaXRpb24iOjEzLCJjaHVua0ludGVyYWN0aW9uIjpmYWxzZSwidmlld2VkVGltZU1zIjozNTkxMCwid29yZENvdW50IjoxNSwiaGVpZ2h0Ijo2NCwid2lkdGgiOjY4MH0sInVybCI6Imh0dHBzOi8vZzEuZ2xvYm8uY29tL211bmRvL25vdGljaWEvMjAxOS8wNC8xNS9mb2dvLW5hLWlncmVqYS1kZS1ub3RyZS1kYW1lLWVtLXBhcmlzLWUtcmVsYXRhZG8tZW0tcmVkZXMtc29jaWFpcy5naHRtbCIsImFjdGlvblRzIjoxNTU1MzU0NTAyODg2LCJob3Jpem9uQ2xpZW50VmVyc2lvbiI6IjEuMC4zIiwiaG9yaXpvbkNsaWVudFJlZmVyZXIiOiJodHRwczovL2cxLmdsb2JvLmNvbS8iLCJjb250ZW50VHlwZSI6Im11bHRpY29udGVudCJ9LHsiaWQiOiJtdWx0aWNvbnRlbnQtY2h1bmstdmlldyIsInZlcnNpb24iOiIzLjAiLCJwcm9wZXJ0aWVzIjp7ImNodW5rVHlwZSI6ImFkcyIsImNodW5rUG9zaXRpb24iOjE0LCJjaHVua0ludGVyYWN0aW9uIjp0cnVlLCJ2aWV3ZWRUaW1lTXMiOjM1OTEwLCJ3b3JkQ291bnQiOjAsImhlaWdodCI6MCwid2lkdGgiOjk3MH0sInVybCI6Imh0dHBzOi8vZzEuZ2xvYm8uY29tL211bmRvL25vdGljaWEvMjAxOS8wNC8xNS9mb2dvLW5hLWlncmVqYS1kZS1ub3RyZS1kYW1lLWVtLXBhcmlzLWUtcmVsYXRhZG8tZW0tcmVkZXMtc29jaWFpcy5naHRtbCIsImFjdGlvblRzIjoxNTU1MzU0NTAyODg3LCJob3Jpem9uQ2xpZW50VmVyc2lvbiI6IjEuMC4zIiwiaG9yaXpvbkNsaWVudFJlZmVyZXIiOiJodHRwczovL2cxLmdsb2JvLmNvbS8iLCJjb250ZW50VHlwZSI6Im11bHRpY29udGVudCJ9LHsiaWQiOiJtdWx0aWNvbnRlbnQtY2h1bmstdmlldyIsInZlcnNpb24iOiIzLjAiLCJwcm9wZXJ0aWVzIjp7ImNodW5rVHlwZSI6InZpZGVvIiwiY2h1bmtQb3NpdGlvbiI6MTUsImNodW5rSW50ZXJhY3Rpb24iOnRydWUsInZpZXdlZFRpbWVNcyI6MzU5MTEsIndvcmRDb3VudCI6MCwiaGVpZ2h0IjozOTYsIndpZHRoIjo2ODB9LCJ1cmwiOiJodHRwczovL2cxLmdsb2JvLmNvbS9tdW5kby9ub3RpY2lhLzIwMTkvMDQvMTUvZm9nby1uYS1pZ3JlamEtZGUtbm90cmUtZGFtZS1lbS1wYXJpcy1lLXJlbGF0YWRvLWVtLXJlZGVzLXNvY2lhaXMuZ2h0bWwiLCJhY3Rpb25UcyI6MTU1NTM1NDUwMjg4OCwiaG9yaXpvbkNsaWVudFZlcnNpb24iOiIxLjAuMyIsImhvcml6b25DbGllbnRSZWZlcmVyIjoiaHR0cHM6Ly9nMS5nbG9iby5jb20vIiwiY29udGVudFR5cGUiOiJtdWx0aWNvbnRlbnQifSx7ImlkIjoibXVsdGljb250ZW50LXZpZXciLCJ2ZXJzaW9uIjoiNC4wIiwicHJvcGVydGllcyI6eyJmZWVkU2VlbiI6ZmFsc2UsInRpbWVPbk11bHRpY29udGVudCI6MzkzODh9LCJ1cmwiOiJodHRwczovL2cxLmdsb2JvLmNvbS9tdW5kby9ub3RpY2lhLzIwMTkvMDQvMTUvZm9nby1uYS1pZ3JlamEtZGUtbm90cmUtZGFtZS1lbS1wYXJpcy1lLXJlbGF0YWRvLWVtLXJlZGVzLXNvY2lhaXMuZ2h0bWwiLCJhY3Rpb25UcyI6MTU1NTM1NDUwMzA4OSwiaG9yaXpvbkNsaWVudFZlcnNpb24iOiIxLjAuMyIsImhvcml6b25DbGllbnRSZWZlcmVyIjoiaHR0cHM6Ly9nMS5nbG9iby5jb20vIiwiY29udGVudFR5cGUiOiJtdWx0aWNvbnRlbnQifV19 | base64
 1453  echo eyJob3Jpem9uQ2xpZW50VVVJRCI6IjM5YzI3Y2NlLTI4YWQtNGMzNy05ZWU5LTc5YTZlYWNlYzczMiIsImhvcml6b25DbGllbnRUZW5hbnQiOiJnMSIsImhvcml6b25DbGllbnRUcyI6MTU1NTM1NDUxMjUzNSwiaG9yaXpvbkNsaWVudFR5cGUiOiJqcyIsImhvcml6b25DbGllbnREZXZpY2VHcm91cCI6ImRlc2t0b3AiLCJob3Jpem9uRGlzcGF0Y2hOdW1iZXIiOjgsImhvcml6b25BY3Rpb25Db3VudGVyIjozMiwiaG9yaXpvbkVudmlyb25tZW50Ijoid2ViIiwiYWN0aW9ucyI6W3siaWQiOiJtdWx0aWNvbnRlbnQtY2h1bmstdmlldyIsInZlcnNpb24iOiIzLjAiLCJwcm9wZXJ0aWVzIjp7ImNodW5rVHlwZSI6InBhcmFncmFwaCIsImNodW5rUG9zaXRpb24iOjEzLCJjaHVua0ludGVyYWN0aW9uIjpmYWxzZSwidmlld2VkVGltZU1zIjozNTkxMCwid29yZENvdW50IjoxNSwiaGVpZ2h0Ijo2NCwid2lkdGgiOjY4MH0sInVybCI6Imh0dHBzOi8vZzEuZ2xvYm8uY29tL211bmRvL25vdGljaWEvMjAxOS8wNC8xNS9mb2dvLW5hLWlncmVqYS1kZS1ub3RyZS1kYW1lLWVtLXBhcmlzLWUtcmVsYXRhZG8tZW0tcmVkZXMtc29jaWFpcy5naHRtbCIsImFjdGlvblRzIjoxNTU1MzU0NTAyODg2LCJob3Jpem9uQ2xpZW50VmVyc2lvbiI6IjEuMC4zIiwiaG9yaXpvbkNsaWVudFJlZmVyZXIiOiJodHRwczovL2cxLmdsb2JvLmNvbS8iLCJjb250ZW50VHlwZSI6Im11bHRpY29udGVudCJ9LHsiaWQiOiJtdWx0aWNvbnRlbnQtY2h1bmstdmlldyIsInZlcnNpb24iOiIzLjAiLCJwcm9wZXJ0aWVzIjp7ImNodW5rVHlwZSI6ImFkcyIsImNodW5rUG9zaXRpb24iOjE0LCJjaHVua0ludGVyYWN0aW9uIjp0cnVlLCJ2aWV3ZWRUaW1lTXMiOjM1OTEwLCJ3b3JkQ291bnQiOjAsImhlaWdodCI6MCwid2lkdGgiOjk3MH0sInVybCI6Imh0dHBzOi8vZzEuZ2xvYm8uY29tL211bmRvL25vdGljaWEvMjAxOS8wNC8xNS9mb2dvLW5hLWlncmVqYS1kZS1ub3RyZS1kYW1lLWVtLXBhcmlzLWUtcmVsYXRhZG8tZW0tcmVkZXMtc29jaWFpcy5naHRtbCIsImFjdGlvblRzIjoxNTU1MzU0NTAyODg3LCJob3Jpem9uQ2xpZW50VmVyc2lvbiI6IjEuMC4zIiwiaG9yaXpvbkNsaWVudFJlZmVyZXIiOiJodHRwczovL2cxLmdsb2JvLmNvbS8iLCJjb250ZW50VHlwZSI6Im11bHRpY29udGVudCJ9LHsiaWQiOiJtdWx0aWNvbnRlbnQtY2h1bmstdmlldyIsInZlcnNpb24iOiIzLjAiLCJwcm9wZXJ0aWVzIjp7ImNodW5rVHlwZSI6InZpZGVvIiwiY2h1bmtQb3NpdGlvbiI6MTUsImNodW5rSW50ZXJhY3Rpb24iOnRydWUsInZpZXdlZFRpbWVNcyI6MzU5MTEsIndvcmRDb3VudCI6MCwiaGVpZ2h0IjozOTYsIndpZHRoIjo2ODB9LCJ1cmwiOiJodHRwczovL2cxLmdsb2JvLmNvbS9tdW5kby9ub3RpY2lhLzIwMTkvMDQvMTUvZm9nby1uYS1pZ3JlamEtZGUtbm90cmUtZGFtZS1lbS1wYXJpcy1lLXJlbGF0YWRvLWVtLXJlZGVzLXNvY2lhaXMuZ2h0bWwiLCJhY3Rpb25UcyI6MTU1NTM1NDUwMjg4OCwiaG9yaXpvbkNsaWVudFZlcnNpb24iOiIxLjAuMyIsImhvcml6b25DbGllbnRSZWZlcmVyIjoiaHR0cHM6Ly9nMS5nbG9iby5jb20vIiwiY29udGVudFR5cGUiOiJtdWx0aWNvbnRlbnQifSx7ImlkIjoibXVsdGljb250ZW50LXZpZXciLCJ2ZXJzaW9uIjoiNC4wIiwicHJvcGVydGllcyI6eyJmZWVkU2VlbiI6ZmFsc2UsInRpbWVPbk11bHRpY29udGVudCI6MzkzODh9LCJ1cmwiOiJodHRwczovL2cxLmdsb2JvLmNvbS9tdW5kby9ub3RpY2lhLzIwMTkvMDQvMTUvZm9nby1uYS1pZ3JlamEtZGUtbm90cmUtZGFtZS1lbS1wYXJpcy1lLXJlbGF0YWRvLWVtLXJlZGVzLXNvY2lhaXMuZ2h0bWwiLCJhY3Rpb25UcyI6MTU1NTM1NDUwMzA4OSwiaG9yaXpvbkNsaWVudFZlcnNpb24iOiIxLjAuMyIsImhvcml6b25DbGllbnRSZWZlcmVyIjoiaHR0cHM6Ly9nMS5nbG9iby5jb20vIiwiY29udGVudFR5cGUiOiJtdWx0aWNvbnRlbnQifV19 | base64 -D
 1454  git pull
 1455  git merge --abort
 1456  git pull
 1457  git status
 1458  git merge --abort
 1459  git status
 1460  git log
 1461  git pull --rebase
 1462  git stash
 1463  git pull --rebase
 1464  git stash pop
 1465  git status
 1466  git log
 1467  git status
 1468  git diff
 1469  history | grep git
 1470  git add -p
 1471  git status
 1472  git commit -m "fix: variable name"
 1473  git status
 1474  git diff
 1475  git add -p
 1476  git status
 1477  git commit -m "docs: typo on documentation"
 1478  git status
 1479  git push origin feat/adjust-protocol-fields 
 1480  git status
 1481  ./hdfs dfs -ls /user/actions/stream/tenant=player
 1482  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/
 1483  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data
 1484  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data/actionVersion=1.0
 1485  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data/actionVersion=1.0/year=2019
 1486  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data/actionVersion=1.0/year=2019/month=4
 1487  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data/actionVersion=1.0/year=2019/month=4/day=15
 1488  ./hdfs dfs -ls /user/actions/stream/tenant=player
 1489  ./hdfs dfs -ls /user/actions/stream/tenant=player/*/
 1490  ./hdfs dfs -ls /user/actions/stream/tenant=player/*
 1491  ./hdfs dfs -ls -R /user/actions/stream/tenant=player/ | grep player-environment
 1492  ./hdfs dfs -ls -R /user/actions/stream/tenant=player/actionContentType=ad
 1493  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=ad
 1494  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video
 1495  export HADOOP_USER_NAME=hdfs
 1496  ./hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video
 1497  ./hdfs dfs -ls /user/actions/stream/tenant=g1
 1498  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=notícia
 1499  ./hdfs dfs -rm -rf /user/actions/stream/tenant=g1/actionContentType=notícia
 1500  ./hdfs dfs -rm -r /user/actions/stream/tenant=g1/actionContentType=notícia
 1501  export HADOOP_USER_NAME=hadoop
 1502  ./hdfs dfs -rm -r /user/actions/stream/tenant=g1/actionContentType=notícia
 1503  ./hdfs dfs -ls /user/actions/stream/tenant=g1
 1504  ./hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=not�cia
 1505  ./hdfs dfs -rm -r /user/actions/stream/tenant=g1/actionContentType=not�cia
 1506  git status
 1507  ls -l
 1508  git diff HorizonClient/HorizonClient/Sources/Dispatcher.swift
 1509  git diff
 1510  git status
 1511  git diff
 1512  git status
 1513  git diff HorizonClient/HorizonClient/Sources/EventsRepository.swift
 1514  brew install swiftlint
 1515  git status
 1516  git diff
 1517  git add -p
 1518  git commit -m "fix: remove recursion on flush method"
 1519  git status
 1520  git add -p
 1521  git commit -m "feat: events should't expired"
 1522  git status
 1523  git diff
 1524  git checkout HorizonClient/HorizonClientTests/DispatcherTests.swift
 1525  git status
 1526  git diff
 1527  git checkout HorizonClient/HorizonClientSample/ViewController.swift
 1528  git status
 1529  git diff
 1530  git status
 1531  git push origin feat/adjust-protocol-fields 
 1532  ls -l
 1533  touch .swiftlint.yml
 1534  ls -l
 1535  cd HorizonClient
 1536  ls -l
 1537  cd ..
 1538  ls -l
 1539  cd HorizonClient/HorizonClient
 1540  ls -l
 1541  pwd
 1542  ls -l
 1543  cd Sources
 1544  ls -l
 1545  cd ..
 1546  ls -l
 1547  cd ..
 1548  ls -l
 1549  cd ..
 1550  cp .swiftlint.yml HorizonClient
 1551  cd HorizonClient
 1552  git status
 1553  git diff
 1554  git status
 1555  git diff
 1556  git status
 1557  git diff
 1558  git checkout HorizonClient/Sources/EventsRepository.swift
 1559  git status
 1560  git diff
 1561  git checkout HorizonClientTests/DispatcherTests.swift
 1562  git status
 1563  git diff
 1564  git status
 1565  git diff
 1566  git status
 1567  git diff
 1568  git git status
 1569  git diff HorizonClient/Sources/HorizonClient.swift
 1570  git checkout HorizonClient/Sources/HorizonClient.swift
 1571  git status
 1572  cd ..
 1573  ls -l
 1574  git status
 1575  rm -rf .swiftlint.yml
 1576  git status
 1577  git diff HorizonClient/HorizonClientSample/ViewController.swift
 1578  git diff
 1579  git diff HorizonClient/HorizonClient/Sources/EventsStorage.swift
 1580  git status
 1581  git diff HorizonClient/HorizonClient/Sources/Dispatcher.swift
 1582  git status
 1583  git diff HorizonClient/HorizonClient/Sources/Dispatcher.swift
 1584  git status
 1585  git add HorizonClient/HorizonClient/Sources/Dispatcher.swift
 1586  git log
 1587  git commit -m "fix: revert to old implementation of flush method"
 1588  git push origin feat/adjust-protocol-fields 
 1589  git status
 1590  git diff
 1591  git status
 1592  git checkout HorizonClient/HorizonClient/Sources/EventsStorage.swift
 1593  git status
 1594  git diff
 1595  git status
 1596  git diff
 1597  git status
 1598  git diff HorizonClient/HorizonClient/Sources/EventJSONCoder.swift
 1599  git checkout HorizonClient/HorizonClient/Sources/EventJSONCoder.swift
 1600  git status
 1601  git diff
 1602  git diff HorizonClient/HorizonClient/Sources/HorizonAPI.swift
 1603  git diff
 1604  cd ,,
 1605  cd ..
 1606  ls -l
 1607  cd ..
 1608  ls -l
 1609  cd horizon-schemas
 1610  git diff
 1611  git pull
 1612  git status
 1613  git pull
 1614  cd ~/go/src/gitlab.globoi.com/bigdata/pipeline/horizon-schemas-service/
 1615  ls -l
 1616  git status
 1617  git diff
 1618  git pull
 1619  git status
 1620  git diff
 1621  ls -l
 1622  cd hzs
 1623  ls -l
 1624  cd schemas
 1625  git status
 1626  git submodule update
 1627  git status
 1628  git diff
 1629  cd ..
 1630  git status
 1631  git schemas
 1632  cd schemas
 1633  git fetch
 1634  git merge origin/master 
 1635  git status
 1636  cd ..
 1637  ls -l
 1638  cd ..
 1639  ls -l
 1640  git diff
 1641  git status
 1642  make tsuru-deploy-qa
 1643  ls -l
 1644  git submodule-update
 1645  make submodule-update
 1646  ls -l
 1647  cd hzs
 1648  git status
 1649  cd schemas
 1650  ls -l
 1651  git status
 1652  cd ..
 1653  ls -l
 1654  cd schemas
 1655  git status
 1656  cd ..
 1657  pwd
 1658  cd ..
 1659  ls -l
 1660  git status
 1661  git stats
 1662  git status
 1663  git checkout -b "feat/update-player-errors-schemas"
 1664  git status
 1665  git diff
 1666  git add hzs/version.go
 1667  git add CHANGELOG.md
 1668  git add hzs/schemas
 1669  git status
 1670  git commit -m "chore: add playerId field to player-errors schema"
 1671  git push origin feat/update-player-errors-schemas 
 1672  cd ..
 1673  cd horizon-schemas-service
 1674  git checkout master
 1675  git pull
 1676  git status
 1677  history | grep tag
 1678  git tag v0.16.0
 1679  git push --tags
 1680  make tsuru-deploy-prod
 1681  cd ..
 1682  ls -l
 1683  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-legacy-stream.git
 1684  history | tail
 1685  tsuru app-log -f -a horizon-legacy-stream-prod
 1686  ls -l
 1687  cd horizon-legacy-stream
 1688  git status
 1689  git pull
 1690  code
 1691  code .
 1692  go test
 1693  ls -l
 1694  cd hls
 1695  go test
 1696  cd c..
 1697  cd ..
 1698  go list -m all
 1699  go -version
 1700  go --version
 1701  go -v
 1702  go help
 1703  go help versiomn
 1704  go help version
 1705  go version
 1706  go list -m all
 1707  go mod
 1708  ls -l
 1709  vi main.go
 1710  go mod
 1711  go mod edit
 1712  go help mod edit
 1713  git status
 1714  git checkout go.mod
 1715  git status
 1716  export GO111MODULE=on
 1717  go test all
 1718  vi ~/.gitconfig
 1719  go test all
 1720  go list -m all
 1721  go get github.com/Shopify/sarama@1.22.0
 1722  go get github.com/Shopify/sarama@v1.22.0
 1723  go list -m all
 1724  git status
 1725  git diff
 1726  go list -m -versions github.com/Shopify/sarama
 1727  go mod vendor
 1728  git status
 1729  pwd
 1730  history
 1731  git status
 1732  make test
 1733  make run
 1734  make tools
 1735  make run
 1736  realize
 1737  go get github.com/oxequa/realize
 1738  realize
 1739  export PATH="$GOPATH/bin:$PATH"
 1740  realize
 1741  echo $GOPATH
 1742  vi ~/.bash_profile
 1743  source ~/.bash_profile
 1744  vi ~/.zshrc
 1745  realize
 1746  make run
 1747  tsuru app-log -f -a horizon-track-qa
 1748  cd ~/
 1749  ls
 1750  cd Projetos
 1751  ls
 1752  mkdir scripts-marotos
 1753  cd scripts
 1754  ls
 1755  popd
 1756  ls
 1757  mv scripts/* scripts-marotos
 1758  ls
 1759  rm scripts
 1760  rm -r scripts
 1761  ls
 1762  cd scripts-marotos
 1763  ls
 1764  virtualenv .venv
 1765  pyenv virtualenv scripts-marotos
 1766  pyenv virtualenv 
 1767  pyenv 
 1768  pyenv help virtualenv
 1769  pyenv virtualenv 3.6.8 scripts-marotos
 1770  pyenv virtualenvs
 1771  pyenv virtualenv scripts-marotos
 1772  pyenv uso scripts-marotos
 1773  pyenv use scripts-marotos
 1774  history | grep pyenv
 1775  pyenv activate scripts-marotos
 1776  vi ~/.bash_profile
 1777  source ~/.bash_profile
 1778  pyenv activate scripts-marotos
 1779  echo "scripts-marotos" > .python-version
 1780  ls
 1781  ls -a
 1782  cat .python-version
 1783  cd ..
 1784  deactivate
 1785  pyenv deactivate
 1786  cd scripts-marotos
 1787  cd ..
 1788  cd scripts-marotos
 1789  pip install kafka
 1790  python kafka-consumer.py
 1791  code .
 1792  python kafka-consumer.py
 1793  python kafka-consumer.py qa hzt.g1
 1794  cd Projetos/scripts-marotos
 1795  curl 'https://horizon-track.qa.globoi.com/auth-session/activity/g1/horizon-pageview?object=https%3A%2F%2Fg1.globo.com%2F&Referrer=&tags=&client_version=0.3.11' -H 'Referer: https://g1.globo.com/' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' --compressed
 1796  python kafka-consumer.py qa hzt-qa.legacy.horizon-pageview
 1797  python kafka-consumer.py qa activity-local_horizon-pageview
 1798  curl 'https://horizon-track.qa.globoi.com/auth-session/activity/g1/horizon-pageview?object=https%3A%2F%2Fg1.globo.com%2F&Referrer=&tags=&client_version=0.3.11' -H 'Referer: https://g1.globo.com/' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' --compressed
 1799  make run
 1800  curl 'https://horizon-track.qa.globoi.com/auth-session/activity/g1/horizon-pageview?object=https%3A%2F%2Fg1.globo.com%2F&Referrer=&tags=&client_version=0.3.11' -H 'Referer: https://g1.globo.com/' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' --compressed
 1801  make run
 1802  ls -l
 1803  cd go
 1804  ls -l
 1805  cd src/gitlab.globoi.com/bigdata/pipeline/horizon-legacy-stream
 1806  make run
 1807  export GO111MODULE=on
 1808  make run
 1809  curl 'https://horizon-track.qa.globoi.com/auth-session/activity/g1/horizon-pageview?object=https%3A%2F%2Fg1.globo.com%2F&Referrer=&tags=&client_version=0.3.11' -H 'Referer: https://g1.globo.com/' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' --compressed
 1810  make run
 1811  ps aux | grep horizon-legacy
 1812  kill -15 47759
 1813  kill -3 47759
 1814  kill -2 47759
 1815  ps aux | grep horizon-legacy
 1816  kill -15 47644
 1817  kill -9 47644
 1818  kill -9 47759
 1819  ps aux | grep horizon-legacy-stream
 1820  kill -9 47776
 1821  ps aux | grep go
 1822  ps aux | grep horizon-legacy-stream
 1823  ps aux | grep realise
 1824  ps aux | grep realize
 1825  kill -15 47765
 1826  make run
 1827  ps aux | grep realize
 1828  kill -2 48085
 1829  make run
 1830  ps aux | grep horizon-legacy
 1831  ps aux | grep realize
 1832  make run
 1833  curl 'https://horizon-track.qa.globoi.com/auth-session/activity/g1/horizon-pageview?object=https%3A%2F%2Fg1.globo.com%2F&Referrer=&tags=&client_version=0.3.11' -H 'Referer: https://g1.globo.com/' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' --compressed
 1834  ssh 00299134@portal.inf.ufrgs.br -L 3128:power-proxy.inf.ufrgs.br:3128
 1835  ls -l
 1836  pdw
 1837  pwd
 1838  cd ..
 1839  ls -l
 1840  cd ..
 1841  ls -l
 1842  cd Projetos
 1843  ls -l
 1844  cd azkaban
 1845  ls -l
 1846  cd pipeline-horizon-stream-ingest
 1847  git status
 1848  git checkout master
 1849  git pull
 1850  git status
 1851  git checkout -b fix/ge-stream-delayed
 1852  git status
 1853  git diff
 1854  git status
 1855  git diff
 1856  git add .
 1857  git commit -m "fix: increase maxRatePerPartition in hzt.ge job"
 1858  git status
 1859  git push origin fix/ge-stream-delayed 
 1860  exit
 1861  make zip
 1862  exit
 1863  ls -l
 1864  cd spark-2.4.0-bin-hadoop2.7
 1865  alias hadoop-use-prod='export HADOOP_CONF_DIR=~/configs/conf-prod'
 1866  cd ..
 1867  ls -l
 1868  cd hadoop-2.7.3
 1869  ls -l
 1870  ls -l .bin/
 1871  ls -l bin/
 1872  bin/yarn application -list
 1873  export HADOOP_CONF_DIR=~/configs/conf-prod
 1874  bin/yarn application -list
 1875  bin/yarn application -list | grep application_1539207608922_187343
 1876  bin/yarn application -kill application_1539207608922_187343
 1877  git status
 1878  cd ..
 1879  ls -l
 1880  cd azkaban
 1881  ls -l
 1882  cd pipeline-horizon-stream-ingest
 1883  git status
 1884  git diff
 1885  git status
 1886  make zip
 1887  bin/yarn application -list | grep application_1539207608922_205468
 1888  bin/yarn application -kill application_1539207608922_205468
 1889  make zip
 1890  bin/yarn application -kill application_1539207608922_205574
 1891  git status
 1892  git pull
 1893  git status .realize.yaml
 1894  git diff .realize.yaml
 1895  git checkout -b refactor/upgrade-sarama-version
 1896  git status
 1897  git diff .realize.yaml
 1898  git add .realize.yaml
 1899  git diff .realize.yaml
 1900  git commit -m "fix: change topic prefix name"
 1901  git status
 1902  git diff CHANGELOG.md
 1903  git diff vendor
 1904  git diff hls
 1905  git add .
 1906  git commit -m "refactor: upgrade sarama version to replace sarama-cluster"
 1907  git status
 1908  git push origin refactor/upgrade-sarama-version 
 1909  cd ..
 1910  ls -l
 1911  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-stream-processor.git
 1912  cd horizon-stream-processor
 1913  code
 1914  code .
 1915  history
 1916  ls -l
 1917  history
 1918  history | grep go
 1919  go list -m all
 1920  go get github.com/Shopify/sarama@v1.22.0
 1921  git status
 1922  history | grep go
 1923  go mod vendor
 1924  git status
 1925  ls -l
 1926  cd ..
 1927  ls -l
 1928  cd horizon-legacy-stream
 1929  make test
 1930  code .
 1931  git status
 1932  git diff 
 1933  make test
 1934  cd ..
 1935  ls -l
 1936  cd horizon-stream-processor
 1937  make test
 1938  git status
 1939  git diff
 1940  ls -l
 1941  cd ..
 1942  ls -l
 1943  cd .
 1944  cd ..
 1945  ls -l
 1946  git clone gitlab@gitlab.globoi.com:leonardo.neuwald/test-repo.git
 1947  cd test-repo
 1948  touch file1
 1949  vi file1
 1950  git add .
 1951  git commit -m "test commit"
 1952  git push origin master
 1953  git checkout -b branch1
 1954  vi file1
 1955  git add .
 1956  git commit -m "branch commit"
 1957  git push origin branch1 
 1958  git rebase -i HEAD~2\n
 1959  git log
 1960  git rebase -i HEAD~2\n
 1961  git log
 1962  git push origin +branch1 
 1963  ls -l
 1964  cd ..
 1965  l s-l
 1966  ls -l
 1967  cd azkaban
 1968  ls -l
 1969  cd pipeline-horizon-stream-ingest
 1970  git status
 1971  git diff
 1972  history
 1973  git log
 1974  git rebase -i HEAD~2
 1975  git status
 1976  git checkout jobs/horizon-track-event-stream-flow/hzt.ge.job
 1977  git statu
 1978  git status
 1979  git rebase -i HEAD~2
 1980  git log
 1981  git push origin +fix/ge-stream-delayed 
 1982  git status
 1983  git diff
 1984  git add .
 1985  git commit -m "fix: increase maxRatePerPartition and memory in hzt.ge job"
 1986  git push origin fix/ge-stream-delayed 
 1987  make zip
 1988  bin/yarn application -list | grep application_1539207608922_205606
 1989  bin/yarn application -kill application_1539207608922_205606
 1990  cd ..
 1991  ls -l
 1992  cd ..
 1993  ls -l
 1994  cd azkaban-gcp-billing
 1995  ls -l
 1996  history
 1997  pyenv virtualenvs
 1998  history | grep pyenv
 1999  pyenv virtualenv gpc-billing
 2000  eval "$(pyenv init -)"
 2001  pyenv virtualenv gpc-billing
 2002  pyenv virtualenv 3.6.8 gpc-billing
 2003  pyenv use gpc-billing
 2004  pyenv activate gpc-billing
 2005  exit
 2006  ls -l
 2007  pip install -r requirements.txt
 2008  git status
 2009  python billing-gcs-companies-bigdata.py 2019 04 24 y
 2010  pyenv deactivate gpc-billing
 2011  cd ..
 2012  ls -l
 2013  cd pipeline-horizon-stream-ingest
 2014  cd ..
 2015  ls -l
 2016  cd ..
 2017  ls -l
 2018  cd horizon-legacy-stream
 2019  git status
 2020  git diff
 2021  history | grep git
 2022  make test
 2023  git status
 2024  git add .
 2025  git commit -m "refactor: rename variables"
 2026  git push origin refactor/upgrade-sarama-version 
 2027  git status
 2028  cd ..
 2029  ls -l
 2030  git status
 2031  cd horizon-stream-processor
 2032  git status
 2033  git checkout -b refactor/upgrade-sarama-version
 2034  git status
 2035  make test
 2036  make run
 2037  history | grep curl
 2038  curl 'https://horizon-track.qa.globo.com/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundary7Jw1LQ1GgO4OcArb' --data-binary $'------WebKitFormBoundary7Jw1LQ1GgO4OcArb\r\nContent-Disposition: form-data; name="data"\r\n\r\neyJob3Jpem9uQ2xpZW50VVVJRCI6IjAzMzM1YzAxLThhNzUtNGRmMS1iYmQ4LWM3ZmUwZWQxMTk4NiIsImhvcml6b25DbGllbnRUZW5hbnQiOiJnMSIsImhvcml6b25DbGllbnRUcyI6MTU1NjIzMTI1NDc5NiwiaG9yaXpvbkNsaWVudFR5cGUiOiJqcyIsImhvcml6b25DbGllbnREZXZpY2VHcm91cCI6ImRlc2t0b3AiLCJob3Jpem9uRGlzcGF0Y2hOdW1iZXIiOjMsImhvcml6b25BY3Rpb25Db3VudGVyIjozLCJob3Jpem9uRW52aXJvbm1lbnQiOiJ3ZWIiLCJhY3Rpb25zIjpbeyJpZCI6ImdlbmVyaWMtZ2VvbG9jYXRpb24tYXV0aG9yaXphdGlvbiIsInZlcnNpb24iOiIxLjAiLCJwcm9wZXJ0aWVzIjp7Im5hbWUiOiJQZXJtaXNzw6NvIE5lZ2FkYSIsInN0YXR1cyI6IkRlbmllZCJ9LCJ1cmwiOiJodHRwczovL2cxLmdsb2JvLmNvbS8iLCJhY3Rpb25UcyI6MTU1NjIzMTI0OTEwOCwiaG9yaXpvbkNsaWVudFZlcnNpb24iOiIxLjAuMyIsImhvcml6b25DbGllbnRSZWZlcmVyIjoiIiwiY29udGVudFR5cGUiOiJob21lLWFwaSJ9XX0=\r\n------WebKitFormBoundary7Jw1LQ1GgO4OcArb\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundary7Jw1LQ1GgO4OcArb--\r\n' --compressed ;
 2039  curl 'https://horizon-track.qa.globoi.com/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundary7Jw1LQ1GgO4OcArb' --data-binary $'------WebKitFormBoundary7Jw1LQ1GgO4OcArb\r\nContent-Disposition: form-data; name="data"\r\n\r\neyJob3Jpem9uQ2xpZW50VVVJRCI6IjAzMzM1YzAxLThhNzUtNGRmMS1iYmQ4LWM3ZmUwZWQxMTk4NiIsImhvcml6b25DbGllbnRUZW5hbnQiOiJnMSIsImhvcml6b25DbGllbnRUcyI6MTU1NjIzMTI1NDc5NiwiaG9yaXpvbkNsaWVudFR5cGUiOiJqcyIsImhvcml6b25DbGllbnREZXZpY2VHcm91cCI6ImRlc2t0b3AiLCJob3Jpem9uRGlzcGF0Y2hOdW1iZXIiOjMsImhvcml6b25BY3Rpb25Db3VudGVyIjozLCJob3Jpem9uRW52aXJvbm1lbnQiOiJ3ZWIiLCJhY3Rpb25zIjpbeyJpZCI6ImdlbmVyaWMtZ2VvbG9jYXRpb24tYXV0aG9yaXphdGlvbiIsInZlcnNpb24iOiIxLjAiLCJwcm9wZXJ0aWVzIjp7Im5hbWUiOiJQZXJtaXNzw6NvIE5lZ2FkYSIsInN0YXR1cyI6IkRlbmllZCJ9LCJ1cmwiOiJodHRwczovL2cxLmdsb2JvLmNvbS8iLCJhY3Rpb25UcyI6MTU1NjIzMTI0OTEwOCwiaG9yaXpvbkNsaWVudFZlcnNpb24iOiIxLjAuMyIsImhvcml6b25DbGllbnRSZWZlcmVyIjoiIiwiY29udGVudFR5cGUiOiJob21lLWFwaSJ9XX0=\r\n------WebKitFormBoundary7Jw1LQ1GgO4OcArb\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundary7Jw1LQ1GgO4OcArb--\r\n' --compressed ;
 2040  git status
 2041  git add .realize.yaml
 2042  git commit -m "fix: change topic prefix name"
 2043  git status
 2044  git add .
 2045  git commit -m "refactor: upgrade sarama version to replace sarama-cluster"
 2046  git status
 2047  git push origin refactor/upgrade-sarama-version 
 2048  cd ..
 2049  ls -l
 2050  bin/yarn application -list | grep application_1539207608922_200101
 2051  bin/yarn application -kill application_1539207608922_200101
 2052  ls -l
 2053  cd horizon_avro_stream
 2054  git status
 2055  git pull
 2056  l s-l
 2057  ls -l
 2058  cd horizon-
 2059  cd horizon-track-service
 2060  git status
 2061  git checkout master
 2062  git pull
 2063  git status
 2064  code .
 2065  git status
 2066  make test
 2067  make run
 2068  curl 'http://localhost:9002/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryfeXbC29klT6zvBnu' --data-binary $'------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu--\r\n' --compressed
 2069  curl -o 'http://localhost:9002/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryfeXbC29klT6zvBnu' --data-binary $'------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu--\r\n' --compressed
 2070  curl -o - 'http://localhost:9002/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryfeXbC29klT6zvBnu' --data-binary $'------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu--\r\n' --compressed
 2071  curl -vvv - 'http://localhost:9002/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryfeXbC29klT6zvBnu' --data-binary $'------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu--\r\n' --compressed
 2072  curl -vvv 'http://localhost:9002/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryfeXbC29klT6zvBnu' --data-binary $'------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu--\r\n' --compressed
 2073  curl -vvv 'http://localhost:9002/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Cookies: hsid=;' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryfeXbC29klT6zvBnu' --data-binary $'------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu--\r\n' --compressed
 2074  curl -vvv 'http://localhost:9002/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Cookie: hsid=;' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryfeXbC29klT6zvBnu' --data-binary $'------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryfeXbC29klT6zvBnu--\r\n' --compressed
 2075  curl -vvv 'http://localhost:9002/'
 2076  curl -vvv 'http://localhost:9002/healthcheck'
 2077  git status
 2078  git diff
 2079  git checkout -b "feat/cookies-for-route"
 2080  git status
 2081  git add CHANGELOG.md hzt/server.go hzt/version.go
 2082  git status
 2083  git add CHANGELOG.md
 2084  git commit -m "feat: removed cookies generation to the routes /metric, /helthcheck and /"
 2085  git status
 2086  git push origin feat/cookies-for-route 
 2087  cd ..
 2088  ls -l
 2089  cd ..
 2090  ls -l
 2091  cd pipeline
 2092  ls -l
 2093  cd ..
 2094  ls -l 
 2095  pwd
 2096  cd ~/
 2097  ls -l
 2098  cd Projetos
 2099  ls -l
 2100  cd hydrogen
 2101  git status
 2102  git pull
 2103  git status
 2104  git add .
 2105  git commit -m "style: reformatting code"
 2106  git status
 2107  history | grep graddle
 2108  history | grep gradle
 2109  ~/gradle/gradle-2.14/bin/gradle clean build
 2110  git status
 2111  git log
 2112  git status
 2113  git add hydrogen.warehouse/src/main/scala/hydrogen/warehouse/PostViewSessionMain.scala
 2114  git commit -m "feat: use horizon storage api to read postview events"
 2115  git status
 2116  git log
 2117  git status
 2118  git add .
 2119  git commit -m "style: reformatting VideoSessionMain source code"
 2120  git status
 2121  git push origin feat/use-horizon-storage-api 
 2122  git status
 2123  git diff
 2124  git statis
 2125  git status
 2126  git add .
 2127  git commit -m "feat: use horizon storage api to read videowatch events"
 2128  git status
 2129  git add .
 2130  git commit -m "style: reformatting PageviewTrackJoinMain source code"
 2131  ~/gradle/gradle-2.14/bin/gradle clean build
 2132  ls -l
 2133  git clone gitlab@gitlab.globoi.com:bigdata/pipeline-jobs-commons.git
 2134  ls -l
 2135  cd pipeline-jobs-commons
 2136  sbt test
 2137  sbt clean compile
 2138  vi ~/.sbt/.credentials
 2139  git status
 2140  git diff
 2141  git status
 2142  git checkout -b "fix/public-objects"
 2143  git satus
 2144  git status
 2145  git diff
 2146  git add .
 2147  git commit -m "fix: remove publicRead ACL definition"
 2148  git status
 2149  git push origin fix/public-objects 
 2150  git checkout master
 2151  git pull
 2152  sbt clean release
 2153  ls -l
 2154  cd ..
 2155  ls -l
 2156  cd horizon-client-ios
 2157  ls -l
 2158  git status
 2159  git diff
 2160  cd ..
 2161  git clone gitlab@gitlab.globoi.com:BigDataPipeline/hadoop2gcs.git
 2162  cd hadoop2gcs
 2163  ls -l
 2164  git status
 2165  git diff
 2166  sbt clean compile
 2167  git status
 2168  git checkout -b "fix/public-objects"
 2169  git status
 2170  git add .
 2171  bin/hdfs dfs -ls /parquet
 2172  bin/hdfs dfs -ls /parquet/pageview
 2173  bin/hdfs dfs -ls /parquet/pageview/2019042915
 2174  bin/hdfs dfs -ls /parquet/pageview/2019042915/201904291560
 2175  git commit -m "fix: update pipeline-job-commons to version 1.0.27"
 2176  git status
 2177  git push origin fix/public-objects 
 2178  git checkout master
 2179  git pull
 2180  git status
 2181  git pull
 2182  make build
 2183  ~/gradle/gradle-2.14/bin/gradle clean build
 2184  make deploy
 2185  cd ..
 2186  git clone gitlab@gitlab.globoi.com:BigDataPipeline/horizon_events_aggregator.git
 2187  bin/hdfs dfs -ls /user/actions
 2188  bin/hdfs dfs -ls /user/actions/confs
 2189  ~/gradle/gradle-2.14/bin/gradle clean build
 2190  git status
 2191  git diff
 2192  history | grep git
 2193  git commit -m "feat: use horizon storage api to read pageview events"
 2194  git add .
 2195  git commit -m "feat: use horizon storage api to read pageview events"
 2196  git push origin feat/use-horizon-storage-api 
 2197  git checkout master 
 2198  git pull
 2199  bin/hdfs dfs -ls /user/actions/bin/hadoop2gcs.jar
 2200  bin/hdfs dfs -ls /user/actions/bin
 2201  bin/hdfs dfs -ls /user/actions/bin/releases
 2202  bin/hdfs dfs -ls /user/actions/bin
 2203  bin/hdfs dfs -ls /user/warehouse/bin/pipeline-hadoop2gcs.jar
 2204  bin/hdfs dfs -cp /user/warehouse/bin/pipeline-hadoop2gcs.jar /user/actions/bin/pipeline-hadoop2gcs.jar
 2205  history | grep export
 2206  export HADOOP_USER_NAME=hadoop
 2207  bin/hdfs dfs -cp /user/warehouse/bin/pipeline-hadoop2gcs.jar /user/actions/bin/pipeline-hadoop2gcs.jar
 2208  bin/hdfs dfs -ls /user/actions/bin/pipeline-hadoop2gcs.jar
 2209  bin/hdfs dfs -ls /user/actions/bin
 2210  bin/hdfs dfs -chown actions:hdfs /user/actions/bin/pipeline-hadoop2gcs.jar
 2211  bin/hdfs dfs -ls /user/actions/bin/pipeline-hadoop2gcs.jar
 2212  bin/hdfs dfs -chmod 755 /user/actions/bin/pipeline-hadoop2gcs.jar
 2213  bin/hdfs dfs -ls /user/actions/bin
 2214  bin/hdfs dfs -ls /user/actions/bin/releases/
 2215  bin/hdfs dfs -mv /user/actions/bin/hadoop2gcs.jar /user/actions/bin/releases/hadoop2gcs_old.jar
 2216  bin/hdfs dfs -mv /user/actions/bin/pipeline-hadoop2gcs.jar /user/actions/bin/hadoop2gcs.jar
 2217  bin/hdfs dfs -ls /user/actions/bin
 2218  curl https://sdk.cloud.google.com | bash\n
 2219  exec -l $SHELL
 2220  gcloud init\n
 2221  gsutil ls gs://\n
 2222  gsutil ls gs://content-knowledge\n
 2223  gsutil ls gs://content-knowledge/agg\n
 2224  gsutil ls gs://content-knowledge/agg/poetica_v1\n
 2225  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage\n
 2226  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1\n
 2227  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/vl_year=2019\n
 2228  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019\n
 2229  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=1\n
 2230  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=1/day=15\n
 2231  gsutil -m acl set -r private gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=1/day=15\n
 2232  ls -l
 2233  cd scripts-marotos
 2234  exit
 2235  cd ..
 2236  ls -l
 2237  mkdir keys
 2238  cd keys
 2239  mv ~/Downloads/bigquery-key-ad4157d539aa.json .
 2240  l s-l
 2241  ls -l
 2242  gcloud auth activate-service-account --key-file ~/Projetos/keys/bigquery-key-ad4157d539aa.json
 2243  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=1/day=15\n
 2244  bin/hdfs dfs -ls /user/profiling/bin
 2245  gcloud auth list
 2246  gcloud auth revoke 926281864602-compute@developer.gserviceaccount.com
 2247  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=1/day=15\n
 2248  gcloud auth list
 2249  gcloud config set account leonardo.neuwald@corp.globo.com
 2250  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=1/day=15\n
 2251  gsutil -m acl set -r private gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=1/day=15\n
 2252  gsutil -m acl set -r private gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=1\n
 2253  gsutil -m acl set -r private gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=2\n
 2254  gsutil -m acl set -r private gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=3\n
 2255  gsutil -m acl set -r private gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=4\n
 2256  gsutil -m acl set -r private gs://atribuicao_comercial/mapped_ids/20190315
 2257  gsutil -m acl set -r private gs://atribuicao_comercial/mapped_ids/20190418
 2258  gsutil -m acl set -r private gs://atribuicao_comercial/mapped_ids
 2259  gsutil -m acl set -r private gs://atribuicao_comercial/sync
 2260  gsutil -m acl set -r private gs://atribuicao_comercial_test/matching_ids
 2261  gsutil ls\n
 2262  gsutil ls -help\n
 2263  gsutil help ls\n
 2264  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=4/day=29\n
 2265  gsutil ls gs://globo_products/agg/stories_v1/tenant=g1/name=stories_v1/year=2019/month=4/day=29\n
 2266  gsutil help ls\n
 2267  gsutil ls -L gs://globo_products/agg/stories_v1/tenant=g1/name=stories_v1/year=2019/month=4/day=29\n
 2268  gsutil ls -l gs://globo_products/agg/stories_v1/tenant=g1/name=stories_v1/year=2019/month=4/day=29\n
 2269  gsutil ls gs://globo_products/*/*/tenant=g1/name=stories_v1/year=2019/*/*\n
 2270  gsutil ls gs://globo_products/**/**/tenant=g1/name=stories_v1/year=2019/**/**/\n
 2271  gsutil ls gs://globo_products/\n
 2272  gsutil ls gs://globo_products/*\n
 2273  gsutil -m acl set -r private gs://globo_products/agg/livecoverage_v1/tenant=g1/name=livecoverage_v1/year=2019\n
 2274  gsutil ls -d gs://globo_products/agg/livecoverage_v1\n
 2275  gsutil ls -r gs://globo_products/agg/livecoverage_v1\n
 2276  gsutil ls -r gs://globo_products/agg/livecoverage_v1 | grep 2019\n
 2277  gsutil -m acl set -r private gs://globo_products/agg/livecoverage_v1/tenant=ge/name=livecoverage_v1/year=2019\n
 2278  gsutil -m acl set -r private gs://globo_products/agg/livecoverage_v1/tenant=gshow/name=livecoverage_v1/year=2019
 2279  gsutil -m acl set -r private gs://globo_products/agg/multicontent_v1/tenant=g1/name=multicontent_v1/year=2019
 2280  gsutil -m acl set -r private gs://globo_products/agg/multicontent_v1/tenant=ge/name=multicontent_v1/year=2019
 2281  gsutil -m acl set -r private gs://globo_products/agg/multicontent_v1/tenant=gshow/name=multicontent_v1/year=2019
 2282  gsutil -m acl set -r private gs://globo_products/agg/multicontent_v2/tenant=g1/name=multicontent_v2/year=2019
 2283  gsutil -m acl set -r private gs://globo_products/agg/multicontent_v2/tenant=ge/name=multicontent_v2/year=2019
 2284  gsutil -m acl set -r private gs://globo_products/agg/multicontent_v2/tenant=gshow/name=multicontent_v2/year=2019
 2285  gsutil -m acl set -r private gs://globo_products/agg/stories_v1/tenant=g1/name=stories_v1/year=2019
 2286  gsutil -m acl set -r private gs://globo_products/agg/stories_v1/tenant=ge/name=stories_v1/year=2019
 2287  gsutil -m acl set -r private gs://globo_products/agg/stories_v1/tenant=gshow/name=stories_v1/year=2019
 2288  gsutil -m acl set -r private gs://globo_products/globoab/**/year=2019
 2289  gsutil -m acl set -r private gs://globo_products/globoab
 2290  history
 2291  gsutil ls gs://globo_products/pagetrack
 2292  gsutil ls gs://globo_products/postviewsession
 2293  gsutil ls gs://globo_products/recommendeditems
 2294  gsutil ls gs://globo_products/videolivesession
 2295  gsutil ls gs://globo_products/videosession
 2296  gsutil -m acl set -r private gs://globo_products/multi-content\ngsutil -m acl set -r private gs://globo_products/users
 2297  gsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=ana_maria_braga/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=bhfm/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=canal_bis/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=canal_brasil/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=canal_mega_pix/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=canal_off/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=canal_philos/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=canal_sexyhot/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=canal_syfy/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=canal_universal/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=canal_viva/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=cartola/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=casa_vogue/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=cbn/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=educacao/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=ego/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=epoca/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=epoca_negocios/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=extra/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=famosos/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=futebolglobonoradio/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=futpedia/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=g1/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=gazeta_web/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=globo_esporte/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=globo_play/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=globosatplay/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=gnt/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=gshow/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=home/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=memoria_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=multishow/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=mundo_gloob/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=o_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=outros/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=pegn/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=premiere_fc/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=radio_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=rede_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_autoesporte/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_casa_e_jardim/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_crescer/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_galileu/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_glamour/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_globo_rural/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_gq/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_marie_claire/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_monet/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=revista_quem/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=sportv/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=techtudo/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=telecine/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=valor/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=variedades/year=2019\ngsutil -m acl set -r private gs://globo_products/pagetrack/glb_product=vogue/year=2019\n
 2298  gsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=cartola/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=ego/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=epoca/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=epoca_negocios/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=extra/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=famosos/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=g1/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=globo_esporte/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=globo_play/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=globosatplay/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=gshow/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=home/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=o_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=outros/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=rede_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=sportv/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=techtudo/year=2019\ngsutil -m acl set -r private gs://globo_products/postviewsession/glb_product=valor/year=2019
 2299  \ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=ana_maria_braga/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=canal_bis/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=canal_brasil/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=canal_mega_pix/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=canal_off/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=canal_philos/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=canal_syfy/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=canal_universal/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=canal_viva/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=casa_vogue/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=cbn/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=educacao/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=ego/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=epoca/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=epoca_negocios/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=extra/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=famosos/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=futpedia/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=g1/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=gazeta_web/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=globo_esporte/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=globo_play/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=globosatplay/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=gnt/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=gshow/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=home/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=multishow/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=mundo_gloob/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=o_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=outros/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=pegn/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=premiere_fc/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=rede_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_autoesporte/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_casa_e_jardim/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_crescer/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_galileu/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_glamour/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_globo_rural/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_gq/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_marie_claire/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_monet/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=revista_quem/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=sportv/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=techtudo/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=valor/year=2019\ngsutil -m acl set -r private gs://globo_products/recommendeditems/glb_product=vogue/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=canal_bis/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=canal_brasil/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=canal_off/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=canal_philos/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=canal_sexyhot/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=canal_universal/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=canal_viva/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=cbn/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=debug/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=epoca_negocios/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=g1/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=gazeta_web/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=globo_esporte/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=globo_play/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=globosatplay/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=gnt/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=gshow/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=home/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=memoria_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=multishow/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=mundo_gloob/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=o_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=outros/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=premiere_fc/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=rede_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=revista_autoesporte/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=sem_object/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=sportv/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=techtudo/year=2019\ngsutil -m acl set -r private gs://globo_products/videolivesession/glb_product=valor/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=ana_maria_braga/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=canal_bis/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=canal_brasil/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=canal_off/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=canal_philos/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=canal_sexyhot/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=canal_syfy/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=canal_universal/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=canal_viva/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=cartola/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=casa_vogue/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=cbn/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=debug/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=educacao/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=ego/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=epoca/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=epoca_negocios/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=extra/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=famosos/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=futpedia/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=g1/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=gazeta_web/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=globo_esporte/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=globo_play/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=globosatplay/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=gnt/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=gshow/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=home/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=memoria_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=multishow/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=mundo_gloob/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=o_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=outros/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=pegn/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=premiere_fc/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=radio_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=rede_globo/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=revista_autoesporte/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=revista_casa_e_jardim/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=revista_crescer/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=revista_galileu/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=revista_glamour/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=revista_globo_rural/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=revista_gq/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=revista_marie_claire/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=revista_quem/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=sem_object/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=sportv/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=techtudo/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=telecine/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=valor/year=2019\ngsutil -m acl set -r private gs://globo_products/videosession/glb_product=vogue/year=2019\n
 2300  ls -l
 2301  history
 2302  cd ..
 2303  ls -l
 2304  cd horizon-track-service
 2305  git status
 2306  rm -rf .vscode/ go.mod go.sum
 2307  ls -l
 2308  git status
 2309  git checkout master
 2310  git pull
 2311  ls -l
 2312  ls -a
 2313  git remote 
 2314  make tsuru-add-remotes
 2315  cd ..
 2316  ls -l
 2317  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/roteiros-artesanais.git
 2318  cd roteiros-artesanais
 2319  ls -l
 2320  mkdir gcloud
 2321  cd gcloud
 2322  ls -l
 2323  cd bin
 2324  ls -l
 2325  ls -a
 2326  ls -l
 2327  vi yarn
 2328  touch change-acl.sh
 2329  ls -l
 2330  touch change-acl
 2331  vi change-acl
 2332  change-acl
 2333  ./change-acl
 2334  ls -l
 2335  chmod u+x change-acl
 2336  ./change-acl
 2337  source ~/.bash_profile
 2338  ./change-acl
 2339  ls -l
 2340  cd Projetos
 2341  ls -l
 2342  cd roteiros-artesanais
 2343  ls -l
 2344  cd gcloud
 2345  ls -l
 2346  change-acl
 2347  ./change-acl
 2348  vi change-acl
 2349  gsutil acl get gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=5/day=1 > acl.txt
 2350  pwd
 2351  gsutil acl get gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=5/day=1 > acl.txt
 2352  gsutil acl get gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=5/day=1
 2353  gsutil -ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=5/day=1
 2354  gsutil ls gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=5/day=1
 2355  gsutil acl get gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=5/day=1/part-00000-1e82690d-a010-41ed-bf89-16ea5b2b9267.avro
 2356  gsutil acl get gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=5/day=1/part-00000-1e82690d-a010-41ed-bf89-16ea5b2b9267.avro > acl.txt
 2357  gsutil acl set acl.txt gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=4/day=28/*.avro
 2358  gsutil acl set acl.txt gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=4/day=28/part-00000-e51987f0-b4e2-4a5b-a0fa-f181e6003021.avro
 2359  vi change-acl
 2360  gsutil acl set -r acl.txt gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=4/day=27
 2361  gsutil -m acl set -r private gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=4/day=27
 2362  gsutil acl set -r acl.txt gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=4/day=27
 2363  git status
 2364  ls -l
 2365  cd ..
 2366  git status
 2367  cd gcloud
 2368  ls -l
 2369  rm -rf change-acl.sh
 2370  cd ..
 2371  ls -l
 2372  ./change-acl globo_products /pagetrack/glb_product=ana_maria_braga/year=2019/month=5/day=1
 2373  ./change-acl globo_products
 2374  cd gcloud
 2375  ls -l
 2376  ./change-acl globo_products
 2377  mv change-acl change-private-acl
 2378  cd ..
 2379  ./gcloud/change-acl globo_products
 2380  ./gcloud/change-private-acl globo_products
 2381  git status
 2382  git add .
 2383  git commit -m "feat: add gcloud scripts"
 2384  git push origin master 
 2385  gsutil acl set -r acl.txt gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=1
 2386  gsutil acl set -r acl.txt gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=2
 2387  gsutil acl set -r acl.txt gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=3
 2388  gsutil acl set -r acl.txt gs://content-knowledge/agg/poetica_v1/tenant=backstage/name=poetica_v1/year=2019/month=4
 2389  exit
 2390  ls -l
 2391  cd ..
 2392  ls -l
 2393  cd ..
 2394  ls -l
 2395  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/pipeline-document-ingest-activemq-consumer.git
 2396  cd pipeline-document-ingest-activemq-consumer
 2397  ls -l
 2398  code .
 2399  make test
 2400  make lint
 2401  make setup
 2402  l s-l
 2403  git diff
 2404  history | grep env
 2405  pyenv virtualenv 3.6.8 doc-ingest-mq
 2406  pyenv activate doc-ingest-mq
 2407  make test
 2408  make setup
 2409  make test
 2410  git status
 2411  git diff
 2412  git status
 2413  git diff
 2414  git status
 2415  git checkout -b "fix/wrong-type-fields"
 2416  git status
 2417  git add .
 2418  git commit -m "fix: force convert to array the fields movieInfo.soundMixes.soundMix, ratings.advisories.advisory and relations.relation"
 2419  git status
 2420  git push origin fix/wrong-type-fields 
 2421  git checkout master
 2422  git pull
 2423  ls -l
 2424  make publish
 2425  git pull
 2426  make publish
 2427  touch ~/.pypirc
 2428  vi ~/.pypirc
 2429  make publish
 2430  vi ~/.pypirc
 2431  cd ..
 2432  pyenv deactivate doc-ingest-mq
 2433  mkdir personal
 2434  cd personal
 2435  git clone git@github.com:rbutti/martian-rationing-system.git
 2436  ls -l
 2437  vi ~/.ssh/id_rsa.pub
 2438  git clone git@github.com:leoneuwald/TesteRepo.git
 2439  cd TesteRepo
 2440  touch file1
 2441  vi file1
 2442  git add .
 2443  git commit -m "teste"
 2444  git push origin master
 2445  git config user.email leo.alvesneuwald@gmail.com
 2446  git config user.name Leonardo Alves Neuwald
 2447  git config user.name "Leonardo Alves Neuwald"
 2448  vi file1
 2449  git add .
 2450  git commit -m "teste"
 2451  git push origin master
 2452  cd ..
 2453  git clone git@github.com:rbutti/martian-rationing-system.git
 2454  cd martian-rationing-system
 2455  git checkout spring-boot-rest-controller-changes
 2456  git pull
 2457  mvn clean compile
 2458  ls -l
 2459  ls -l /opt
 2460  ls -l /
 2461  cd ~
 2462  ls -l
 2463  mv ~/Downloads/apache-maven-3.6.0 ~/
 2464  ls -l
 2465  JAVA_HOME
 2466  java -v
 2467  java -version
 2468  export PATH=~/apache-maven-3.6.0/bin:$PATH
 2469  mvn -c
 2470  mvn clean compile
 2471  export PATH=~/apache-maven-3.6.0/bin:$PATH
 2472  mvn clean compile
 2473  ls -l
 2474  cd backend
 2475  mvn clean compile
 2476  mvn spring-boot:run\n
 2477  git status
 2478  git pull
 2479  export PATH=~/apache-maven-3.6.0/bin:$PATH
 2480  ls -l
 2481  git status
 2482  ls -l
 2483  owd
 2484  pwd
 2485  cd ..
 2486  ls -l
 2487  cd ..
 2488  ls -l
 2489  cd ..
 2490  ls -l
 2491  /usr/local/opt/python/bin/python3.7 -m pip install -U pylint --user
 2492  cd pipeline-document-ingest-activemq-consumer
 2493  git status
 2494  git pull
 2495  git log
 2496  ls -l
 2497  history
 2498  pyenv activate doc-ingest-mq
 2499  make test
 2500  git status
 2501  git diff
 2502  git status
 2503  git diff
 2504  history | grep fix
 2505  history | grep checkout
 2506  git checkout -b "fix/wrong-type-fields"
 2507  git checkout -b "fix/wrong-field-relationships-relationship-type"
 2508  git status
 2509  history | grep commit
 2510  git ad .
 2511  git add .
 2512  git commit -m "fix: force convert to array the field relationships.relationship"
 2513  git push origin fix/wrong-field-relationships-relationship-type 
 2514  git checkout master
 2515  git pull
 2516  git status
 2517  history | grep tag
 2518  git tag v0.7.3
 2519  git push --tags
 2520  history | grep doc-ingest-mq
 2521  pyenv deactivate doc-ingest-mq
 2522  cd ..
 2523  ls -l
 2524  cd roteiros-artesanais
 2525  git status
 2526  git diff
 2527  git status
 2528  git log
 2529  git add .
 2530  git log
 2531  git commit -m "feat: add new mongo scripts"
 2532  git status
 2533  git push origin master
 2534  cd ..
 2535  ls -l
 2536  cd hadoop-2.7.3
 2537  history | grep g1
 2538  history | grep hdfs
 2539  ./hdfs dfs -ls /user/actions/stream/tenant=g1
 2540  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1
 2541  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=ab
 2542  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=ab/actionId=ab-conversion
 2543  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=ab/actionId=ab-conversion/actionVersion=1.0
 2544  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=ab
 2545  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1
 2546  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=common
 2547  ls -l
 2548  cd horizon_event_stream
 2549  git status
 2550  git pull
 2551  sbt clean compile
 2552  ls -l
 2553  cd ..
 2554  ls -l
 2555  cd roteiros-artesanais
 2556  ls -l
 2557  touch kafka-consumer.py\n
 2558  ls -l
 2559  cd ..
 2560  ls -l
 2561  cd horizon_event_stream
 2562  ls -l
 2563  vi Makefile
 2564  sbt clean compile
 2565  git status
 2566  git checkout -b "fix/case-sensitive-g1"
 2567  git status
 2568  git add src/main/scala/com/globo/pipeline/horizoneventstream/HorizonEventStreamMain.scala
 2569  git commit -m "fix: case sensitive g1"
 2570  git push origin fix/case-sensitive-g1 
 2571  git checkout master
 2572  git status
 2573  git pull
 2574  git status
 2575  cd ..
 2576  ls -l
 2577  rm -rf horizon_event_stream
 2578  git clone gitlab@gitlab.globoi.com:BigDataPipeline/horizon_event_stream.git
 2579  ./bin/hdfs dfs -ls /user/actions/bin/horizon_event_stream.jar
 2580  cd horizon_event_stream
 2581  git status
 2582  sbt clean publishLocal
 2583  ls -l
 2584  ls -l target
 2585  ls -l target/scala-2.11
 2586  git status
 2587  git diff
 2588  git add .
 2589  git commit -m "fix: add config to make spark case-sensitive"
 2590  git status
 2591  git push origin master
 2592  make test
 2593  make release
 2594  make deploy
 2595  git status
 2596  make release
 2597  make deploy
 2598  history | grep yarn
 2599  bin/yarn application -kill application_1539207608922_214396
 2600  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1
 2601  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent
 2602  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-chunk-view
 2603  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-chunk-view/actionVersion=3.0
 2604  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-chunk-view/actionVersion=3.0/year=2019/month=5
 2605  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-chunk-view/actionVersion=3.0/year=2019/month=5/day=6
 2606  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent
 2607  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-chunk-view/actionVersion=3.0/year=2019/month=5
 2608  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-chunk-view/actionVersion=3.0/year=2019/month=5/day=6
 2609  ./bin/hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-chunk-view/actionVersion=3.0/year=2019/month=5
 2610  bin/yarn application -kill application_1539207608922_208139
 2611  cd ..
 2612  ls -l
 2613  cd pipeline-document-ingest-activemq-consumer
 2614  git status
 2615  git pull
 2616  git log
 2617  git checkout fix/wrong-field-relationships-relationship-type 
 2618  git status
 2619  git pull
 2620  ls -l
 2621  history
 2622  cd ..
 2623  ls -l
 2624  cd ..
 2625  ls -l
 2626  cd ..
 2627  ls -l
 2628  cd horizon-schemas
 2629  ls -l
 2630  git pull
 2631  vi Makefile
 2632  make test
 2633  ls -l
 2634  vi README.md
 2635  make test
 2636  vi test.js
 2637  cd ..
 2638  ls -l
 2639  cd horizon-schemas-service
 2640  ls -l
 2641  git status
 2642  git diff
 2643  ls -l
 2644  history | grep git
 2645  history | grep make
 2646  code .
 2647  git status
 2648  git pull
 2649  make submodule-update
 2650  git diff
 2651  zip horizon_avro_stream horizon_avro_stream.zip
 2652  ls -l
 2653  wpd
 2654  pwd
 2655  cd horizon_avro_stream
 2656  git status
 2657  git pull
 2658  cd ..
 2659  mkdir streams
 2660  cd streams
 2661  ls -l
 2662  git status
 2663  git diff
 2664  git checkout -b "feat/add-new-ge-schemas"
 2665  git status
 2666  git diff
 2667  git add CHANGELOG.md hzs/schemas hzs/version.go tasks/tsuru.mk
 2668  git commit -m "chore: update schemas"
 2669  git push origin feat/add-new-ge-schemas 
 2670  git checkout master
 2671  git pull
 2672  git status
 2673  git diff
 2674  make submodule-update
 2675  git status
 2676  git diff
 2677  cd hzs
 2678  git status
 2679  git diff
 2680  cd schemas
 2681  ls -l
 2682  git status
 2683  git checkout master
 2684  git status
 2685  git pull
 2686  cd ..
 2687  ls -l
 2688  cd ..
 2689  git status
 2690  git pull
 2691  git diff
 2692  cd hzs/schemas
 2693  git diff
 2694  git status
 2695  git pull
 2696  cd ..
 2697  l s-l
 2698  ls -l
 2699  cd ..
 2700  ls -l
 2701  rm -rf horizon-schemas-service
 2702  ls -l
 2703  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-schemas-service.git
 2704  git status
 2705  cd horizon-schemas-service
 2706  ls -l
 2707  git status
 2708  git pull
 2709  git checkout -b "feat/add-new-ge-schema"
 2710  make submodule-update
 2711  git status
 2712  cd hzs/schemas
 2713  ls -l
 2714  cd ..
 2715  ls -l
 2716  cd ..
 2717  ls -l
 2718  git status
 2719  git diff
 2720  git add CHANGELOG.md hzs/version.go
 2721  git status
 2722  git add hzs/schemas
 2723  git status
 2724  git commit -m "chore: update schemas"
 2725  git status
 2726  git push origin feat/add-new-ge-schema
 2727  history
 2728  vi tasks/tsuru.mk
 2729  git status
 2730  git diff
 2731  history | grep submodule
 2732  history | grep git
 2733  history | grep playkit
 2734  history | grep 89
 2735  ls -l
 2736  cd hzs
 2737  ls -l
 2738  ls l
 2739  ls -l
 2740  cd schemas
 2741  git status
 2742  history | grep 88
 2743  history | grep 89
 2744  git checkout playkit 
 2745  git merge master
 2746  cd ..
 2747  ls -l
 2748  cd ..
 2749  git status
 2750  git idff
 2751  git diff
 2752  make tsuru-deploy-qa
 2753  vi tasks/tsuru.mk
 2754  make tsuru-deploy-dev
 2755  history
 2756  vi ~/.bash_profile
 2757  export HADOOP_CONF_DIR=~/configs/conf-qa
 2758  ./bin/hdfs dfs -ls /
 2759  history | grep hdfs
 2760  ./bin/hdfs dfs -ls /user/actions/stream
 2761  vi ~/.bash_profile
 2762  ls ~/configs/conf-prod
 2763  vi ~/configs/conf-prod/core-site.xml
 2764  vi ~/configs/conf-prod/hdfs-site.xml
 2765  vi ~/.bash_profile
 2766  export HADOOP_CONF_DIR=~/configs/conf-prod
 2767  pwd
 2768  cd bin
 2769  ls -l
 2770  vi hdfs
 2771  hdfs dfs -ls /
 2772  .hdfs dfs -ls /
 2773  ./hdfs dfs -ls /
 2774  ./hdfs dfs -ls /user/actions/confs
 2775  ./hdfs dfs -put ~/Downloads/agg-feed-v1_json.js /user/actions/confs
 2776  ./hdfs dfs -ls /user/actions/confs
 2777  ./hdfs dfs -chown actions:hdfs /user/actions/confs/agg-feed-v1_json.js
 2778  ./hdfs dfs -ls /user/actions/confs
 2779  pwd
 2780  history | grep hadoop
 2781  ./hdfs dfs -ls /warehouse/document-ingest/videos-gracenote-metadata
 2782  ./hdfs dfs -ls /warehouse/document-ingest
 2783  ls -l
 2784  git status
 2785  cd hzs/schemas
 2786  ls -l
 2787  git status
 2788  history
 2789  git diff
 2790  git log
 2791  git merge experimentation-v2
 2792  git pull
 2793  git merge experimentation-v2
 2794  git fetch
 2795  git fetch --all
 2796  git merge experimentation-v2
 2797  history | grep 88
 2798  ./yarn application -list | grep application_1539207608922_208171
 2799  ./yarn application -kill application_1539207608922_208171
 2800  git fetch origin merge-requests/57/head:experimentation
 2801  git merge experimentation 
 2802  git status
 2803  cd ..
 2804  ls -l
 2805  make tsuru-deploy-dev
 2806  git status
 2807  make tsuru-deploy-qa
 2808  ls -l
 2809  cd ..
 2810  ls -l
 2811  cd azkaban
 2812  ls -l
 2813  cd pipeline-horizon-stream-ingest
 2814  git status
 2815  git checkout master
 2816  git pull
 2817  git staus
 2818  git status
 2819  pwd
 2820  git pull
 2821  cd ..
 2822  ls -l
 2823  cd ..
 2824  ls -l
 2825  cd pipeline-horizon-stream-ingest
 2826  ls -l
 2827  git pull
 2828  git diff
 2829  git status
 2830  git diff
 2831  git status
 2832  git diff
 2833  git checkout -b "feat/create-hzt-ab-and-mab-jobs"
 2834  git status
 2835  git add .
 2836  git commit -m "feat: add hzt.ab and hzt.mab jobs"
 2837  git push origin feat/create-hzt-ab-and-mab-jobs 
 2838  ls -l
 2839  cd horizon_events_aggregator
 2840  ls -l
 2841  git pull
 2842  cd ..
 2843  ls -l
 2844  cd hydrogen
 2845  git status
 2846  git diff
 2847  git checkout feat/use-horizon-storage-api 
 2848  git status
 2849  cd ..
 2850  ls -l
 2851  cd ..
 2852  ls -l
 2853  cd ..
 2854  ls -l
 2855  cd pipeline-horizon-stream-ingest
 2856  make zip 
 2857  cd pipeline
 2858  cd horizon-track-service
 2859  git pull
 2860  git status
 2861  code .
 2862  git status
 2863  git checkout -b "feat/tenants-ab-and-mab"
 2864  git status
 2865  make test
 2866  git status
 2867  git diff
 2868  git add CHANGELOG.md hzt/version.go tasks/tsuru.mk
 2869  git status
 2870  git commit -m "feat: enable tenants ab and mab"
 2871  git push origin feat/tenants-ab-and-mab 
 2872  cd ..
 2873  cd horizon-track-service
 2874  git checkout master
 2875  git pull
 2876  ls -l
 2877  make tsuru-deploy-qa
 2878  history | grep log
 2879  tsuru app-log -f -a horizon-track-qa
 2880  tsuru app-log -f -a horizon-track-qa | grep ab
 2881  gt status
 2882  git status
 2883  git diff
 2884  history
 2885  git diff
 2886  git add .
 2887  git commit -m "fix: add hzt.ab and hzt.mab on dependency list"
 2888  git status
 2889  git push origin feat/create-hzt-ab-and-mab-jobs 
 2890  make zip
 2891  tsuru app-log -f -a horizon-track-service-prod | grep infoglobo.oglobo
 2892  history | grep yarn
 2893  ./yarn application -list | grep application_1544721290109_0587
 2894  vi ~/.bash_profile
 2895  export HADOOP_CONF_DIR=~/configs/conf-qa
 2896  ./yarn application -list | grep application_1544721290109_0587
 2897  ./yarn application -kill application_1544721290109_0587
 2898  git status
 2899  git checkout master
 2900  git pull
 2901  make zip
 2902  git status
 2903  cd ..
 2904  ls -l
 2905  pwd
 2906  cd ..
 2907  ls -l
 2908  cd horizon-schemas-service
 2909  git checkout master
 2910  git pull
 2911  git diff
 2912  cd ..
 2913  ls -l
 2914  mv horizon-schemas-service horizon-schemas-service-2
 2915  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-schemas-service.git
 2916  cd horizon-schemas-service
 2917  history | grep tag
 2918  git tag v0.17.0
 2919  git push --tags
 2920  make test
 2921  ls -l
 2922  git status
 2923  make test
 2924  vi tasks/app.mk
 2925  make vendor
 2926  code .
 2927  make submodule-update
 2928  make test
 2929  git status
 2930  make tsuru-deploy-prod
 2931  make tsuru-add-remotes 
 2932  make tsuru-deploy-prod
 2933  git status
 2934  git pull
 2935  ls -l
 2936  git status
 2937  ls -l
 2938  cd ..
 2939  ls -l
 2940  cd horizon-schemas-service
 2941  cd azkaban
 2942  ls -l\n: 1557757493:0;ls -l
 2943  cd pipeline-horizon-stream-ingest
 2944  git status
 2945  git pull
 2946  git checkout feat/create-hzt-ab-and-mab-jobs 
 2947  git status
 2948  make zip
 2949  git status
 2950  git diff
 2951  git add .
 2952  git commit -m "fix: add driver-java-options with hdp.version on spark-submit"
 2953  git status
 2954  git push origin feat/create-hzt-ab-and-mab-jobs 
 2955  ls -l
 2956  git status
 2957  cd ..
 2958  ls -l
 2959  cd ..
 2960  ls -l
 2961  cd pipeline-document-ingest-activemq-consumer
 2962  git status
 2963  git checkout master
 2964  git pull
 2965  vi CHANGELOG.md
 2966  ls -l
 2967  vi setup.py
 2968  cd ingest
 2969  ls -l
 2970  cd ..
 2971  ls -l
 2972  cd ingest
 2973  ls -l
 2974  vi __init__.py
 2975  cd ..
 2976  ls -l
 2977  git pull
 2978  ./yarn application -list | grep application_1539207608922_200106
 2979  history | grep use
 2980  export HADOOP_CONF_DIR=~/configs/conf-prod
 2981  ./yarn application -list | grep application_1539207608922_200106
 2982  ./yarn application -kill application_1539207608922_200106
 2983  history
 2984  git status
 2985  history | grep tag
 2986  git tag v0.7.4
 2987  git push --tags
 2988  git status
 2989  make test
 2990  history | grep pyenv
 2991  pyenv activate doc-ingest-mq
 2992  make test
 2993  vi Makefile
 2994  make setup
 2995  make test
 2996  make publish
 2997  vi ~/.pypirc
 2998  make publish
 2999  pyenv deactivate doc-ingest-mq
 3000  cd ..
 3001  cd azkaban
 3002  cd pipeline-document-ingest
 3003  git pull
 3004  pwd
 3005  git status
 3006  make zip
 3007  ls -l
 3008  cd ..
 3009  ls -l
 3010  mv Downloads/kafka_2.11-0.10.1.1 .
 3011  ls -l
 3012  cd kafka_2.11-0.10.1.1
 3013  bin/kafka-topics.sh --list --zookeeper kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092
 3014  bin/kafka-topics.sh --list --zookeeper kafka01.qa.globoi.com:2181,kafka02.qa.globoi.com:2181,kafka03.qa.globoi.com:2181
 3015  ls -l
 3016  cd ..
 3017  ls -l
 3018  cd hadoop-2.7.3
 3019  ls -l
 3020  cd bin
 3021  ./yarn application -list | grep  application_1539207608922_213594
 3022  ./yarn application -kill application_1539207608922_213594
 3023  history
 3024  history | grep tsuru
 3025  tsuru app-log -f -a horizon-track-qa | grep ab
 3026  tsuru app-log -f -a horizon-track-qa | grep mab
 3027  tsuru app-log -f -a horizon-http-stream-qa | grep mab
 3028  ls -l
 3029  cd ..
 3030  ls -l
 3031  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-http-stream.git
 3032  cd horizon-http-stream
 3033  make test
 3034  history | grep export
 3035  export HADOOP_CONF_DIR=~/configs/conf-qa
 3036  ./yarn application -list | grep application_1544721290109_0597
 3037  ./yarn application -kill application_1544721290109_0597
 3038  code .
 3039  export HADOOP_CONF_DIR=~/configs/conf-prod
 3040  ./hdfs dfs -ls /
 3041  ./hdfs dfs -ls /user/actions/stream/checkpoints
 3042  export HADOOP_CONF_DIR=~/configs/conf-qa
 3043  ./hdfs dfs -ls /user/actions/stream/checkpoints
 3044  ./hdfs dfs -mv /user/actions/stream/checkpoints/g1 /user/actions/stream/checkpoints/g1_old
 3045  history | grep export
 3046  export HADOOP_USER_NAME=hadoop
 3047  ./hdfs dfs -ls /user/actions/stream/checkpoints
 3048  ./hdfs dfs -mv /user/actions/stream/checkpoints/g1 /user/actions/stream/checkpoints/g1_old
 3049  export HADOOP_USER_NAME=hdfs
 3050  ./hdfs dfs -mv /user/actions/stream/checkpoints/g1 /user/actions/stream/checkpoints/g1_old
 3051  git status
 3052  history | grep git
 3053  git checkout -b "feat/tenants-ab-and-mab"
 3054  git add CHANGELOG.md hzt/version.go tasks/tsuru.mk
 3055  git add CHANGELOG.md hhs/version.go tasks/tsuru.mk
 3056  git status
 3057  git add tasks/env.mk
 3058  git commit -m "feat: enable tenants ab and mab"
 3059  git status
 3060  git push origin feat/tenants-ab-and-mab 
 3061  make vendor
 3062  make tsuru-deploy-qa
 3063  curl -X POST \\n  https://horizon-track.qa.globoi.com/event/mab \\n  -H 'Accept: */*' \\n  -H 'Cache-Control: no-cache' \\n  -H 'Connection: keep-alive' \\n  -H 'Content-Type: application/json' \\n  -H 'Host: horizon-track.qa.globoi.com' \\n  -H 'Postman-Token: 5f136585-9277-486b-8a85-87445a33cdcb,da6c9117-0f8a-47b5-b1a2-ab3971defa33' \\n  -H 'User-Agent: PostmanRuntime/7.11.0' \\n  -H 'accept-encoding: gzip, deflate' \\n  -H 'cache-control: no-cache' \\n  -H 'content-length: 1027' \\n  -d '{\n   "horizonClientTenant": "mab",\n   "horizonClientUUID": "09cbe2c7-226d-49b3-9045-173a107eb3ed",\n   "horizonClientTs": 1557780745,\n   "horizonClientType": "server-side",\n   "horizonClientDeviceGroup": ".",\n   "actions": [\n       {\n           "id": "mab-increment",\n           "version": "2.0",\n           "actionTs": 1557780745,\n           "url": "http://globo-ab.globo.com/",\n           "horizonClientVersion": "0.1",\n           "horizonClientReferer": "http://globo-ab.globo.com/",\n           "contentType": "mab",\n           "properties": {\n               "experiment": "ranked",\n               "algorithm": "rba-ths",\n               "arms": [\n                   {\n                       "slot": 0,\n                       "name": "arm1"\n                   },\n                   {\n                       "slot": 1,\n                       "name": "arm2"\n                   }\n               ],\n               "trackId": "09cbe2c7-226d-49b3-9045-173a107eb3ed"\n           }\n       }\n   ],\n   "contentType": "application/json"\n}'
 3064  tsuru app-log -f -a horizon-track-qa | grep mab
 3065  export HADOOP_CONF_DIR=~/configs/conf-prod
 3066  ./hdfs dfs -ls /user/actions/stream
 3067  ./hdfs dfs -ls /user/actions/stream/tenant=g1
 3068  export HADOOP_CONF_DIR=~/configs/conf-qa
 3069  ./yarn application -kill application_1544721290109_0601
 3070  ./yarn application -kill application_1544721290109_0598
 3071  ./yarn application -kill application_1544721290109_0600
 3072  ls -l
 3073  cd ..
 3074  ls -l
 3075  cd pipeline-video-warehouse
 3076  make zip
 3077  pwd
 3078  cd ..
 3079  ls -l
 3080  cd ..
 3081  ls -l
 3082  cd ..
 3083  cd bigdata/pipeline
 3084  ls-l
 3085  ls -l
 3086  git status
 3087  git diff
 3088  ./hdfs dfs -ls /hbase-libs
 3089  gradle clean build
 3090  history | grep gradle
 3091  ~/gradle/gradle-2.14/bin/gradle clean build
 3092  history | grep info
 3093  tsuru app-info -a horizon-schemas-prod
 3094  ls -l
 3095  git status
 3096  git pull
 3097  git diff
 3098  ls -l
 3099  ~/gradle/gradle-2.14/bin/gradle clean build
 3100  export HADOOP_CONF_DIR=~/configs/conf-prod
 3101  ./hdfs dfs -ls /tmp
 3102  ./hdfs dfs -ls /tmp/warehouse
 3103  \tls -l
 3104  cd ..
 3105  ls -l
 3106  cd hydrogen.warehouse
 3107  ls -l
 3108  cd build
 3109  ls -l
 3110  cd ..
 3111  cd hydrogen.warehouse
 3112  ~/gradle/gradle-2.14/bin/gradle clean build
 3113  echo $SPARK_HOME
 3114  pwd
 3115  export SPARK_HOME="~/spark-2.4.0-bin-hadoop2.7"
 3116  echo $SPARK_HOME
 3117  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.4.0-bin-hadoop2.7"
 3118  echo $SPARK_HOME
 3119  pwd
 3120  cd /Users/leonardo.neuwald/Projetos/hydrogen/hydrogen.warehouse
 3121  ls -l
 3122  ./videolivesession.sh
 3123  echo $SPARK_HOME
 3124  ls -l ~
 3125  mv ~/Downloads/spark-2.1.1-bin-hadoop2.7 .
 3126  ls -l
 3127  ls -l ~
 3128  mv spark-2.1.1-bin-hadoop2.7 ~/
 3129  ls -l ~
 3130  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7"
 3131  ./videolivesession.sh
 3132  cd build
 3133  ls -l
 3134  cd libs
 3135  ls -l
 3136  jar xf jar-file hydrogen.warehouse.jar
 3137  pwd
 3138  cd libs
 3139  ls -l
 3140  jar xf jar-file hydrogen.warehouse.jar
 3141  jar xf hydrogen.warehouse.jar
 3142  ls -l
 3143  pwd
 3144  ls -l
 3145  cd ..
 3146  ls -l
 3147  cd ..
 3148  ls -l
 3149  cd horizon-storage
 3150  ls -l
 3151  git status
 3152  git pull
 3153  git status
 3154  sbt clean compile
 3155  sbt clean package
 3156  ls -l ~/Downloads/measures-scala_2.11-0.0.5.jar
 3157  ./videolivesession.sh
 3158  ls -l
 3159  cd ..
 3160  ls -l
 3161  cd ..
 3162  ls -l
 3163  ./videolivesession.sh
 3164  cd ..
 3165  ls -l
 3166  cd ..
 3167  ls -l
 3168  cd hadoop-2.7.3
 3169  cd bin
 3170  ./yarn application -list | grep application_1539207608922_220044
 3171  ./yarn application -kill application_1539207608922_220044
 3172  tsuru app-info horizon-track-service-prod
 3173  tsuru app-info =a horizon-track-service-prod
 3174  tsuru app-info -a horizon-track-service-prod
 3175  history | grep kafka
 3176  bin/kafka-topics.sh --list --zookeeper kafka01.qa.globoi.com:2181,kafka02.qa.globoi.com:2181,kafka03.qa.globoi.com:2181/kafka-0.8.2
 3177  ls -l
 3178  cd ..
 3179  ls -l
 3180  cd ..
 3181  ls -l
 3182  cd kafka_2.11-0.10.1.1
 3183  bin/kafka-topics.sh --list --zookeeper kafka01.qa.globoi.com:2181,kafka02.qa.globoi.com:2181,kafka03.qa.globoi.com:2181/kafka-0.8.2
 3184  bin/kafka-topics.sh --list --zookeeper zookeeper01.globoi.com zookeeper02.globoi.com zookeeper03.globoi.com zookeeper04.globoi.com zookeeper05.globoi.com:2181/kafka-0.8.2\n
 3185  bin/kafka-topics.sh --list --zookeeper kafka01.qa.globoi.com:2181,kafka02.qa.globoi.com:2181,kafka03.qa.globoi.com:2181/kafka-0.8.2
 3186  bin/kafka-topics.sh --list --zookeeper zookeeper01.globoi.com,zookeeper02.globoi.com,zookeeper03.globoi.com,zookeeper04.globoi.com,zookeeper05.globoi.com:2181/kafka-0.8.2\n
 3187  bin/kafka-topics.sh --create --zookeeper kafka01.qa.globoi.com:2181,kafka02.qa.globoi.com:2181,kafka03.qa.globoi.com:2181/kafka-0.8.2 --replication-factor 3 --partitions 10 --topic hzt.tst
 3188  bin/kafka-topics.sh --create --zookeeper kafka01.qa.globoi.com:2181,kafka02.qa.globoi.com:2181,kafka03.qa.globoi.com:2181/kafka-0.8.2 --replication-factor 3 --partitions 10 --topic hhs.tst
 3189  ls -l
 3190  cd ..
 3191  ls -l
 3192  cd ..
 3193  ls -l
 3194  cd ..
 3195  cd hadoop-2.7.3
 3196  cd bin
 3197  history | grep hdfs
 3198  ./hdfs dfs -ls /user/actions/stream/checkpoints
 3199  history | grep qa
 3200  export HADOOP_CONF_DIR=~/configs/conf-qa
 3201  ./hdfs dfs -ls /user/actions/stream/checkpoints
 3202  history | grep mv
 3203  ./hdfs dfs -rm -r /user/actions/stream/checkpoints/g1
 3204  cd roteiros-artesanais
 3205  ls -l
 3206  cd kafka
 3207  ls -l
 3208  ./create_topic
 3209  ls -l
 3210  chmod 777 create_topic
 3211  ./create_topic
 3212  export KAFKA_HOME=~/kafka_2.11-0.10.1.1
 3213  ./create_topic
 3214  ./create_topic a
 3215  pwd
 3216  ./create_topic a
 3217  ls -l $SPARK_HOME/bin/kafka-topics.sh
 3218  ls -l $SPARK_HOME
 3219  echo $SPARK_HOME
 3220  ./create_topic a
 3221  ./create_topic g1
 3222  git status
 3223  cd ..
 3224  ls -l
 3225  git status
 3226  git diff
 3227  git add README.md
 3228  git add kafka/
 3229  git status
 3230  git commit -m "feat: add kafka script"
 3231  git push origin master
 3232  ls -l
 3233  cd kafka
 3234  ls -l 
 3235  vi create_hhs_and_hzt_topics
 3236  ./create_hhs_and_hzt_topics ab
 3237  ./create_hhs_and_hzt_topics mab
 3238  ls -l
 3239  cd ..
 3240  ls -l
 3241  cd kafka
 3242  ls -l
 3243  cd ..
 3244  ls -l
 3245  cd horizon-http-stream
 3246  git checkout master
 3247  git pull
 3248  vi CHANGELOG.md
 3249  history | grep tsuru
 3250  history | grep make
 3251  make tsuru-add-remotes
 3252  make tsuru-deploy-qa
 3253  make tsuru-deploy-prod
 3254  tsuru app-info -a horizon-http-stream-prod
 3255  make tsuru-deploy-prod
 3256  git status
 3257  git checkout Gopkg.
 3258  git checkout Gopkg.lock
 3259  git pull
 3260  history | grep tag
 3261  git tag v3.3.1
 3262  git push --tags
 3263  git status
 3264  make tsuru-deploy-prod
 3265  vi tasks/tsuru.mk
 3266  make tsuru-deploy-prod
 3267  vi tasks/tsuru.mk
 3268  cd azkaban
 3269  ls -l
 3270  cd pipeline-horizon-stream-ingest
 3271  git checkout master
 3272  git pull
 3273  git diff
 3274  git status
 3275  vi jobs/horizon-track-event-stream-flow/hzt.hdfs.checker.job
 3276  make zip
 3277  git status
 3278  git pull
 3279  ls -l
 3280  cd jobs
 3281  ls -l
 3282  cd horizon-avro-stream-flow
 3283  ls -l
 3284  cd ..
 3285  cd horizon-track-event-stream-flow
 3286  ls -l
 3287  vi hzt.ab.job
 3288  git status
 3289  cd ..
 3290  cd horizon-track-event-stream-flow
 3291  git status
 3292  cd ..
 3293  ls -l
 3294  cd ..
 3295  git status
 3296  git pull
 3297  make zip
 3298  git statu
 3299  git status
 3300  git checkout -b "docs/update_changelog"
 3301  git status
 3302  git add .
 3303  git commit -m "docs: update changelog"
 3304  git push origin docs/update_changelog 
 3305  cd ..
 3306  ls -l
 3307  vi tasks/tsuru.mk
 3308  git status
 3309  cd ..
 3310  ls -l
 3311  cd horizon-track-service
 3312  git status
 3313  git pull
 3314  vi CHANGELOG.md
 3315  git tag v0.22.0
 3316  git push --tags
 3317  make tsuru-add-remotes
 3318  vi tasks/tsuru.mk
 3319  make tsuru-deploy-qa
 3320  make tsuru-deploy-prod
 3321  export HADOOP_CONF_DIR=~/configs/conf-qa
 3322  ls -l
 3323  cd ..
 3324  cd hydrogen
 3325  ls -l
 3326  cd hydrogen.warehouse
 3327  git status
 3328  vi videolivesession.sh
 3329  export HADOOP_CONF_DIR=~/configs/conf-prod
 3330  ./hdfs dfs -ls /parquets
 3331  ./hdfs dfs -ls /parquet
 3332  ./hdfs dfs -ls /parquet/videowatchlive
 3333  ./hdfs dfs -ls /parquet/videowatchlive/2019051500
 3334  ./hdfs dfs -du -h /parquet/videowatchlive/2019051500
 3335  ./hdfs dfs -get /parquet/videowatchlive/2019051500
 3336  ls -l
 3337  export HADOOP_CONF_DIR=~/configs/conf-qa
 3338  ./hdfs dfs -ls /parquet
 3339  ./hdfs dfs -mkdir /parquet/videowatchlive
 3340  ./hdfs dfs -ls /parquet
 3341  ./hdfs dfs -put 2019051500 /parquet/videowatchlive
 3342  echo $HADOOP_CONF_DIR
 3343  ls -l
 3344  history
 3345  ls -l
 3346  cd ..
 3347  ls -l
 3348  cd conf-qa
 3349  ls -l
 3350  vi core-site.xml
 3351  ls -l
 3352  cd ..
 3353  cd hydrogen.warehouse
 3354  ls -l
 3355  ./videolivesession.sh
 3356  history | grep spark
 3357  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7"
 3358  ./videolivesession.sh
 3359  cd conf-qa
 3360  ls -l
 3361  cd ..
 3362  ls -l
 3363  cd ..
 3364  ls -l
 3365  cd configs
 3366  ls -l
 3367  cd conf-
 3368  cd conf-qa
 3369  ls -l
 3370  pwd
 3371  vi videolivesession.sh
 3372  ./videolivesession.sh
 3373  cd ..
 3374  ls -l
 3375  cd ..
 3376  cd hadoop-2.7.3
 3377  ls -l
 3378  cd bin
 3379  ./yarn application -list | grep application_1544721290109_0603
 3380  ./yarn application -kill application_1544721290109_0603
 3381  ./videolivesession.sh
 3382  ls -l
 3383  history | grep gradle
 3384  pwd
 3385  ~/gradle/gradle-2.14/bin/gradle clean build
 3386  ./videolivesession.sh
 3387  ls -l
 3388  cd ..
 3389  ls -l
 3390  cd ..
 3391  ls -l
 3392  cd spark-2.1.1-bin-hadoop2.7
 3393  ls -l
 3394  cd sbin
 3395  ls -l
 3396  cd ..
 3397  cd bin
 3398  ls -l
 3399  $SPARK_HOME/bin/spark-shell -v --name="test" --master yarn-cluster
 3400  export HADOOP_CONF_DIR="/Users/leonardo.neuwald/configs/conf-qa"
 3401  $SPARK_HOME/bin/spark-shell -v --name="test" --master yarn-cluster
 3402  $SPARK_HOME/bin/spark-shell -v --name="test" --master yarn
 3403  export HADOOP_USER_NAME=warehouse
 3404  $SPARK_HOME/bin/spark-shell -v --name="test" --master yarn
 3405  telnet 10.127.175.158 62364
 3406  ifconfig
 3407  l s-l
 3408  ls -l
 3409  cd ..
 3410  ls -l
 3411  cd ..
 3412  ls -l
 3413  cd hadoop-2.7.3
 3414  ls -l
 3415  cd bin
 3416  ./hdfs dfs -ls /
 3417  ./hdfs dfs -ls /tmp/wareshouse
 3418  ./hdfs dfs -ls /tmp/warehouse
 3419  ./hdfs dfs -ls /tmp/warehouse/videolivesession
 3420  ./hdfs dfs -ls /tmp/warehouse/videolivesession/parquet
 3421  ./hdfs dfs -ls /tmp/warehouse/videolivesession/parquet/glb_product=g1
 3422  ./hdfs dfs -ls /tmp/warehouse/videolivesession/parquet/glb_product=g1/year=2019
 3423  ./hdfs dfs -ls /tmp/warehouse/videolivesession/parquet/glb_product=g1/year=2019/month=5
 3424  ./hdfs dfs -ls /tmp/warehouse/videolivesession/parquet/glb_product=g1/year=2019/month=5/day=15
 3425  ls -l
 3426  cd ..
 3427  ls -l
 3428  cookiecutter http://gitlab.globoi.com/bigdatapipeline/cookiecutter-pipeline-scala-app-lib.git
 3429  cd lmb
 3430  ls -l
 3431  cd ..
 3432  ls -l
 3433  cd horizon-storage
 3434  sbt clean test
 3435  sbt clean publishLocal
 3436  cd ..
 3437  ls -l
 3438  cd hydrogen
 3439  ls -l
 3440  cd hydrogen.warehouse
 3441  ./videolivesession.sh
 3442  ./hdfs dfs -rm -r /tmp/warehouse/videolivesession
 3443  ./videolivesession.sh
 3444  git status
 3445  git diff
 3446  sbt clean test
 3447  history | grep tsuru
 3448  tsuru app-log -f -a horizon-track-qa | grep mab
 3449  tsuru app-log -f -a horizon-track-prod | grep mab
 3450  tsuru app-log -f -a horizon-track-service-prod | grep mab
 3451  sbt clean test
 3452  tsuru app-log -f -a horizon-track-service-prod | grep mab
 3453  tsuru app-info -a horizon-track-service-prod
 3454  sbt clean test
 3455  curl -X POST \\n  http://horizon-track-service-prod.gcloud-horizon.globoi.com/event/mab \\n  -d '{\n    "horizonClientTenant": "mab",\n    "horizonClientUUID": "52cbd3e5-247c-4f7d-b390-0e90add96cc4",\n    "horizonClientTs": 1558125820,\n    "horizonClientType": "server-side",\n    "horizonClientDeviceGroup": ".",\n    "actions": [\n        {\n            "id": "mab-increment",\n            "version": "2.0",\n            "actionTs": 1558125820,\n            "url": "http://globo-ab.globo.com/",\n            "horizonClientVersion": "0.1",\n            "horizonClientReferer": "http://globo-ab.globo.com/",\n            "contentType": "mab",\n            "properties": {\n                "experiment": "ranked",\n                "algorithm": "rba-ths",\n                "arms": [\n                    {\n                        "slot": 0,\n                        "name": "arm2"\n                    },\n                    {\n                        "slot": 1,\n                        "name": "arm1"\n                    }\n                ],\n                "trackId": "52cbd3e5-247c-4f7d-b390-0e90add96cc4"\n            }\n        }\n    ],\n    "contentType": "application/json"\n}'
 3456  curl -vv -X POST \\n  http://horizon-track-service-prod.gcloud-horizon.globoi.com/event/mab \\n  -d '{\n    "horizonClientTenant": "mab",\n    "horizonClientUUID": "52cbd3e5-247c-4f7d-b390-0e90add96cc4",\n    "horizonClientTs": 1558125820,\n    "horizonClientType": "server-side",\n    "horizonClientDeviceGroup": ".",\n    "actions": [\n        {\n            "id": "mab-increment",\n            "version": "2.0",\n            "actionTs": 1558125820,\n            "url": "http://globo-ab.globo.com/",\n            "horizonClientVersion": "0.1",\n            "horizonClientReferer": "http://globo-ab.globo.com/",\n            "contentType": "mab",\n            "properties": {\n                "experiment": "ranked",\n                "algorithm": "rba-ths",\n                "arms": [\n                    {\n                        "slot": 0,\n                        "name": "arm2"\n                    },\n                    {\n                        "slot": 1,\n                        "name": "arm1"\n                    }\n                ],\n                "trackId": "52cbd3e5-247c-4f7d-b390-0e90add96cc4"\n            }\n        }\n    ],\n    "contentType": "application/json"\n}'
 3457  sbt clean test
 3458  ls -l
 3459  git statu
 3460  cd ..
 3461  l s-l
 3462  ls -l
 3463  cd azkaban
 3464  ls -l
 3465  cd azkaban-gcp-billing
 3466  git status
 3467  git pull
 3468  ls -l
 3469  history | grep pyenv
 3470  pyenv use gpc-billing
 3471  pyenv activate gpc-billing
 3472  ls -l
 3473  history | grep billing
 3474  python billing-gcs-companies-bigdata.py 2019 05 19 y
 3475  python billing-gcs-companies-ga.py 2019 05 19 y
 3476  ls -l
 3477  ./yarn application -list | grep application_1539207608922_216195
 3478  export HADOOP_CONF_DIR=~/configs/conf-prod
 3479  ./yarn application -list | grep application_1539207608922_216195
 3480  ./yarn application -kill application_1539207608922_216195
 3481  pyenv deactivate gpc-billing
 3482  cd ..
 3483  ls -l
 3484  cd ..
 3485  ls -l
 3486  cd kafka_2.11-0.10.1.1
 3487  ls -l
 3488  ./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.qa.globoi.com,kafka02.qa.globoi.com,kafka03.qa.globoi.com:9092 --topic hhs.g1 --time -1
 3489  ./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hhs.g1 --time -1
 3490  ./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hhs.g1 --time -2
 3491  ./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.globoi.com --topic hhs.valor-invest --time -1
 3492  ./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.globoi.com:9092 --topic hhs.valor-invest --time -1
 3493  ./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.globoi.com:9092 --topic hhs.valor-investe --time -1
 3494  ls -l
 3495  cd hadoop-2.7.3
 3496  ls -l
 3497  cd bin
 3498  .hdfs dfs -ls /
 3499  ./hdfs dfs -ls /
 3500  export HADOOP_CONF_DIR=~/configs/conf-prod
 3501  ./hdfs dfs -ls /
 3502  ./hdfs dfs -ls /user/actions/stream/
 3503  ./hdfs dfs -ls /user/actions/stream/checkpoint
 3504  ./hdfs dfs -ls /user/actions/stream/checkpoints
 3505  ./hdfs dfs -ls /user/actions/stream/checkpoints/valor-invest
 3506  ./hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe
 3507  ./hdfs dfs -text /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 3508  ./hdfs dfs -get /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 3509  ./hdfs dfs -put valor-investe_hhs.valor-investe_offsets.txt_2 /user/actions/stream/checkpoints/valor-investe
 3510  history | grep export
 3511  export HADOOP_USER_NAME=hdfs
 3512  ./hdfs dfs -put valor-investe_hhs.valor-investe_offsets.txt_2 /user/actions/stream/checkpoints/valor-investe
 3513  export HADOOP_USER_NAME=hadoop
 3514  ./hdfs dfs -put valor-investe_hhs.valor-investe_offsets.txt_2 /user/actions/stream/checkpoints/valor-investe
 3515  ./hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe
 3516  ./hdfs dfs -chown actions:hdfs /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt_2
 3517  ./hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe
 3518  cd ..
 3519  ls -l
 3520  cd hadoop-2.7.3
 3521  ls -l
 3522  cd bin
 3523  ./yarn application -list | grep application_1539207608922_225186
 3524  ./yarn application -kill application_1539207608922_225186
 3525  ./hdfs dfs -mv /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt_old
 3526  ./hdfs dfs -mv /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt_2 /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 3527  ./hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe
 3528  ./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.globoi.com:9092 --topic hhs.valor-investe --time -2
 3529  ls -l
 3530  pwd
 3531  cd ..
 3532  ls -l
 3533  cd kafka_2.11-0.10.1.1
 3534  ./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.globoi.com:9092 --topic hhs.valor-investe --time -2
 3535  ls -l
 3536  ./hdfs dfs -put valor-investe_hhs.valor-investe_offsets.txt_3 /user/actions/stream/checkpoints/valor-investe
 3537  export HADOOP_CONF_DIR=~/configs/conf-qa
 3538  exit
 3539  export HADOOP_CONF_DIR=~/configs/conf-prod
 3540  cd ..
 3541  ls -l
 3542  cd hadoop-2.7.3
 3543  ls -l
 3544  cd bin
 3545  ./yarn application -list | grep valor-invest
 3546  ls -l
 3547  pwd
 3548  ./yarn application -list | grep valor-investe
 3549  ./yarn application -kill application_1539207608922_225202
 3550  ./hdfs dfs -ls  /user/actions/stream/tenant=valor-investe/actionContentType=feed/actionId=bastian-post-click/actionVersion=1.1/year=2019/month=5/day=20
 3551  cd ..
 3552  ls -l
 3553  cd ..
 3554  cd hadoop2gcs
 3555  cd ..
 3556  cd hadoop-2.7.3
 3557  cd bin
 3558  ./hdfs dfs -ls  /user/actions/stream/tenant=valor-investe/actionContentType=feed/actionId=bastian-post-click/actionVersion=1.1/year=2019/month=5/day=20
 3559  export HADOOP_CONF_DIR=~/configs/conf-prod
 3560  ./hdfs dfs -ls  /user/actions/stream/tenant=valor-investe/actionContentType=feed/actionId=bastian-post-click/actionVersion=1.1/year=2019/month=5/day=20
 3561  ./yarn application -list | grep valor-investe
 3562  cd kafka_2.11-0.10.1.1
 3563  ls -l
 3564  history | grep kafka
 3565  ./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.globoi.com:9092 --topic hhs.valor-investe --time -2
 3566  ./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka01.globoi.com:9092 --topic hhs.valor-investe --time -2
 3567  ./yarn application -list | grep valor-investe
 3568  ./hdfs dfs -mkdir /tmp/valor-invest
 3569  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=feed/actionId=bastian-post-click/actionVersion=1.1/year=2019/month=5/day=20 /tmp/valor-invest/01
 3570  export HADOOP_USER_NAME=hadoop
 3571  ./yarn application -list | grep valor-investe
 3572  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=feed/actionId=bastian-post-click/actionVersion=1.1/year=2019/month=5/day=20 /tmp/valor-invest/01
 3573  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=feed/actionId=bastian-post-view/actionVersion=2.0/year=2019/month=5/day=20 /tmp/valor-invest/02
 3574  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=live-coverage/actionId=live-coverage-focus/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/03
 3575  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=live-coverage/actionId=live-coverage-load/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/04
 3576  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=live-coverage/actionId=live-coverage-post-view/actionVersion=1.1/year=2019/month=5/day=20 /tmp/valor-invest/05
 3577  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=live-coverage/actionId=live-coverage-push-update/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/06
 3578  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=live-coverage/actionId=live-coverage-timeline-view/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/07
 3579  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=live-coverage/actionId=live-coverage-timers/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/08
 3580  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=live-coverage/actionId=live-coverage-unload/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/09
 3581  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=multicontent/actionId=multicontent-chunk-view/actionVersion=3.0/year=2019/month=5/day=20 /tmp/valor-invest/10
 3582  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=multicontent/actionId=multicontent-element-click/actionVersion=3.0/year=2019/month=5/day=20 /tmp/valor-invest/11
 3583  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=multicontent/actionId=multicontent-load/actionVersion=3.0/year=2019/month=5/day=20 /tmp/valor-invest/12
 3584  ./yarn application -list | grep valor-investe
 3585  ./yarn application -kill application_1539207608922_225283
 3586  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=multicontent/actionId=multicontent-view/actionVersion=4.0/year=2019/month=5/day=20 /tmp/valor-invest/13
 3587  ./yarn application -list | grep valor-investe
 3588  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=multicontent/actionId=performance-backend-load/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/14
 3589  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=multicontent/actionId=performance-browser-load/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/15
 3590  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=multicontent/actionId=performance-network-load/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/16
 3591  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=multicontent/actionId=performance-page-load/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/17
 3592  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=multicontent/actionId=performance-user-load/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/18
 3593  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=pages/actionId=pages-component-click/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/19
 3594  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=pages/actionId=pages-component-view/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/20
 3595  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=pages/actionId=pages-view/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/21
 3596  ./hdfs dfs -mv /user/actions/stream/tenant=valor-investe/actionContentType=pes/actionId=pes-sync-id/actionVersion=1.0/year=2019/month=5/day=20 /tmp/valor-invest/22
 3597  history | grep hdfs
 3598  ./hdfs dfs -mv /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt_old_2
 3599  ./hdfs dfs -mv /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt_3 /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 3600  ./hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe
 3601  history | grep chown
 3602  ./hdfs dfs -chown actions:hdfs /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 3603  ./hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe
 3604  cd ..
 3605  ls -l
 3606  cd ..
 3607  ls -l
 3608  cd Projetos
 3609  ls -l
 3610  cd horizon-storage
 3611  git status
 3612  git checkout -b "feat/send_measures_data"
 3613  git status
 3614  git diff
 3615  git add README.md
 3616  git commit -m "docs: add more details of usage on README"
 3617  git status
 3618  git push origin feat/send_measures_data 
 3619  git diff
 3620  make test
 3621  history | grep log
 3622  suru app-log -f -a horizon-track-service-prod | grep mab
 3623  tsuru app-log -f -a horizon-track-service-prod | grep mab
 3624  tsuru app-log -f -a horizon-metric-processor-prod\n
 3625  tsuru app-log -f -a horizon-track-service-prod
 3626  tsuru app-log -f -a horizon-track-service-prod | grep ab_conversion
 3627  ls -l
 3628  ./hdfs dfs -ls /parquet
 3629  ./hdfs dfs -ls /parquet/ab
 3630  ./hdfs dfs -ls /parquet/ab/impressions
 3631  git status
 3632  git diff
 3633  export HADOOP_CONF_DIR=~/configs/conf-prod
 3634  sbt clean publishLocal
 3635  cd ..
 3636  ls -l
 3637  cd ..
 3638  ls -l
 3639  cd Projetos
 3640  ls -l
 3641  cd hydrogen
 3642  ls -l
 3643  cd hydrogen.warehouse
 3644  ls -l
 3645  history | grep videosession
 3646  history | grep videolivesession.sh
 3647  ./videolivesession.sh
 3648  git status
 3649  git diff
 3650  git diff src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonReader.scala
 3651  git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonReader.scala
 3652  git commit -m "fix: measures don't support LocalDateTime dates"
 3653  git status
 3654  git diff
 3655  git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/config/HorizonConfiguration.scala
 3656  git commit -m "feat: get configurations from environment"
 3657  git status
 3658  git diff
 3659  git add .
 3660  git commit -m "feat: measures calls should not throw errors"
 3661  git status
 3662  git push origin feat/send_measures_data 
 3663  ./yarn application -list | grep application_1539207608922_225288
 3664  cd ..
 3665  ls -l
 3666  cd ..
 3667  cd hadoop-2.7.3
 3668  ls -l
 3669  cd bin
 3670  ./yarn application -list | grep application_1539207608922_225288
 3671  ./yarn application -kill application_1539207608922_225288
 3672  ls -l
 3673  cd ..
 3674  cd Projetos
 3675  cd hydrogen
 3676  ls -l
 3677  git status
 3678  git diff
 3679  git diff hydrogen.commons/src/main/scala/hydrogen/commons/google/StorageService.scala
 3680  git checkout hydrogen.commons/src/main/scala/hydrogen/commons/google/StorageService.scala
 3681  git status
 3682  git diff hydrogen.warehouse/src/main/scala/hydrogen/warehouse/utils/PartitionByUtils.scala
 3683  git add hydrogen.warehouse/src/main/scala/hydrogen/warehouse/utils/PartitionByUtils.scala
 3684  git commit -m "fix: params order"
 3685  git status
 3686  git diff
 3687  git add hydrogen.commons/src/main/resources/hadoop.qa.properties
 3688  git commit -m "fix: backstage url"
 3689  git status
 3690  git diff
 3691  git push origin feat/use-horizon-storage-api 
 3692  ls -l
 3693  vi Makefile
 3694  git status
 3695  git pull
 3696  sbt clean publishLocal
 3697  ls -l
 3698  cd ..
 3699  ls -l
 3700  cd ..
 3701  cd hadoop-2.7.3
 3702  cd bin
 3703  ./hdfs dfs -ls /user/warehouse/bin
 3704  export HADOOP_CONF_DIR=~/configs/conf-prod
 3705  export HADOOP_USER_NAME=hadoop
 3706  ./hdfs dfs -ls /user/warehouse/bin
 3707  ls -l
 3708  pwd
 3709  ./hdfs dfs -put /Users/leonardo.neuwald/Projetos/horizon-storage/target/scala-2.11/horizon-storage_2.11-0.1.2-SNAPSHOT.jar /user/warehouse/bin
 3710  ./hdfs dfs -ls /user/warehouse/bin
 3711  ./hdfs dfs -chown warehouse:hdfs /user/warehouse/bin/horizon-storage_2.11-0.1.2-SNAPSHOT.jar
 3712  ./hdfs dfs -chmod 755 /user/warehouse/bin/horizon-storage_2.11-0.1.2-SNAPSHOT.jar
 3713  ./hdfs dfs -ls /user/warehouse/bin
 3714  ./hdfs dfs -put /Users/leonardo.neuwald/Downloads/measures-scala_2.11-0.0.5.jar /user/warehouse/bin
 3715  ./hdfs dfs -chmod 755 /user/warehouse/bin/measures-scala_2.11-0.0.5.jar
 3716  ./hdfs dfs -chown warehouse:hdfs /user/warehouse/bin/measures-scala_2.11-0.0.5.jar
 3717  ./hdfs dfs -ls /user/warehouse/bin
 3718  ~/gradle/gradle-2.14/bin/gradle clean build
 3719  ls -l
 3720  cd gradle-2.0
 3721  ls -l
 3722  cd ..
 3723  ls -l
 3724  cd hydrogen.warehouse
 3725  ls- l
 3726  ls -l
 3727  ./deploy_jar.sh
 3728  git status
 3729  git checkout src/main/scala/hydrogen/warehouse/VideoLiveSessionMain.scala
 3730  git pull
 3731  ./deploy_jar.sh prod
 3732  ./deploy_jar.sh prod warehouse
 3733  ~/gradle/gradle-2.14/bin/gradle clean build
 3734  ./deploy_jar.sh prod warehouse
 3735  ./hdfs dfs -ls /user/warehouse/bin
 3736  git status
 3737  git checkout ../hydrogen.commons/src/main/scala/hydrogen/commons/job/DateJobTools.scala
 3738  git status
 3739  git diff
 3740  vi ./deploy_jar.sh
 3741  cd ..
 3742  ls -l
 3743  vi deploy_jar.sh
 3744  ~/gradle/gradle-2.14/bin/gradle clean build
 3745  git status
 3746  git diff
 3747  sbt clean publishLocal
 3748  cd hydrogen.warehouse
 3749  ls -l
 3750  ./deploy_jar.sh prod warehouse
 3751  ./hdfs dfs -rmr /Users/leonardo.neuwald/Projetos/horizon-storage/target/scala-2.11/horizon-storage_2.11-0.1.2-SNAPSHOT.jar
 3752  ./hdfs dfs -put /Users/leonardo.neuwald/Projetos/horizon-storage/target/scala-2.11/horizon-storage_2.11-0.1.2-SNAPSHOT.jar /user/warehouse/bin
 3753  ./hdfs dfs -rmr /user/warehouse/bin/horizon-storage_2.11-0.1.2-SNAPSHOT.jar
 3754  ./hdfs dfs -put /Users/leonardo.neuwald/Projetos/horizon-storage/target/scala-2.11/horizon-storage_2.11-0.1.2-SNAPSHOT.jar /user/warehouse/bin
 3755  ./hdfs dfs -chown warehouse:hdfs /user/warehouse/bin/horizon-storage_2.11-0.1.2-SNAPSHOT.jar
 3756  ./hdfs dfs -chmod 755 /user/warehouse/bin/horizon-storage_2.11-0.1.2-SNAPSHOT.jar
 3757  git status
 3758  git diff
 3759  git add .
 3760  git commit -m "feat: print params"
 3761  git status
 3762  git add .
 3763  git commit -m "feat: print params"
 3764  git push origin feat/send_measures_data 
 3765  git status
 3766  git diff
 3767  git status
 3768  git diff
 3769  git pill
 3770  git pull
 3771  git pull origin feat/send_measures_data 
 3772  git status
 3773  git diff src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonReader.scala
 3774  git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonReader.scala
 3775  git commit -m "fix: variable names should be more descritible"
 3776  git status
 3777  git add .
 3778  git commit -m "docs: changelog for version 0.2.0"
 3779  git push origin feat/send_measures_data 
 3780  git statuis
 3781  cd ..
 3782  git status
 3783  git diff
 3784  git status
 3785  git diff hydrogen.warehouse/airflow_jobs/videolivesession_daily.py
 3786  git status
 3787  git diff hydrogen.warehouse/airflow_jobs/videolivesession_daily.py
 3788  git status
 3789  git diff hydrogen.warehouse/airflow_jobs/recommendeditems_daily.py
 3790  git status
 3791  git diff
 3792  git status
 3793  git diff hydrogen.warehouse/airflow_jobs/pagetracknew_daily.py
 3794  git status
 3795  git diff
 3796  git status
 3797  git diff hydrogen.warehouse/videolivesession.sh
 3798  git checkout hydrogen.warehouse/videolivesession.sh
 3799  git status
 3800  git diff hydrogen.warehouse/airflow_jobs/pagetracknew_daily.py
 3801  git diff hydrogen.warehouse/airflow_jobs/postviewsession_daily.py
 3802  git diff hydrogen.warehouse/airflow_jobs/recommendeditems_daily.py
 3803  git diff hydrogen.warehouse/airflow_jobs/videosession_daily.py
 3804  git diff hydrogen.warehouse/airflow_jobs/videolivesession_daily.py
 3805  git status
 3806  git diff hydrogen.warehouse/airflow_jobs/pagetracknew_daily.py
 3807  git diff 
 3808  git status
 3809  git add hydrogen.warehouse/airflow_jobs
 3810  git status
 3811  git commit -m "feat: add horizon-storage on extra-jars"
 3812  git push origin feat/use-horizon-storage-api 
 3813  ./hdfs dfs -ls /user/warehouse/bin/horizon-storage_2.11-0.1.2-SNAPSHOT.jar
 3814  ./hdfs dfs -mv /user/warehouse/bin/horizon-storage_2.11-0.1.2-SNAPSHOT.jar /user/warehouse/bin/horizon-storage.jar
 3815  ./hdfs dfs -ls /user/warehouse/bin/
 3816  ./hdfs dfs -mv /user/warehouse/bin/measures-scala_2.11-0.0.5.jar /user/warehouse/bin/measures-scala.jar
 3817  git status
 3818  git diff
 3819  git commit -m "fix: support diferents date inputs"
 3820  git add .
 3821  git commit -m "fix: support diferents date inputs"
 3822  git push origin feat/use-horizon-storage-api 
 3823  git checkout master
 3824  git status
 3825  git pull
 3826  make release
 3827  git status
 3828  git fetch
 3829  git fetch --all
 3830  cd ..
 3831  ls -l
 3832  cd azkaban
 3833  ls -l
 3834  cd azkaban-gcp-billing
 3835  cd ..
 3836  ls -l
 3837  cd pipeline-horizon-stream-ingest
 3838  git status
 3839  git checkout master
 3840  git pull
 3841  git status
 3842  git diff
 3843  git pull
 3844  ./yarn application -list | grep application_1539207608922_225936
 3845  ./yarn application -kill application_1539207608922_225936
 3846  ./yarn application -kill application_1539207608922_226713
 3847  ./yarn application -kill application_1539207608922_226734
 3848  history | grep kafka
 3849  echo $KAFKA_HOME
 3850  cd ..
 3851  ls -l
 3852  cd roteiros-artesanais/kafka
 3853  ls -l
 3854  chmod 777 get_earliest_offset_in_topic.sh
 3855  ./get_earliest_offset_in_topic.sh
 3856  ./get_earliest_offset_in_topic.sh hhs.valor-investe
 3857  git status
 3858  cd ..
 3859  git status
 3860  git diff kafka-consumer.py
 3861  vi kafka-consumer.py
 3862  git status
 3863  git add README.md kafka/create_hhs_and_hzt_topics kafka/create_hhs_and_hzt_topics.sh kafka/get_earliest_offset_in_topic.sh
 3864  git status
 3865  git commit -m "feat: add script to get earliest offset still in a topic"
 3866  git push origin master
 3867  cd ..
 3868  ls -l
 3869  cd azkaban/
 3870  ls -l
 3871  cd pipeline-horizon-stream-ingest
 3872  git status
 3873  git pull
 3874  git checkout -b "fix/valor-investe-resources"
 3875  git add .
 3876  git commit -m "fix: increase valor-investe resources"
 3877  git status
 3878  git push origin fix/valor-investe-resources 
 3879  git status
 3880  git diff hydrogen.warehouse/airflow_jobs/videosession_daily.py
 3881  git status
 3882  git diff
 3883  git status
 3884  git diff hydrogen.warehouse/airflow_jobs/postviewsession_daily.py
 3885  ./hdfs dfs -ls /warehouse/videolivesession/parquet
 3886  ./hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=g1
 3887  ./hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=g1/year=2019
 3888  ./hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=g1/year=2019/month=5
 3889  ./hdfs dfs -du -h /warehouse/videolivesession/parquet/glb_product=g1/year=2019/month=5
 3890  ./hdfs dfs -du -h /warehouse/videosession/parquet/glb_product=g1/year=2019/month=5
 3891  ./hdfs dfs -du -h /warehouse/postviewsession/parquet/glb_product=g1/year=2019/month=5
 3892  git status
 3893  git diff
 3894  git diff hydrogen.warehouse/airflow_jobs/videosession_daily.py
 3895  ./yarn application -list | grep application_1539207608922_226560
 3896  ./yarn application -kill application_1539207608922_226560
 3897  cd ..
 3898  ls l
 3899  ls -l
 3900  cd horizon-storage
 3901  git status
 3902  git pull
 3903  git checkout -b "feat/measures-fields"
 3904  git status
 3905  make test
 3906  git status
 3907  git add .
 3908  git commit -m "fix: file size should't consider replication"
 3909  git push origin feat/measures-fields 
 3910  cd ..
 3911  ls -l
 3912  cd hydrogen
 3913  ls -l
 3914  git status
 3915  git diff hydrogen.warehouse/airflow_jobs/videosession_daily.py
 3916  git diff
 3917  git diff hydrogen.warehouse/airflow_jobs/postviewsession_daily.py
 3918  git status
 3919  git diff
 3920  git status
 3921  git diff
 3922  ./yarn application -list | grep application_1539207608922_226670
 3923  ./yarn application -kill application_1539207608922_226670
 3924  git status
 3925  git diff
 3926  ./yarn application -kill application_1539207608922_226928
 3927  git diff
 3928  git status
 3929  git add build.gradle
 3930  git commit -m "chore: update horizon-storage version"
 3931  git status
 3932  git add .
 3933  git commit -m "fix: commit window_job on git, this job already exists on airflow"
 3934  git status
 3935  git push origin feat/use-horizon-storage-api 
 3936  cd ..
 3937  ls -l
 3938  cd horizon_events_aggregator
 3939  git status
 3940  git pull
 3941  git status
 3942  git diff
 3943  git diff src/test/scala/com/globo/pipeline/HorizonEventsAggregatorTest.scala
 3944  sbt clean test
 3945  pwd
 3946  code .
 3947  vcode .
 3948  sbt clean test
 3949  sbt test
 3950  ls -l
 3951  pwd
 3952  cd ..
 3953  cd .
 3954  cd ..
 3955  cd horizon-s
 3956  cd horizon-storage
 3957  git status
 3958  git diff
 3959  sbt clean test
 3960  git status
 3961  git diff
 3962  git status
 3963  git diff
 3964  git log
 3965  git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonReader.scala
 3966  git status
 3967  sbt clean compile
 3968  sbt clean test
 3969  git stats
 3970  git status
 3971  git commit -m "feat: add timeBetweenFilter and timeSince measures"
 3972  git push origin feat/measures-fields 
 3973  cd ..
 3974  ls -l
 3975  cd hydrogen
 3976  git status
 3977  git diff
 3978  git add .
 3979  git commit -m "fix: add newline at end of file"
 3980  git push origin feat/use-horizon-storage-api 
 3981  git status
 3982  git diff
 3983  git add .
 3984  git commit -m "fix: add newline at end of file"
 3985  git push origin feat/use-horizon-storage-api 
 3986  git checkout master
 3987  git pull
 3988  sbt clean test
 3989  git status
 3990  git diff src/main/scala/com/globo/pipeline/horizoneventsagg/HorizonEventsAggregator.scala
 3991  sbt clean test
 3992  pwd
 3993  ./yarn application -list | grep application_1539207608922_232642
 3994  history | grep export
 3995  export HADOOP_CONF_DIR=~/configs/conf-prod
 3996  ./yarn application -list | grep application_1539207608922_232642
 3997  ./yarn application -kill application_1539207608922_232642
 3998  sbt clean test
 3999  sbt  test
 4000  ls -l
 4001  cd ..
 4002  ls -l
 4003  cd azkaban
 4004  ls -l
 4005  cd pipeline-horizon-stream-ingest
 4006  git status
 4007  git checkout master
 4008  git pull
 4009  make zip
 4010  git status
 4011  ls -l
 4012  cd ..
 4013  ls -l
 4014  cd horizon_events_aggregator
 4015  ls -l
 4016  gut status
 4017  git status
 4018  ls -l /tmp
 4019  ls -l /tmp/t
 4020  rm -rf /tmp/t
 4021  ls -l /tmp
 4022  ls -l /tmp/
 4023  ls- l
 4024  ls -l
 4025  ./hdfs dfs -ls /user/actions/confs
 4026  ./hdfs dfs -get /user/actions/confs
 4027  ls -l
 4028  ./yarn application -list | grep application_1539207608922_221350
 4029  ./yarn application -kill application_1539207608922_221350
 4030  ./yarn application -kill application_1539207608922_221351
 4031  cd ..
 4032  ls -l
 4033  cd azkaban
 4034  ls -l
 4035  cd pipeline-horizon-stream-ingest
 4036  ls -l
 4037  git status
 4038  git diff
 4039  make zip
 4040  ./yarn application -list | grep application_1539207608922_233231
 4041  git status
 4042  git diff
 4043  git status
 4044  git diff
 4045  git status
 4046  git diff
 4047  make zip
 4048  git diff
 4049  git status
 4050  make zip
 4051  git diff
 4052  make zip
 4053  ./yarn application -kill application_1539207608922_233231
 4054  ./yarn application -kill application_1539207608922_231777
 4055  ./yarn application -kill application_1539207608922_233265
 4056  ./yarn application -kill application_1539207608922_233266
 4057  ./yarn application -kill application_1539207608922_230724
 4058  ls -l
 4059  cd ..
 4060  ls -l
 4061  cd pipeline-queue-swap
 4062  git status
 4063  git pull
 4064  git status
 4065  git diff
 4066  git status
 4067  git diff
 4068  git status
 4069  git checkout -b "fix/params-order"
 4070  git status
 4071  git add .
 4072  git status
 4073  git add .
 4074  git status
 4075  git commit -m "fix: queue-to and queue-from params order"
 4076  git push origin fix/params-order 
 4077  cd ..
 4078  ls -l
 4079  cd pipeline-horizon-stream-ingest
 4080  git status
 4081  git diff
 4082  git status
 4083  git diff
 4084  git status
 4085  git diff
 4086  git stats
 4087  git status
 4088  git diff
 4089  git add jobs/horizon-track-event-stream-flow/hzt.player.job
 4090  git checkout -b fix/player-resources
 4091  git status
 4092  git commit -m "fix: increase hzt.player executor memory"
 4093  git statys
 4094  git status
 4095  git add jobs/horizon-avro-stream-flow/avro.hdfs.checker.job
 4096  git add jobs/horizon-avro-stream-flow/avro.postview.job
 4097  git status
 4098  git commit -m "feat: remove avro.postview job"
 4099  git status
 4100  git add .
 4101  git commit -m "docs: update changelog"
 4102  git status
 4103  git push origin fix/player-resources 
 4104  cd ..
 4105  cd pipeline-horizon-stream-ingest
 4106  git checkout master
 4107  git pull
 4108  git status
 4109  git diff 
 4110  cd ..
 4111  ls -l
 4112  git clone gitlab@gitlab.globoi.com:BigDataPipeline/horizon_events_aggregator.git horizon_events_aggregator_master
 4113  cd horizon_events_aggregator_master
 4114  ls -l
 4115  cd ..
 4116  ls -l
 4117  cd ..
 4118  ls -l
 4119  cd horizon_events_aggregator
 4120  git status
 4121  git checkout -b "feat/use-horizon-storage"
 4122  git checkout src/test/scala/com/globo/pipeline/HorizonEventsAggregatorTest.scala
 4123  git diff
 4124  git status
 4125  git add .
 4126  git commit -m "style: reformat file with intellij"
 4127  git status
 4128  git add .
 4129  git commit -m "style: reformat file with intellij"
 4130  sbt clean test
 4131  git status
 4132  git diff
 4133  git add .
 4134  git commit -m "feat: add horizon-storage dependency"
 4135  sbt clean test
 4136  git status
 4137  git add .
 4138  git commit -m "refactor: remove useless code"
 4139  git status
 4140  sbt clean test
 4141  git status
 4142  git diff src/main/scala/com/globo/pipeline/horizoneventsagg/HorizonEventsAggregator.scala
 4143  sbt clean test
 4144  git status
 4145  git diff
 4146  git add .
 4147  git commit -m "feat: change code to use horizon-storage api"
 4148  git status
 4149  git push origin feat/use-horizon-storage 
 4150  git status
 4151  git diff
 4152  git status
 4153  git add .
 4154  git commit -m "feat: update aggConfs and airflow jobs"
 4155  git status
 4156  git push origin feat/use-horizon-storage 
 4157  cd ..
 4158  ls -l
 4159  cd horizon-storage
 4160  git status
 4161  git diff
 4162  git checkout src/main/scala/com/globo/bigdata/pipeline/horizonstorage/config/HorizonConfiguration.scala
 4163  git pull
 4164  sbt clean test
 4165  git status
 4166  git pull
 4167  sbt clean test
 4168  git status
 4169  git checkout master
 4170  git checkout feat/use-horizon-storage 
 4171  cd ..
 4172  cd horizon-storage
 4173  git checkout master
 4174  git pull
 4175  git status
 4176  git checkout -b "chore/gitlab-ci"
 4177  git status
 4178  git commit -m "chore: add gitlab-ci"
 4179  git push origin chore/gitlab-ci 
 4180  git checkout master
 4181  git pull
 4182  make release
 4183  ls -l
 4184  git pull origin master
 4185  ls -l
 4186  history | grep hdfs
 4187  cd ~/Downloads
 4188  ls -l
 4189  ls -l ~/Desktop/q
 4190  ls -l ~/Desktop/
 4191  ls -l ~/Downloads
 4192  history | grep hdfs
 4193  ./hdfs dfs -ls /user/warehouse/bin
 4194  ./hdfs dfs -put /Users/leonardo.neuwald/Downloads/horizon-storage_2.11-0.2.1.jar /user/warehouse/bin
 4195  history | grep export
 4196  export HADOOP_USER_NAME=hadoop
 4197  ./hdfs dfs -put /Users/leonardo.neuwald/Downloads/horizon-storage_2.11-0.2.1.jar /user/warehouse/bin
 4198  ./hdfs dfs -ls /user/warehouse/bin
 4199  ./hdfs dfs -chown warehouse:hdfs /user/warehouse/bin/horizon-storage_2.11-0.2.1.jar
 4200  ./hdfs dfs -chmod 775 /user/warehouse/bin/horizon-storage_2.11-0.2.1.jar
 4201  ./hdfs dfs -ls /user/warehouse/bin
 4202  ./hdfs dfs -mv /user/warehouse/bin/horizon-storage.jar /user/warehouse/bin/horizon-storage_old.jar
 4203  ./hdfs dfs -mv /user/warehouse/bin/horizon-storage_2.11-0.2.1.jar /user/warehouse/bin/horizon-storage.jar
 4204  ./hdfs dfs -ls /user/warehouse/bin
 4205  history | grep export
 4206  export HADOOP_CONF_DIR=~/configs/conf-qa
 4207  ./hdfs dfs -ls /user/actions/confs/agg-multicontent_v1.json
 4208  ./hdfs dfs -ls /user/actions/confs
 4209  ./hdfs dfs -ls /user/actions
 4210  export HADOOP_USER_NAME=actions
 4211  ./hdfs dfs -mkdir /user/actions/confs
 4212  ./hdfs dfs -ls /user/actions/stream
 4213  ./hdfs dfs -ls /user/actions/stream/tenant=ab
 4214  ./hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab
 4215  ./hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionsId=ab-impression
 4216  ./hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression
 4217  ./hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.0
 4218  ./hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.0/year=2019
 4219  ./hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.0/year=2019/month=5
 4220  ssh datascience-qa-be01.cmal08be-1140.cp.globoi.com\n
 4221  ./hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.0/year=2019/month=5/day=14
 4222  export HADOOP_CONF_DIR=~/configs/conf-prod
 4223  ./hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.0/year=2019/month=5
 4224  export HADOOP_CONF_DIR=~/configs/conf-qa
 4225  ./hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.0/year=2019/month=5
 4226  ./hdfs dfs -ls /user/actions/confs
 4227  ls -l
 4228  cd ~/Projetos/
 4229  ls -l
 4230  cd horizon_events_aggregator
 4231  ls -l
 4232  git status
 4233  cd ..
 4234  cd horizon_events_aggregator_master
 4235  git status
 4236  git diff
 4237  pwd
 4238  ./hdfs dfs -put /Users/leonardo.neuwald/Projetos/horizon_events_aggregator_master/tasks/agg-ab_v2.json /user/actions/confs
 4239  ./hdfs dfs -ls /user/actions/confs
 4240  ls -l
 4241  git status
 4242  sbt clean compile
 4243  ./horizon_events_agg_prod.sh
 4244  history | grep SPARK
 4245  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7"
 4246  ./horizon_events_agg_prod.sh
 4247  export HADOOP_CONF_DIR="~/configs/conf-qa"
 4248  export HADOOP_CONF_DIR=~/configs/conf-qa
 4249  ./horizon_events_agg_prod.sh
 4250  make build
 4251  ./horizon_events_agg_prod.sh
 4252  make build
 4253  ./horizon_events_agg_prod.sh
 4254  vi ./horizon_events_agg_prod.sh
 4255  ./horizon_events_agg_prod.sh
 4256  export HADOOP_CONF_DIR=~/configs/conf-qa
 4257  ./hdfs dfs -ls /tmp/agg/mc_test1/year=2019/month=5/day=14
 4258  ./hdfs dfs -rmr /tmp/agg/mc_test1/year=2019/month=5/day=14
 4259  ./horizon_events_agg_prod.sh
 4260  ./hdfs dfs -get /tmp/agg/mc_test1/year=2019/month=5
 4261  ls -l
 4262  cd ..
 4263  ls -l
 4264  git status
 4265  git diff
 4266  ls -l
 4267  cd ..
 4268  ls -l
 4269  cd ..
 4270  ls -l
 4271  cd ..
 4272  ls -l
 4273  cd ~
 4274  ls -l
 4275  cd Projetos
 4276  ls -l
 4277  cd horizon-storage
 4278  ls -l
 4279  git checkout chore/gitlab-ci
 4280  git status
 4281  mvn clean test
 4282  sbt clean test
 4283  sbt test
 4284  git status
 4285  git checkout
 4286  git status
 4287  git checkout src/main/scala/com/globo/bigdata/pipeline/horizonstorage/config/HorizonConfiguration.scala
 4288  git checkout src/test/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonReaderTest.scala
 4289  git status
 4290  git add .
 4291  git commit -m "docs: update changelog"
 4292  git push origin chore/gitlab-ci 
 4293  git status
 4294  git diff
 4295  git checkout horizon_events_agg_prod.sh  project/Dependencies.scala tasks/horizon-events-agg-poetica.py tasks/agg-ab_v2.json
 4296  git status
 4297  git checkout horizon_events_agg_prod.sh  project/Dependencies.scala tasks/horizon-events-agg-poetica.py
 4298  ls -l
 4299  git status
 4300  rm -rf tasks/agg-ab_v2.json
 4301  ls -l
 4302  git status
 4303  git pull
 4304  cd ..
 4305  ls -l
 4306  cd horizon_events_aggregator_master
 4307  ls -l
 4308  cp tasks ~/Projetos
 4309  cp -R tasks ~/Projetos
 4310  ls -l ~Projetos
 4311  ls -l ~/Projetos
 4312  git status
 4313  git rebase -i
 4314  git status
 4315  git pull
 4316  git diff
 4317  cd ..
 4318  ls -l
 4319  cd ..
 4320  ls -l
 4321  cd ..
 4322  cd bigdata
 4323  ls -
 4324  ls -l
 4325  cd pipeline
 4326  cd ..
 4327  ls -l
 4328  cd test-repo
 4329  ls -l
 4330  git pull
 4331  git checkout master
 4332  git pull
 4333  mkdir file2
 4334  vi file2
 4335  rm -rf file2
 4336  touch file2
 4337  touch file3
 4338  touch file4
 4339  touch file5
 4340  vi file2
 4341  vi file3
 4342  vi file4
 4343  vi file5
 4344  git add file2
 4345  git commit -m "vai 1"
 4346  git add file3
 4347  git commit -m "vai 2"
 4348  git push origin master
 4349  git add file4
 4350  git add file5
 4351  git commit -m "vai 3"
 4352  git push origin master
 4353  git status
 4354  git log
 4355  git commit --amend
 4356  git status
 4357  git push origin master
 4358  git push --force
 4359  git pull
 4360  git status
 4361  git push origin master
 4362  git rebase -i HEAD~3
 4363  git rebase -i HEAD~6
 4364  git rebase -i HEAD~4
 4365  git rebase -i HEAD~3
 4366  :q!
 4367  git status
 4368  cd ..
 4369  rm -rf test-repo
 4370  git clone gitlab@gitlab.globoi.com:leonardo.neuwald/test-repo.git
 4371  cd test-repo
 4372  git status
 4373  git rebase -i master\n
 4374  git status
 4375  git log
 4376  git status
 4377  git pull
 4378  git rebase -i master\n
 4379  git reset 536e361
 4380  git status
 4381  git push origin master
 4382  git push -f
 4383  git pull
 4384  git status
 4385  git reset 536e361
 4386  git status
 4387  git log
 4388  git push origin master --force
 4389  git pull
 4390  git status
 4391  git pull
 4392  git reset 536e361
 4393  git status
 4394  git push origin master --force
 4395  git rebase -i master
 4396  git rebase -i origin/master
 4397  git rebase -i origin
 4398  git rebase -i
 4399  git status
 4400  git pull
 4401  ls -l
 4402  cd ..
 4403  ls -l
 4404  cd pipeline-jobs-commons
 4405  cd ..
 4406  ls -l
 4407  cd horizon_events_aggregator_master
 4408  ls -l
 4409  history
 4410  cd ..
 4411  cd hadoop-2.7.3
 4412  ls -l
 4413  cd ..
 4414  s -l
 4415  cd configs
 4416  ls -l
 4417  cd conf-prod
 4418  vi hdfs-site.xml
 4419  export HADOOP_CONF_DIR=~/configs/conf-prod
 4420  cd ..
 4421  cd ,,
 4422  cd ..
 4423  cd hadoop-2.7.3
 4424  cd bin
 4425  ./hdfs dfs -ls /
 4426  cd ..
 4427  ls -l 
 4428  cd configs
 4429  ls -l
 4430  cd conf-prod
 4431  vi hdfs-site.xml
 4432  cd ..
 4433  cd .
 4434  cd ..
 4435  ls -l
 4436  cd hadoop-2.7.3
 4437  cd bin
 4438  ./yarn aplication -list | grep application_1539207608922_231790
 4439  ./yarn application -list | grep application_1539207608922_231790
 4440  ./yarn application -kill application_1539207608922_231790
 4441  ls -l
 4442  cd ..
 4443  ls -l
 4444  cd horizon-client-ios
 4445  git status
 4446  cd ..
 4447  git checkout gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client-ios.git horizon-ios
 4448  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client-ios.git horizon-ios
 4449  cd horizon-ios
 4450  ls -l
 4451  git checkout feature/change-architecture 
 4452  git pull
 4453  git status
 4454  git checkout HorizonClient/HorizonClient.xcodeproj/project.pbxproj
 4455  cd ..
 4456  cd horizon-client-ios
 4457  ls -l
 4458  git status
 4459  git diff HorizonClient/HorizonClient.xcodeproj/project.pbxproj
 4460  cd ..
 4461  ls -l
 4462  cd horizon-ios
 4463  ld -l
 4464  ls -l
 4465  git status
 4466  ls -l
 4467  git status
 4468  git checkout HorizonClient/HorizonClient.xcodeproj/project.pbxproj
 4469  ls -l
 4470  cd HorizonClient
 4471  ls -l
 4472  git status
 4473  git diff
 4474  git checkout HorizonClient.xcodeproj/project.pbxproj
 4475  ls -l
 4476  cd ..
 4477  ls -l
 4478  cd ..
 4479  ls -l
 4480  rm -rf horizon-ios
 4481  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client-ios.git horizon-ios
 4482  rm -rf horizon-ios
 4483  cd ..
 4484  cd Projetos
 4485  ls -l
 4486  mv horizon-client-ios horizon-client-ios_old
 4487  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client-ios.git
 4488  rm -rf horizon-client-ios
 4489  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client-ios.git
 4490  rm -rf horizon-client-ios
 4491  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client-ios.git
 4492  rm -rf horizon-client-ios
 4493  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client-ios.git
 4494  git status
 4495  cd horizon-client-ios
 4496  git clone feature/change-architecture
 4497  git checkout feature/change-architecture
 4498  git pull
 4499  pop install
 4500  git status
 4501  git checkout HorizonClient/HorizonClient.xcodeproj/project.pbxproj
 4502  pod install
 4503  cd HorizonClient
 4504  pod install
 4505  git status
 4506  cd ..
 4507  ls -l
 4508  git status
 4509  git diff
 4510  git status
 4511  git diff
 4512  git status
 4513  git add .
 4514  git commit -m "fix: use the new identification route"
 4515  git status
 4516  git push origin feature/change-architecture 
 4517  git status
 4518  git diff
 4519  git add .
 4520  git commit -m "feat: equalize properties with Android"
 4521  git push origin feature/change-architecture 
 4522  git checkout master
 4523  git pull
 4524  code
 4525  code .
 4526  git status
 4527  git checkout -b "chore/update-client-version"
 4528  git add .
 4529  git commit -m "chore: update client version"
 4530  git push origin chore/update-client-version 
 4531  git checkout master
 4532  git pull
 4533  pwd
 4534  git status
 4535  git add .
 4536  git commit -m "chore: add swift_version and change the author"
 4537  git push origin master
 4538  xcode-select -p
 4539  carthage
 4540  brew install carthage
 4541  ls -l HorizonClient
 4542  cd HorizonClient
 4543  pod repo push globoi HorizonClient.podspec --allow-warnings --verbose
 4544  pod repo add 
 4545  pod repo add globoi https://github.com/globoi/pods-repository
 4546  pod repo push globoi HorizonClient.podspec --allow-warnings --verbose
 4547  xcrun simctl
 4548  xcode-select -p
 4549  xcode-select --switch /Applications/Xcode.app/Contents/Developer
 4550  sudo xcode-select --switch /Applications/Xcode.app/Contents/Developer
 4551  xcrun simctl
 4552  cd ..
 4553  ls -l
 4554  cd HorizonClient
 4555  carthage build --no-skip-current --platform ios --configuration Release
 4556  carthage archive HorizonClient
 4557  pwd
 4558  cd ..
 4559  cd leonardo.neuwald
 4560  cd Projetos
 4561  git clone git@github.com:globoi/horizon-client-ios-bin-releases.git
 4562  ls -l
 4563  cd horizon-client-ios-bin-releases
 4564  ls -l
 4565  cd Frameworks
 4566  ls -l
 4567  cd Carthage
 4568  ls -l
 4569  cd ..
 4570  unzip HorizonClient.framework.zip
 4571  ls -l
 4572  mv ~/Projetos/horizon-client-ios/Carthage/Build/iOS/HorizonClient.framework ~/Projetos/horizon-client-ios-bin-releases/Frameworks
 4573  rm -f ~/Projetos/horizon-client-ios-bin-releases/Frameworks/HorizonClient.framework
 4574  rm -rf ~/Projetos/horizon-client-ios-bin-releases/Frameworks/HorizonClient.framework
 4575  ls -l ~/Projetos/horizon-client-ios-bin-releases/Frameworks
 4576  git status
 4577  mv ~/Projetos/horizon-client-ios/Carthage/Build/iOS/HorizonClient.framework ~/Projetos/horizon-client-ios-bin-releases/Frameworks
 4578  git status
 4579  git add .
 4580  git status
 4581  ls -l
 4582  git status
 4583  rm -rf HorizonClient.framework.zip ../HorizonClient.framework.zip
 4584  git status
 4585  git diff
 4586  git pull
 4587  carthage build --no-skip-current --platform ios --configuration Release
 4588  carthage archive HorizonClient
 4589  rm -rf ~/Projetos/horizon-client-ios-bin-releases/Frameworks/HorizonClient.framework
 4590  mv ~/Projetos/horizon-client-ios/HorizonClient/Carthage\ 2/Build/iOS/HorizonClient.framework  ~/Projetos/horizon-client-ios-bin-releases/Frameworks
 4591  git status
 4592  git checkout HorizonClient.framework
 4593  git status
 4594  cd ..
 4595  ls -l
 4596  cd ..
 4597  rm -rf horizon-client-ios-bin-releases
 4598  git clone git@github.com:globoi/horizon-client-ios-bin-releases.git
 4599  git status
 4600  rm -rf HorizonClient.framework.zip
 4601  git status
 4602  carthage build --no-skip-current --platform ios --configuration Release
 4603  carthage archive HorizonClient
 4604  pwd
 4605  ls -l
 4606  pwd
 4607  cd horizon-client-ios-bin-releases
 4608  ls -l
 4609  cd Frameworks
 4610  ls -l
 4611  rm -rf HorizonClient.framework
 4612  pwd
 4613  mv Carthage2/Build/iOS/HorizonClient.framework /Users/leonardo.neuwald/Projetos/horizon-client-ios-bin-releases/Frameworks
 4614  git status
 4615  history | grep clone
 4616  git status
 4617  git diff
 4618  git add .
 4619  git commit -m "Update framework to version 1.0.0-xcode10.1"
 4620  git status
 4621  git push origin master
 4622  git tag 1.0.0-xcode10.1
 4623  git push origin --tags\n
 4624  git status
 4625  rm -rf HorizonClient.framework.zip
 4626  git pull
 4627  pod repo push globoi HorizonClient.podspec --allow-warnings --verbose
 4628  ls -l
 4629  cd ..
 4630  ls -l
 4631  cd .
 4632  cd ..
 4633  ls -l
 4634  cd horizon-storage
 4635  git status
 4636  git diff
 4637  sbt clean test
 4638  sbt clean compile
 4639  sbt clean test
 4640  git status
 4641  git diff
 4642  git add .
 4643  git commit -m "fix: get hadoop configurations from HADOOP_CONF_DIR environment variable"
 4644  git status
 4645  git push origin chore/gitlab-ci 
 4646  ls -l
 4647  ls -l 
 4648  ls -l ~/
 4649  ls -la ~/
 4650  vi ~/.bash_profile
 4651  ls -l $HOME/hadoop-2.7.3/bin
 4652  source ~/.bash_profile
 4653  hdfs dfs -ls /
 4654  hadoop-use-prod
 4655  hadoop-use-qa
 4656  hdfs dfs -ls /
 4657  hadoop-use-prod
 4658  hdfs dfs -ls /
 4659  hdfs dfs -ls /parquet/videowatch/20190510
 4660  hdfs dfs -ls /parquet/videowatch
 4661  hdfs dfs -ls /parquet/videowatch/2019061114
 4662  hdfs dfs -ls /parquet/videowatch/2019061112
 4663  cd ..
 4664  ls -l
 4665  mkdir recommendation
 4666  cd recommendation
 4667  ls -l
 4668  git clone gitlab@gitlab.globoi.com:bigdata/recommendation/algorithm-engine.git
 4669  cd algorithm-engine
 4670  hdfs dfs -ls /user/actions/stream/
 4671  hdfs dfs -ls /user/actions/stream/tenant=ge
 4672  hdfs dfs -ls /user/actions/stream/tenant=ge/actionsContentType=common
 4673  hdfs dfs -ls /user/actions/stream/tenant=ge/actionContentType=common
 4674  hdfs dfs -ls /user/actions/stream/tenant=ge
 4675  hdfs dfs -ls /user/actions/stream/tenant=ge/actionContentType=feed
 4676  cd ..
 4677  ls -l
 4678  cd ..
 4679  ls -l
 4680  cd horizon-storage
 4681  git status
 4682  git add CHANGELOG.md
 4683  git commit -m "chore: update CHANGELOG"
 4684  git add .gitlab-ci.yml
 4685  history | grep style
 4686  git add .gitlab-ci.yml
 4687  git commit -m "style: add line at end of file"
 4688  git push origin chore/gitlab-ci 
 4689  git checkout master
 4690  git pull
 4691  make release
 4692  ls -l
 4693  git statux
 4694  git status
 4695  git checkout HorizonClient.podspec
 4696  git status
 4697  git pull
 4698  git status
 4699  vi ~/.sbt/.credentials
 4700  cd ..
 4701  rm -rf horizon-storage
 4702  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-storage.git
 4703  cd horizon-storage
 4704  git pull
 4705  make release
 4706  git status
 4707  cd ..
 4708  git status
 4709  git checkout README.md
 4710  git pull
 4711  git statusd
 4712  git status
 4713  git checkout -b docs/add-architeture-explanation
 4714  git add .
 4715  git commit -m "docs: add architectural information about Horizon Client"
 4716  git push origin docs/add-architeture-explanation 
 4717  ls -l
 4718  cd ..
 4719  cd pipeline
 4720  ls -l
 4721  cd ..
 4722  ls -l
 4723  cd azkaban
 4724  ls -l
 4725  cd azkaban-gcp-billing
 4726  ls -l
 4727  history | grep pyenv
 4728  pyenv activate gpc-billing
 4729  python billing-gcs-companies-bigdata.py 2019 06 11 y
 4730  pyenv deactivate gpc-billing
 4731  brew update
 4732  brew install pyenv
 4733  brew upgrade pyenv
 4734  echo -e 'if command -v pyenv 1>/dev/null 2>&1; then\n  eval "$(pyenv init -)"\nfi' >> ~/.zshenv
 4735  brew install pyenv-virtualenv
 4736  echo 'eval "$(pyenv virtualenv-init -)"' >> ~/.zshenv
 4737  exit
 4738  ls -l
 4739  pyenv install 3.6.5
 4740  pyenv virtualenv 3.6.5 v3.6.5\n
 4741  pyenv local v3.6.5
 4742  python --version
 4743  pyenv deactivate v3.6.5
 4744  exit
 4745  cd ..
 4746  cd leonardo.neuwald
 4747  ls -l
 4748  pyenv local
 4749  ls -la
 4750  rm -rf .python-version
 4751  ls -l
 4752  cd Projetos
 4753  ls -l
 4754  ls-l
 4755  ls -l
 4756  cd Projetos
 4757  ls -l
 4758  mkdir client
 4759  cd client
 4760  ls -l
 4761  git clone gitlab@gitlab.globoi.com:bigdata/horizon-client-js.git
 4762  cd horizon-client-js
 4763  code .
 4764  cd ..
 4765  ls -l
 4766  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client.git
 4767  cd horizon-client
 4768  ls -l
 4769  code .
 4770  cd ..
 4771  cd horizon-client-js
 4772  ls -l
 4773  cd js
 4774  ls -l
 4775  cd ..
 4776  code .
 4777  cd ..
 4778  cd horizon-client
 4779  code .
 4780  make test
 4781  vi Makefile
 4782  npm
 4783  brew update
 4784  brew install node
 4785  npm -v
 4786  make test
 4787  vi /Users/leonardo.neuwald/.npm/_logs/2019-06-12T14_04_18_351Z-debug.log
 4788  git status
 4789  git diff
 4790  make test
 4791  jest
 4792  npm install --save-dev jest
 4793  git status
 4794  jest
 4795  exit
 4796  make test
 4797  yarn
 4798  npm install --save-dev jest\n
 4799  jest
 4800  ls -l
 4801  git status
 4802  rm -rf src/page-props.js
 4803  git status
 4804  git checkout src/page-props.js
 4805  ls -l
 4806  git status
 4807  git diff
 4808  make test
 4809  vi /Users/leonardo.neuwald/.npm/_logs/2019-06-12T14_16_42_704Z-debug.log
 4810  make setup
 4811  make test
 4812  hdfs dfs -ls /
 4813  vi ~/.bash_profile
 4814  hadoop-use-prod
 4815  hdfs dfs -ls /
 4816  ls -l
 4817  cd ..
 4818  ls -l
 4819  history | grep go
 4820  history | grep gopath
 4821  history | grep PATH
 4822  echo $GOPATH
 4823  cd $GOPATH
 4824  ls -l
 4825  cd src
 4826  ls -l
 4827  cd ..
 4828  ls -l
 4829  cd src/gitlab.globoi.com/bigdata/pipeline/
 4830  ls -l
 4831  cd horizon-track-service
 4832  git status
 4833  git diff
 4834  rm -rf go.sum go.mod .vscode
 4835  git status
 4836  git pull
 4837  ls -l
 4838  git pull
 4839  cd ..
 4840  ls -l
 4841  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-user-resolver.git
 4842  cd horizon-user-resolver
 4843  git pull
 4844  git checkout origin/feat/add-cookie-gst-support 
 4845  git checkout master
 4846  git pull origin master
 4847  git fetch
 4848  git fetch --all
 4849  git checkout feat/add-cookie-gst-support 
 4850  code .
 4851  go mod tidy
 4852  go mod vendor
 4853  git status
 4854  history | grep GO
 4855  export GO111MODULE=on
 4856  code .
 4857  git status
 4858  curl -vvv http://be.gsatmulti.globoi.com/oauth/token-info/\?token\=637a07f569891618be0379e36418392f
 4859  vi ~/.zshenv
 4860  mkdir p
 4861  cd p
 4862  vi ~/.zshrc
 4863  vi ~/.bash_profile
 4864  pyenv virtualenv 3.6.5 cris
 4865  pyenv local cris
 4866  ls -l
 4867  ls -la
 4868  python --version
 4869  vi .python-version
 4870  rm -rf .python-version
 4871  vi ~/.zshrc
 4872  vi ~/.zshenv
 4873  git status
 4874  git diff
 4875  git diff cache/cocoon.go
 4876  git status
 4877  git diff
 4878  git status
 4879  git diff
 4880  git add .
 4881  git commit -m "test: add tests for gst cookie resolution"
 4882  git push origin feat/add-cookie-gst-support 
 4883  git status
 4884  git pull
 4885  go get github.com/vektra/mockery/.../
 4886  ls -l
 4887  cd authentication
 4888  ls -l
 4889  mockery -name=GsatMultiAuthenticator
 4890  echo $PAHT
 4891  echo $PATH
 4892  vim ~/.zshrc
 4893  vim ~/.zshenv
 4894  vim ~/.bash_profile
 4895  source ~/.bash_profile
 4896  echo $PATH
 4897  vim ~/.zshrc
 4898  echo $GOPATH/bin/mockery
 4899  mockery -name=GsatMultiAuthenticator
 4900  $GOPATH/bin/mockery -name=GsatMultiAuthenticator
 4901  ls -l $GOPATH/bin/mockery 
 4902  ls -l $GOPATH/bin/mockery
 4903  ls -l $GOPATH/bin
 4904  go get github.com/vektra/mockery/
 4905  $GOPATH/bin/mockery -name=GsatMultiAuthenticator
 4906  ls -l $GOPATH/bin/mockery
 4907  ls -l $GOPATH/bin
 4908  pwd
 4909  go get github.com/vektra/mockery/.../
 4910  git status
 4911  git diff
 4912  cd ..
 4913  ls -l
 4914  cd ..
 4915  ls -l
 4916  cd ..
 4917  ls -l
 4918  cd ..
 4919  ls -l
 4920  cd ..
 4921  ls -l
 4922  cd ..
 4923  ls -l
 4924  go get github.com/vektra/mockery/.../
 4925  ls -l
 4926  git status
 4927  cd src/gitlab.globoi.com
 4928  cd ..
 4929  cd bin
 4930  cd ..
 4931  ls -l
 4932  cd bin
 4933  ls -l
 4934  cd ..
 4935  ls -l
 4936  cd src/gitlab.globoi.com/bigdata/pipeline/horizon-user-resolver
 4937  git status\\n
 4938  git status
 4939  git diff
 4940  git checkout go.mod
 4941  git checkout go.sum
 4942  git checkout resolver_test.go
 4943  git status
 4944  git pull
 4945  $GOPATH/bin/mockery -name=GsatMultiAuthenticator
 4946  ls -l
 4947  cd authentication
 4948  $GOPATH/bin/mockery -name=GsatMultiAuthenticator
 4949  git status
 4950  git diff
 4951  git status
 4952  cd ..
 4953  git status
 4954  git add .
 4955  git commit -m "test: add tests for gst cookie resolution"
 4956  git push origin feat/add-cookie-gst-support 
 4957  git status
 4958  history | grep restart
 4959  history | grep tsuru
 4960  tsuru app-log -a horizon-http-stream-prod
 4961  tsuru app-restart -a horizon-http-stream-prod
 4962  exit
 4963  ls -l
 4964  cd Projetos
 4965  ls -l
 4966  mkdir curso-python
 4967  cd curso-python
 4968  git clone https://gitlab.globoi.com/workshop/python/exercicios_1.git
 4969  cd exercicios_1
 4970  ls -l
 4971  pyenv virtualenv 3.6.5 exercicio_1
 4972  cd exercicio_1
 4973  pyenv local exercicio_1
 4974  code .
 4975  make run
 4976  cd ..
 4977  l s-l
 4978  cd exercicio_2
 4979  pyenv virtualenv 3.6.5 exercicio_2
 4980  pyenv local exercicio_2
 4981  cd ..
 4982  code .
 4983  make run
 4984  cd ..
 4985  cd exercicios_1
 4986  cd exercicio_2
 4987  make run
 4988  cd ..
 4989  cd exercicio_3
 4990  pyenv virtualenv 3.6.5 exercicio_3
 4991  pyenv local exercicio_3
 4992  make test
 4993  exit
 4994  cd Projetos
 4995  ls -l
 4996  cd curso-python
 4997  cd exercicios_4
 4998  cd exercicios_1
 4999  exercicio_4
 5000  ls -l
 5001  pyenv virtualenv 3.6.5 exercicio_4
 5002  pyenv local exercicio_4
 5003  make run
 5004  cd ..
 5005  cd exercicio_6
 5006  pyenv virtualenv 3.6.5 exercicio_6
 5007  pyenv local exercicio_6
 5008  make setup
 5009  make run
 5010  cd ..
 5011  l s-l
 5012  cd exercicio_7
 5013  pyenv virtualenv 3.6.5 exercicio_7
 5014  pyenv local exercicio_7
 5015  make setup 
 5016  make run
 5017  cd ..
 5018  cd exercicio_8
 5019  pyenv virtualenv 3.6.5 exercicio_8
 5020  pyenv local exercicio_8
 5021  make setup
 5022  make run
 5023  exit
 5024  git status
 5025  git checkout master
 5026  git pull
 5027  git checkout fix/prioritize-header-over-cookies
 5028  git status
 5029  git pull
 5030  git status
 5031  code .
 5032  git status
 5033  git add CHANGELOG.md
 5034  git commit -m "docs: remove useless information of changelog"
 5035  git push origin fix/prioritize-header-over-cookies 
 5036  cd ..
 5037  ls -l
 5038  cd ..
 5039  ls -l
 5040  cd ..
 5041  ls -l
 5042  cd ..
 5043  ls -l
 5044  cd ..
 5045  ls -l
 5046  cd client
 5047  ls -l
 5048  horizon-client
 5049  git status
 5050  git diff
 5051  code .
 5052  git diff
 5053  make test
 5054  git status
 5055  git diff
 5056  git checkout Makefile
 5057  make test
 5058  git status
 5059  git checkout -b "fix/tenant-with-default-value"
 5060  git status
 5061  git diff
 5062  git status
 5063  git add .
 5064  git status
 5065  git add .
 5066  git commit -m "fix: tenant and deviceGroup now return default values when arguments and window are empty"
 5067  git status
 5068  git push origin fix/tenant-with-default-value 
 5069  cd ..
 5070  ls -l
 5071  cd ..
 5072  ls -l
 5073  cd Projetos
 5074  ls -l
 5075  cd curso-python
 5076  ls -l
 5077  git clone https://gitlab.globoi.com/workshop/python/exercicios_2.git
 5078  cd exercicios_2
 5079  cd exercicio_1
 5080  ls -l
 5081  code .
 5082  pyenv virtualenv 3.6.5 workshop
 5083  pyenv local workshop
 5084  code .
 5085  cd ..
 5086  code .
 5087  cd exercicio_1
 5088  ls -l
 5089  make run
 5090  cd ..
 5091  cd exercicio_2
 5092  pyenv local workshop
 5093  make run-filter
 5094  make run-map
 5095  make run-reduce
 5096  make run-plus
 5097  cd ..
 5098  cd exercicio_3
 5099  pyenv local workshop
 5100  make run
 5101  cd ..
 5102  cd exercicio_4
 5103  pyenv local workshop
 5104  run passwords.txt
 5105  makerun passwords.txt
 5106  make run passwords.txt
 5107  make run file=passwords.txt
 5108  make run file:passwords.txt
 5109  make run --file passwords.txt
 5110  make run --file=passwords.txt
 5111  make run --file:passwords.txt
 5112  make run
 5113  make run file password.txt
 5114  python read.py file password.txt
 5115  python read.py file=password.txt
 5116  python read.py password.txt
 5117  python read.py passwords.txt
 5118  python read.py file=passwords.txt
 5119  python read.py --lines 3  passwords.txt
 5120  python read.py --line 3  passwords.txt
 5121  python read.py --lines 3  passwords.txt
 5122  python read.py --lines=3  passwords.txt
 5123  python read.py passwords.txt --lines 3
 5124  python read.py passwords.txt --lines=3
 5125  python read.py passwords.txt --lines:3
 5126  python read.py passwords.txt --lines 3
 5127  cd ..
 5128  cd exercicio_5
 5129  make run file password.txt
 5130  pyenv local workshop
 5131  make run
 5132  cd ..
 5133  cd exercicio_6
 5134  pyenv local workshop
 5135  pip install requests
 5136  make run
 5137  make run --file cris.txt
 5138  python news.py --file cris.txt
 5139  cd ..
 5140  cd exercicio_7
 5141  ls -l
 5142  pyenv local workshop
 5143  make test
 5144  cd ..
 5145  cd exercicios_1
 5146  code .
 5147  ls -l
 5148  cd ..
 5149  ls -l
 5150  cd ..
 5151  ls -l
 5152  cd $GO_PATH
 5153  ls -l
 5154  echo $GO_PATH
 5155  echo $GOPATH
 5156  cd $GOPATH
 5157  ls -l
 5158  cd src
 5159  ls -l
 5160  cd gitlab.globoi.com
 5161  ls- l
 5162  ls -l
 5163  cd bigdata
 5164  ls -l
 5165  cd pipeline
 5166  ls -l
 5167  cd horizon-stream-processor
 5168  git status
 5169  git checkout master
 5170  git pull
 5171  code .
 5172  go list -m all
 5173  git status
 5174  git pull
 5175  go list -m all
 5176  ls -l ~/.ivy2/cache/ | grep apache
 5177  ls -l ~/.ivy2/cache/org.apache.hadoop/ | grep hbase
 5178  ls -l ~/.ivy2/cache/org.apache.hadoop
 5179  history | grep hdfs
 5180  history | grep conf
 5181  export HADOOP_CONF_DIR=~/configs/conf-prod
 5182  hdfs dfs -ls /
 5183  hdfs dfs -ls /hbase-libs
 5184  hdfs dfs -ls /hbase-libs/1.0.0
 5185  hdfs dfs -ls /user/hdfs/.Trash/
 5186  hdfs dfs -ls /user/hadoop
 5187  hdfs dfs -ls /user/hadoop/.Trash
 5188  history | grep export
 5189  export HADOOP_USER_NAME=hadoop
 5190  history | grep export
 5191  hdfs dfs -ls /user/hadoop/.Trash
 5192  hdfs dfs -ls /user
 5193  hdfs dfs -ls /user/hdfs/
 5194  hdfs dfs -ls /hbase-libs/1.2.3
 5195  history | grep export
 5196  export GO111MODULE=on
 5197  go list -m all
 5198  git pull
 5199  go get gitlab.globoi.com/bigdata/pipeline/horizon-user-resolver.git
 5200  git status
 5201  git diff
 5202  git checkout -b "feat/update-horizon-user-resolver"
 5203  git status
 5204  git add .
 5205  git status
 5206  ls -l
 5207  git status
 5208  code .
 5209  git status
 5210  git add .
 5211  git status
 5212  git commit -m "feat: update horizon-user-resolver version"
 5213  git push origin feat/update-horizon-user-resolver 
 5214  make test
 5215  hdfs dfs -ls /
 5216  history | grep export
 5217  export HADOOP_USER_NAME=hadoop
 5218  hdfs dfs -ls /
 5219  ./hdfs dfs -ls /
 5220  export HADOOP_CONF_DIR=~/configs/conf-prod
 5221  hdfs dfs -ls /
 5222  cd ~/Downloads
 5223  ls -l
 5224  hdfs dfs -put hbase-protocol-1.0.0.jar /hbase-libs/1.0.0/
 5225  hdfs dfs -ls /hbase-libs/1.0.0
 5226  hdfs dfs -ls /hbase-libs/1.0.0/hbase-protocol-1.0.0.jar
 5227  hdfs dfs -ls /hbase-libs/1.0.0
 5228  hdfs dfs -ls /hbase-libs/1.0.0/hbase-protocol-1.0.0.jar
 5229  hdfs dfs -ls /hbase-libs/1.0.0
 5230  git status
 5231  git add vendor/*
 5232  git status
 5233  git diff
 5234  git add go.sum
 5235  git status
 5236  git diff
 5237  git commit -m "feat: update horizon-user-resolver version"
 5238  git status
 5239  git add .
 5240  git commit -m "feat: add new settings"
 5241  git push origin feat/update-horizon-user-resolver 
 5242  code .
 5243  make test
 5244  git status
 5245  git add .
 5246  git commit -m "fix"
 5247  git commit --amend
 5248  git status
 5249  git push origin feat/update-horizon-user-resolver 
 5250  git pull
 5251  ls -l
 5252  cd ..
 5253  ls -l
 5254  cd Projetos
 5255  ls -l
 5256  cd azkaban
 5257  ls- l
 5258  ls -l
 5259  cd pipeline-queue-swap
 5260  git checkout master
 5261  git pull
 5262  ls -l
 5263  cd jobs
 5264  ls -l
 5265  vi swap.sh
 5266  echo $HADOOP_HOME
 5267  echo $HADOOPHOME
 5268  ls -l ~/hadoop-2.7.3/
 5269  ./swap.sh ~/hadoop-2.7.3/ root.hadoop root.warehouse
 5270  chmod 777 ./swap.sh
 5271  ./swap.sh ~/hadoop-2.7.3/ root.hadoop root.warehouse
 5272  tsuru tsuru-deploy-dev
 5273  make tsuru-deploy-dev
 5274  make tsuru-deploy-qa
 5275  ./swap.sh ~/hadoop-2.7.3/ root.hadoop root.actions
 5276  make tsuru-deploy-dev
 5277  make tsuru-deploy-qa
 5278  ./swap.sh ~/hadoop-2.7.3/ root.actions root.warehouse
 5279  vi swap.sh
 5280  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_250711 -queue root.warehouse
 5281  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_250704 -queue root.warehouse
 5282  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_250703 -queue root.warehouse
 5283  git status
 5284  git diff
 5285  git add .
 5286  git diff
 5287  git commit -m "fix: names of env variables"
 5288  git status
 5289  git push origin feat/update-horizon-user-resolver 
 5290  make tsuru-deploy-dev
 5291  make tsuru-deploy-qa
 5292  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_250709 -queue root.warehouse
 5293  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_250708 -queue root.warehouse
 5294  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_250718 -queue root.warehouse
 5295  cd ..
 5296  ls -l
 5297  cd horizon-http-stream
 5298  git status
 5299  git diff
 5300  git pull
 5301  git status
 5302  rm -rf go.mod go.sum
 5303  git status
 5304  git pull
 5305  code .
 5306  ./swap.sh ~/hadoop-2.7.3/ root.actions root.warehouse
 5307  cd ..
 5308  ls -l
 5309  cd ..
 5310  ls -l
 5311  cd personal
 5312  ls -l
 5313  git clone git@github.com:leoneuwald/deeplearning-dl4j.git
 5314  cd deeplearning-dl4j
 5315  mv ~/Downloads
 5316  mv ~/Downloads/spark-2.3.1-bin-hadoop2.7 ~/
 5317  mv ~/Downloads/spark-2.3.1-bin-hadoop2.6 ~/
 5318  ls -l ~/spark-2.3.1-bin-hadoop2.7
 5319  ls -l ~/spark-2.3.1-bin-hadoop2.7/bin
 5320  cd ~/spark-2.3.1-bin-hadoop2.7/bin
 5321  pwd
 5322  ls -l
 5323  cd ~/
 5324  ls -l
 5325  cd Projetos
 5326  ls -l
 5327  cd personal
 5328  ls -l
 5329  cd deeplearning-dl4j
 5330  ls -l
 5331  pwd
 5332  cd ..
 5333  ls -l
 5334  cd .
 5335  cd ..
 5336  cd leonardo.neuwald
 5337  ls -l
 5338  cd spark-2.3.1-bin-hadoop2.7
 5339  cd bin
 5340  cd ..
 5341  cd sbin
 5342  ls -l
 5343  ./start-master.sh
 5344  vi /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-AdministorsMBP3.out
 5345  ./start-master.sh
 5346  ps aux | grep spark
 5347  kill -9 21397
 5348  ps aux | grep spark
 5349  ./start-master.sh
 5350  tail -f /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-AdministorsMBP3.out
 5351  ls -l /Users/leonardo.neuwald/
 5352  cd spark-2.3.1-bin-hadoop2.7
 5353  cd sbin
 5354  ls -l
 5355  ./start-slave.sh
 5356  ./start-slave.sh spark://AdministorsMBP3:7077
 5357  tail -f /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-AdministorsMBP3.out
 5358  pwd
 5359  ls -l
 5360  ./tinyImagenetTrain.sh
 5361  sbt clean assembly
 5362  ls -l /Users/leonardo.neuwald/Projetos/personal/deeplearning-dl4j/target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar
 5363  df -h /Users/leonardo.neuwald/Projetos/personal/deeplearning-dl4j/target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar
 5364  du -h /Users/leonardo.neuwald/Projetos/personal/deeplearning-dl4j/target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar
 5365  ps aux | grep spark
 5366  kill -9 22379
 5367  ps aux | grep spark
 5368  kill -9 21677
 5369  du -h /Users/leonardo.neuwald/Projetos/personal/deeplearning-dl4j/target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar
 5370  ls -l
 5371  cd ..
 5372  cd leonardo.neuwald
 5373  cd Projetos
 5374  ls -l
 5375  echo $GOPATH
 5376  cd ..
 5377  cd go
 5378  ls -l
 5379  cd src
 5380  ls -l
 5381  cd gitlab.globoi.com
 5382  ls -l
 5383  cd bigdata
 5384  ls l--
 5385  ls -l
 5386  cd pipeline
 5387  ls -l
 5388  cd horizon-http-stream
 5389  git status
 5390  git pull
 5391  history | grep go
 5392  pwd
 5393  cd ..
 5394  ls -l
 5395  cd ..
 5396  ls -l
 5397  cd Projetos
 5398  ls -l
 5399  cd client
 5400  ls -l
 5401  cd horizon-client
 5402  git status
 5403  git checkout master
 5404  git pull
 5405  vi Makefile
 5406  make build-prod
 5407  git status
 5408  code .
 5409  git status
 5410  git diff
 5411  git status
 5412  git add .
 5413  git commit -m "version: bump to 1.3.0"
 5414  git status
 5415  cd ..
 5416  ls -l
 5417  rm -rf horizon-client
 5418  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client.git
 5419  cd horizon-client
 5420  git pull
 5421  ls -l
 5422  cd ..
 5423  git clone gitlab@gitlab.globoi.com:bigdata/commons/docs.git
 5424  cd docs
 5425  git status
 5426  cd ..
 5427  ls -l
 5428  cd ..
 5429  pwd
 5430  cd ..
 5431  ls -l
 5432  cd azkaban
 5433  ls -l
 5434  cd pipeline-document-ingest
 5435  git status
 5436  git pull
 5437  code .
 5438  git status
 5439  git diff
 5440  git status
 5441  git diff
 5442  make zip
 5443  git status
 5444  git diff
 5445  git checkout -b feat/scheduled-aurelio-execution
 5446  git status
 5447  git diff
 5448  make zip
 5449  git status
 5450  git add .
 5451  git commit -m "feat: created a separated Aurelio Tokenizer job"
 5452  git status
 5453  git push origin feat/scheduled-aurelio-execution 
 5454  make zip
 5455  cd pipeline/horizon-http-stream
 5456  git status
 5457  history | grep export
 5458  echo $GO111MODULE
 5459  ls -l
 5460  git status
 5461  rm -rf go
 5462  ls -l
 5463  git status
 5464  rm -rf go.mod go.sum 
 5465  git status
 5466  git pull
 5467  dep ensure
 5468  git status
 5469  git diff
 5470  ls -l 
 5471  cd vendor
 5472  ls- l
 5473  ls -la
 5474  cd ..
 5475  dep ensure
 5476  git status
 5477  dep check
 5478  ls -l
 5479  rm -rf vendor/gitlab.globoi.com/bigdata/pipeline/horizon-user-resolver.git
 5480  dep ensure
 5481  git status
 5482  git checkout Gopkg.lock
 5483  dep ensure
 5484  git status
 5485  rm -rf vendor/gitlab.globoi.com
 5486  git status
 5487  git checkout Gopkg.lock
 5488  dep ensure
 5489  git status
 5490  git diff
 5491  git status
 5492  make vendor
 5493  git status
 5494  echo $GO111MODULE
 5495  history | grep GO111MODULE
 5496  export GO111MODULE=off
 5497  echo $GO111MODULE
 5498  git status
 5499  git checkout Gopkg.lock
 5500  git pull
 5501  make vendor
 5502  git status
 5503  dep ensure -update
 5504  git status
 5505  git checkout vendor
 5506  git status
 5507  rm -rf vendor
 5508  git checkout vendor
 5509  git status
 5510  git checkout Gopkg.lock
 5511  git status
 5512  git pull
 5513  ls -l
 5514  dep ensure -update gitlab.globoi.com/bigdata/pipeline/horizon-user-resolver.git
 5515  git status
 5516  yarn application -lisgt
 5517  yarn application -list
 5518  history | grep export
 5519  export HADOOP_CONF_DIR=~/configs/conf-prod
 5520  yarn application -list
 5521  history | grep yarn
 5522  history | grep movetoqueue
 5523  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_251530 -queue root.streams
 5524  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_251530 -queue root.default
 5525  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_251536 -queue root.default
 5526  cd ..
 5527  ls -l
 5528  cd pipeline-horizon-stream-ingest
 5529  git status
 5530  git pull
 5531  atom .
 5532  cd ..
 5533  ls -l
 5534  cd Projetos
 5535  cd scripts-marotos
 5536  git status
 5537  cd ..
 5538  cd roteiros-artesanais
 5539  git status
 5540  ls -l
 5541  cd kafka
 5542  git status
 5543  ls -l 
 5544  vi get_earliest_offset_in_topic.sh
 5545  ./get_earliest_offset_in_topic.sh hhs.valor-investe
 5546  history | grep KAFKA
 5547  export KAFKA_HOME=~/kafka_2.11-0.10.1.1
 5548  ./get_earliest_offset_in_topic.sh hhs.valor-investe
 5549  ls -l 
 5550  hdfs dfs -ls /
 5551  hdfs dfs -ls /user/actions/
 5552  hdfs dfs -ls /user/actions/stream
 5553  hdfs dfs -ls /user/actions/stream/checkpoints
 5554  hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe
 5555  hdfs dfs -get /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 5556  atom .
 5557  git status
 5558  hdfs dfs -mv /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt_28_06
 5559  git status
 5560  git diff
 5561  atom .
 5562  hdfs dfs -put valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/
 5563  hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe/
 5564  hdfs dfs -chown actions:hdfs /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 5565  git checkout -b feat/update-horizon-user-resolver
 5566  git status
 5567  git add .
 5568  git commit -m "chore"
 5569  git commit -amend
 5570  git commit --amend
 5571  git status
 5572  git push origin feat/update-horizon-user-resolver 
 5573  yarn application -kill application_1539207608922_251554
 5574  hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe/
 5575  hdfs dfs -ls /user/actions/stream/checkpoints/g1
 5576  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_251564 -queue root.default
 5577  git status
 5578  atom .
 5579  git status
 5580  git checkout -b fix/increase-valor-investe-resources
 5581  git status
 5582  atom.
 5583  atom .
 5584  git status
 5585  git add .
 5586  git commit -m "fix: increase hzt.valor-investe resources"
 5587  git status
 5588  git push origin fix/increase-valor-investe-resources 
 5589  ./get_earliest_offset_in_topic.sh hhs.valor-investe
 5590  hdfs dfs -get /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 5591  rm -rf valor-investe_hhs.valor-investe_offsets.txt
 5592  hdfs dfs -get /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 5593  atom .
 5594  yarn application -kill application_1539207608922_251582
 5595  hdfs dfs -mv /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt_28_06_2
 5596  hdfs dfs -put valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/
 5597  hdfs dfs -chown actions:hdfs /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 5598  hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe
 5599  history | grep move
 5600  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_251583 -queue root.default
 5601  hdfs dfs -text /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 5602  ./get_earliest_offset_in_topic.sh hhs.valor-investe
 5603  hdfs dfs -mv /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt_28_06_3
 5604  hdfs dfs -put valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/
 5605  hdfs dfs -chown actions:hdfs /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 5606  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_251590 -queue root.default
 5607  hdfs dfs -ls /parquet
 5608  hdfs dfs -ls /user/actions/stream
 5609  hdfs dfs -ls /user/actions/stream/tenant=g1
 5610  hdfs dfs -ls /user/actions/stream/tenant=ge
 5611  hdfs dfs -ls /user/actions/stream/tenant=player/
 5612  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video
 5613  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player=environment-data
 5614  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data
 5615  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data/actionVersion=1.0
 5616  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data/actionVersion=1.0/year=2019/month=6/day=17
 5617  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data/actionVersion=1.0/year=2019
 5618  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data/actionVersion=1.0/year=2019/month=6
 5619  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/actionId=player-environment-data/actionVersion=1.0/year=2019/month=6/day=18
 5620  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video/
 5621  hdfs dfs -ls /user/actions/stream/tenant=player
 5622  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=monitoring
 5623  cd ..
 5624  cd pipeline-horizon-stream-ingest
 5625  git status
 5626  git pull
 5627  git checkout master
 5628  git pul
 5629  git pull
 5630  git status
 5631  atom .
 5632  make zip
 5633  ls -l
 5634  rm -rf valor-investe_hhs.valor-investe_offsets.txt
 5635  ./get_earliest_offset_in_topic.sh hhs.valor-investe
 5636  hdfs dfs -get /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 5637  atom .
 5638  yarn application -kill application_1539207608922_252116
 5639  hdfs dfs -mv /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt_19_06
 5640  hdfs dfs -put valor-investe_hhs.valor-investe_offsets.txt /user/actions/stream/checkpoints/valor-investe/
 5641  hdfs dfs -chown actions:hdfs /user/actions/stream/checkpoints/valor-investe/valor-investe_hhs.valor-investe_offsets.txt
 5642  hdfs dfs -ls /user/actions/stream/checkpoints/valor-investe
 5643  git status
 5644  git checkout master
 5645  git pull
 5646  cd ..
 5647  ls -l
 5648  cd ..
 5649  ls -l
 5650  cd ..
 5651  ls -l
 5652  cd horizon-client-ios
 5653  ls -l
 5654  git status
 5655  git checkout master
 5656  atom .
 5657  code .
 5658  cd ..
 5659  ls -l
 5660  cd hydrogen
 5661  ls -l
 5662  cd hydrogen.user-frequency
 5663  ls -l
 5664  atom .
 5665  hdfs dfs -ls /parquet/agg/user/monthly
 5666  hdfs dfs -ls /parquet/agg/user/
 5667  cd ..
 5668  git status
 5669  git diff
 5670  git checkout hydrogen.warehouse/airflow_jobs/videosession_daily.py
 5671  git status
 5672  git pull
 5673  git status
 5674  git diff
 5675  git status
 5676  git idff
 5677  git diff
 5678  hdfs dfs -ls /parquet/user
 5679  hdfs dfs -df -h /parquet/user
 5680  hdfs dfs -du -h /parquet/user
 5681  git status
 5682  git diff
 5683  yarn application -list | grep application_1539207608922_252368
 5684  yarn application -kill application_1539207608922_252368
 5685  yarn application -list | grep application_1539207608922_252368
 5686  yarn application -list | grep application_1539207608922_252381
 5687  yarn application -kill application_1539207608922_252381
 5688  yarn application -kill application_1539207608922_252388
 5689  yarn application -kill application_1539207608922_252391
 5690  yarn application -kill application_1539207608922_252394
 5691  git status
 5692  rm -rf README.pdf
 5693  git pull
 5694  git status
 5695  code .
 5696  cd ..
 5697  ls -l
 5698  cd horizon-client-ios-bin-releases
 5699  git status
 5700  git pull
 5701  cp ../horizon-client-ios/HorizonClient/HorizonClient .
 5702  cp -r ../horizon-client-ios/HorizonClient/HorizonClient .
 5703  ls -l
 5704  rm -rf Frameworks
 5705  git status
 5706  rm -rf HorizonClient
 5707  cp -r ../horizon-client-ios/HorizonClient/HorizonClient .
 5708  git status
 5709  code .
 5710  git statuds
 5711  git status
 5712  git diff
 5713  rm -rf HorizonClient
 5714  cp -r ../horizon-client-ios/HorizonClient/HorizonClient .
 5715  git status
 5716  ls -l HorizonClient
 5717  ls -l HorizonClient/Sources
 5718  cd ..
 5719  cd horizon-client-ios-bin-releases
 5720  git add .
 5721  git status
 5722  git log
 5723  git commit -m "Update framework to version 1.1.0"
 5724  git push origin master
 5725  git tag 1.1.0
 5726  git push origin 1.1.0 
 5727  git status
 5728  git add .
 5729  git commit -m "chore: release client with source"
 5730  git push origin master
 5731  pod repo push globoi HorizonClient.podspec --allow-warnings --verbose
 5732  ls -l
 5733  cd HorizonClient
 5734  ls -l
 5735  rm -rf Carthage
 5736  rm -rf Carthage2
 5737  pod repo push globoi HorizonClient.podspec --allow-warnings --verbose
 5738  ls -l
 5739  cd Projetos
 5740  ls -l
 5741  cd horizon-client-ios
 5742  cd ..
 5743  mv ~/Downloads/TestHorizon .
 5744  cd TestHorizon/TestHorizon
 5745  pod update
 5746  pod install
 5747  cd ..
 5748  ls -l
 5749  cd hydrogen
 5750  git status
 5751  git diff
 5752  git checkout -b "fix/increase-user-frequency-resources"
 5753  git add .
 5754  git commit -m "fix: increase uses-frequency job resources"
 5755  git push origin fix/increase-user-frequency-resources 
 5756  ls -l
 5757  pwdf
 5758  pwd
 5759  cd ..
 5760  ls -l
 5761  cd ..
 5762  ls -l
 5763  cd azkaban
 5764  ls- l
 5765  ls -l
 5766  cd pipeline-horizon-stream-ingest
 5767  git status
 5768  git diff
 5769  git checkout -b "fix/increase-valor-investe-resources"
 5770  atom .
 5771  code .
 5772  git checkout -b "fix/increase-valorinveste-resources"
 5773  atom .
 5774  code .
 5775  atom .
 5776  git status
 5777  git add .
 5778  git commit -m "fix: increase hzt.valor-investe resources"
 5779  git push origin fix/increase-valorinveste-resources 
 5780  cd ..
 5781  ls -l
 5782  cd azkaban
 5783  ls -l
 5784  cd azkaban-gcp-billing
 5785  git status
 5786  git pull
 5787  ls -l
 5788  history | grep pyenv
 5789  pyenv activate gpc-billing
 5790  pyenv activate pip
 5791  history | grep pip
 5792  history | grep pip install
 5793  history | grep 'pip install'
 5794  pip install -r requirements.txt
 5795  python billing-gcs-companies-ga.py 2019 06 19 y
 5796  ls -l
 5797  pwd
 5798  pyenv deactivate gpc-billing
 5799  pyenv activate gpc-billing
 5800  pip install -r requirements.txt
 5801  python billing-gcs-companies-ga.py 2019 06 19 y
 5802  pyenv deactivate gpc-billing
 5803  hdfs dfs -ls /
 5804  hdfs dfs -ls /user/actions
 5805  hdfs dfs -ls /user/actions/stream
 5806  hdfs dfs -ls /user/actions/stream/tenant=techtudo/year=2019/month=5
 5807  hdfs dfs -ls /user/actions/stream/tenant=techtudo/year=2019
 5808  hdfs dfs -ls /user/actions/stream/tenant=techtudo
 5809  hdfs dfs -ls /user/actions/stream/tenant=techtudo/*/*/
 5810  hdfs dfs -ls /user/actions/stream/tenant=techtudo/*/*
 5811  ls -l
 5812  cd pipeline
 5813  ls -l
 5814  cd horizon-http-stream
 5815  git status
 5816  git pull
 5817  code .
 5818  tsuru service instance -h
 5819  tsuru service-instance-info -h
 5820  tsuru service-instance-info tsuru-dbaas-dev horizon_user_resolver_dev
 5821  tsuru service-instance-status tsuru-dbaas-dev horizon_user_resolver_dev
 5822  tsusu service -h
 5823  tsuru service -h
 5824  tsuru service-instance-status
 5825  tsuru service-instance-status tsuru-dbaas-qa
 5826  tsuru service-instance-list tsuru-dbaas-dev
 5827  tsuru service-info tsuru-dbaas-dev
 5828  tsuru app-stop -a horizon-http-stream-dev
 5829  tsuru service instance tsuru-dbaas-dev horizon_http_stream_redis_cache_dev
 5830  tsuru service-instance-status tsuru-dbaas-dev horizon_http_stream_redis_cache_dev
 5831  tsuru service-instance-unbind -h
 5832  tsuru service-instance-unbind tsuru-dbaas-dev horizon_http_stream_redis_cache_dev -a horizon-http-stream-dev
 5833  tsuru service-instance-bind
 5834  tsuru service-instance-bind tsuru-dbaas-dev horizon_user_resolver_dev -a horizon-http-stream-dev
 5835  tsuru app-info -a horizon-service-track-prod
 5836  tsuru app-info -a horizon-track-service-prod
 5837  tsuru app-info -a horizon-schemas-service-prod
 5838  tsuru app-info -a horizon-schemas-prod
 5839  tsuru app
 5840  tsuru app-start -a horizon-http-stream-dev
 5841  tsuru app-info -a horizon-http-stream-dev
 5842  tsuru app-log -a horizon-http-stream-dev
 5843  tsuru service
 5844  tsuru service-list 
 5845  tsuru service-instance-info
 5846  tsuru service-instance-info tsuru-dbaas-dev horizon_http_stream_redis_cache_qa
 5847  tsuru service-info tsuru-dbaas-dev
 5848  tsuru service-instance-add tsuru-dbaas-dev horizon_user_resolver_qa redis-4-0-tiny-single-node-memory-only-cs-rjdev-dev -t bigdata -d 'Horizon user resolver cache'
 5849  tsuru service instance status tsuru-dbaas-dev horizon_user_resolver_qa
 5850  tsuru service instance info tsuru-dbaas-dev horizon_user_resolver_qa
 5851  tsuru service instance status tsuru-dbaas-dev horizon_user_resolver_qa
 5852  hdfs dfs -ls /user/actions/stream/tenant=player
 5853  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=video
 5854  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=monitoring
 5855  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=monitoring/actionId=player-events
 5856  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=monitoring/actionId=player-events/actionVersion=1.1
 5857  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=monitoring/actionId=player-events/actionVersion=1.1/year=2019/
 5858  hdfs dfs -ls /user/actions/stream/tenant=player/actionContentType=monitoring/actionId=player-events/actionVersion=1.1/year=2019/month=6
 5859  tsuru service instance status tsuru-dbaas-dev horizon_user_resolver_qa
 5860  tsuru app-stop -a horizon-stream-processor-qa
 5861  tsuru service-instance-unbind tsuru-dbaas-dev horizon_http_stream_redis_cache_qa -a horizon-stream-processor-qa
 5862  tsuru service-instance-bind tsuru-dbaas-dev horizon_user_resolver_qa -a horizon-stream-processor-qa
 5863  tsuru app-info -a horizon-stream-processor-qa
 5864  tsuru app-start -a horizon-stream-processor-qa
 5865  tsuru app-info -a horizon-stream-processor-qa
 5866  tsuru app-log -f -a horizon-stream-processor-qa
 5867  tsuru app-stop -a horizon-http-stream-qa
 5868  tsuru service-instance-unbind tsuru-dbaas-dev horizon_http_stream_redis_cache_qa -a horizon-http-stream-qa
 5869  tsuru service-instance-bind tsuru-dbaas-dev horizon_user_resolver_qa -a horizon-http-stream-qa
 5870  tsuru app-info -a horizon-http-stream-qa
 5871  tsuru app-start -a horizon-http-stream-qa
 5872  tsuru app-info -a horizon-http-stream-qa
 5873  tsuru app-log -f -a horizon-http-stream-qa
 5874  tsuru app-stop -a horizon-legacy-stream-qa
 5875  tsuru service-instance-unbind tsuru-dbaas-dev horizon_http_stream_redis_cache_qa -a horizon-legacy-stream-qa
 5876  tsuru service-instance-bind tsuru-dbaas-dev horizon_user_resolver_qa -a horizon-legacy-stream-qa
 5877  tsuru app-info -a horizon-legacy-stream-qa
 5878  tsuru app-start -a horizon-legacy-stream-qa
 5879  tsuru app-log -f -a horizon-http-stream-qa
 5880  tsuru app-info -a horizon-legacy-stream-qa
 5881  tsuru app-log -f -a horizon-legacy-stream-qa
 5882  tsuru app-log -f -a horizon-track-service-qa
 5883  tsuru app-log -f -a horizon-stream-processor-qa
 5884  tsuru app-info -a horizon-legacy-stream-qa
 5885  tsuru app-log -f -a horizon-http-stream-qa
 5886  tsuru app-info -a horizon-http-stream-qa
 5887  mv ~/Downloads/redis-4.0.14 ~/
 5888  cd ~/redis-4.0.14
 5889  make 
 5890  make test
 5891  ls -l
 5892  cd src
 5893  ls -l
 5894  ./redis-cli horizonuse-01-15611383256.dev.redis.globoi.com -a b8CgnfRtCu -p 6379
 5895  ./redis-cli
 5896  cd spark-2.3.1-bin-hadoop2.7
 5897  ls -l
 5898  cd sbin
 5899  ls -l
 5900  pwd
 5901  /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/sbin
 5902  ls -l
 5903  ./start-master.sh
 5904  tail -f Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-AdministorsMBP3.out
 5905  tail -f/ Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-AdministorsMBP3.out
 5906  tail -f /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-AdministorsMBP3.out
 5907  ps aux | grep spark
 5908  ./start-slave.sh
 5909  ./start-slave.sh spark://AdministorsMBP3:7077
 5910  tail -f /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-AdministorsMBP3.out
 5911  ls -l
 5912  cd Projetos
 5913  ls -l
 5914  cd personal
 5915  ls -l
 5916  cd deeplearning-dl4j
 5917  ls -l
 5918  ./tinyImagenetTrain.sh
 5919  pwd
 5920  ./tinyImagenetTrain.sh
 5921  mv target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar .
 5922  ls -l
 5923  sbt assembly
 5924  ./tinyImagenetTrain.sh
 5925  sbt assembly
 5926  ps aux | grep spark
 5927  sbt assembly
 5928  java -version
 5929  java 
 5930  java -cp target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar --help
 5931  java -cp target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar
 5932  java -jar target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar com.neuwald.dl4j.mnist.MnistMain
 5933  java -cp target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar com.neuwald.dl4j.mnist.MnistMain
 5934  sbt assembly
 5935  java -jar target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar com.neuwald.dl4j.mnist.MnistMain
 5936  java -cp target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar com.neuwald.dl4j.mnist.MnistMain
 5937  ls -l
 5938  cd project
 5939  ls -l
 5940  cd .
 5941  git status
 5942  ls -l /tmp//mnist
 5943  ls -l /tmp/mnist
 5944  java -cp target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar com.neuwald.dl4j.mnist.MnistMain
 5945  cd ..
 5946  ls -l
 5947  java -cp target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar com.neuwald.dl4j.mnist.MnistMain
 5948  ls -l
 5949  cd ..
 5950  ls -l
 5951  cd ..
 5952  ls -l
 5953  cd Projetos
 5954  ls -l
 5955  cd azkaban
 5956  ls -l
 5957  cd azkaban-gcp-billing
 5958  ls -l
 5959  history | grep pyenv
 5960  pyenv activate gpc-billing
 5961  billing-gcs-companies-ga.py 2019 06 24 y
 5962  python billing-gcs-companies-ga.py 2019 06 24 y
 5963  pyenv deactivate gpc-billing
 5964  yarn application -list | application_1539207608922_248991
 5965  application_1539207608922_248991
 5966  yarn application -list | application_1539207608922_24899
 5967  yarn application -list | grep application_1539207608922_24899
 5968  yarn application -kill application_1539207608922_248991
 5969  ls -l
 5970  cd ..
 5971  ls -l
 5972  cd ..
 5973  ls -l
 5974  cd ..
 5975  ls -l
 5976  cd ..
 5977  ls l
 5978  ls -l
 5979  cd client
 5980  ls -l
 5981  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-client-android.git
 5982  telnet 10.129.240.102 22
 5983  brew install telnet\n
 5984  telnet 10.129.240.102 22
 5985  wget 10.129.240.102:8080/id
 5986  curl 10.129.240.102:8080/id
 5987  curl --v 10.129.240.102:8080/id
 5988  cd horizon-client-android
 5989  atom ,
 5990  atom .
 5991  yarn application -list | grep application_1539207608922_231852
 5992  yarn application -kill application_1539207608922_231852
 5993  history | grep default
 5994  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_256692 -queue root.default
 5995  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_256698 -queue root.default
 5996  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_256699 -queue root.default
 5997  ~/hadoop-2.7.3/bin/yarn application -movetoqueue application_1539207608922_256726 -queue root.default
 5998  ls -l
 5999  cd pipeline
 6000  ls -l
 6001  cd horizon-track-service
 6002  git status
 6003  git pull
 6004  code .
 6005  git status
 6006  git checkout -b feat/generate-anonymous-user-with-jwt
 6007  history | grep export
 6008  export GO111MODULE=off
 6009  history | grep def
 6010  history | grep dep
 6011  dep ensure -add github.com/dgrijalva/jwt-go
 6012  make test
 6013  git status
 6014  git add .
 6015  git status
 6016  git commit -m "feat: generate anonymous user with JWT"
 6017  git push origin feat/generate-anonymous-user-with-jwt 
 6018  git checkout master
 6019  git pull
 6020  exit
 6021  git fetch -all
 6022  git fetch
 6023  git checkout feat/horizon-cloud 
 6024  code .
 6025  git status
 6026  git pull
 6027  make test
 6028  git log
 6029  gst
 6030  git diff
 6031  git add --all
 6032  gst
 6033  git commit -m "refactor: extract mark request counter middleware"
 6034  history | grep mockery
 6035  $GOPATH/bin/mockery -name=IntervalCounterTask
 6036  git status
 6037  $GOPATH/bin/mockery -name=IntervalCounterTask
 6038  mockery -name=IntervalCounterTask
 6039  ls -l
 6040  cd hzt/counter
 6041  mockery -name=IntervalCounterTask
 6042  make test
 6043  cd ..
 6044  make test
 6045  git status
 6046  git diff
 6047  git add hzt/counter/
 6048  git status
 6049  git commit -m "feat: create a interval counter"
 6050  git push origin feat/horizon-cloud 
 6051  make test
 6052  ls -l
 6053  cd hzt
 6054  cd counter
 6055  mockery -name=requestCounter
 6056  mockery -name=RequestCounter
 6057  cd ..
 6058  ls -l
 6059  make test
 6060  git status
 6061  git diff
 6062  git status
 6063  git add .
 6064  git commit -m "refactor: convert throttling to IntervalCounterTask"
 6065  git push origin feat/horizon-cloud 
 6066  git status
 6067  git diff
 6068  make test
 6069  git status
 6070  git add .
 6071  git commit -m "feat: create logic to change route"
 6072  git push origin feat/horizon-cloud 
 6073  make test
 6074  git status
 6075  git add .
 6076  git commit -m "feat: add RequestRouteArrangementControl middleware to server"
 6077  git push origin feat/horizon-cloud 
 6078  pyenv activate gpc-billing
 6079  python billing-gcs-companies-ga.py 2019 06 27 y
 6080  pyenv deactivate gpc-billing
 6081  git status
 6082  git diff
 6083  git status
 6084  make test
 6085  git status
 6086  git add .
 6087  git commit -m "feat: add new configs to settings"
 6088  git push origin feat/horizon-cloud 
 6089  git diff
 6090  git status
 6091  git diff
 6092  make tsuru-deploy-qa
 6093  tsuru app-info -a horizon-track-qa
 6094  curl http://horizon-track.qa.globoi.com
 6095  curl http://horizon-track.qa.globoi.com/id
 6096  curl horizon-track-qa.gcloud.dev.globoi.com
 6097  curl horizon-cld.qa.globoi.com
 6098  curl -XPOST horizon-cld.qa.globoi.com/event
 6099  curl -XPOST horizon-cld.qa.globoi.com/events
 6100  curl -XPOST horizon-cld.qa.globoi.com/event\n: 1561727384:0;make tsuru-deploy-qa
 6101  curl http://horizon-track.qa.globoi.com/id
 6102  curl http://horizon.qa.globoi.com/id
 6103  make tsuru-deploy-qa
 6104  tsuru app-log -a horizon-track-qa
 6105  make tsuru-deploy-qa
 6106  go run
 6107  make run
 6108  ifconfig
 6109  history | grep movequeue
 6110  history | grep move
 6111  cd ..
 6112  ls -l
 6113  cd ..
 6114  ls -l
 6115  pwd
 6116  cd /Users/leonardo.neuwald/go/src/gitlab.globoi.com/bigdata/pipeline/horizon-track-service
 6117  git status
 6118  git diff
 6119  make tsuru-deploy-qa
 6120  go run
 6121  make run
 6122  git status
 6123  git diff
 6124  make tsuru-deploy-qa
 6125  git status
 6126  git diff
 6127  git status
 6128  git diff
 6129  git add hzt/* tasks/*
 6130  git status
 6131  git commit -m "feat: change configs for testing"
 6132  git push origin feat/horizon-cloud 
 6133  cd /Users/leonardo.neuwald/Projetos/azkaban/azkaban-gcp-billing/
 6134  history | grep pyenv
 6135  pyenv activate gpc-billing
 6136  python billing-gcs-companies-bigdata.py 2019 06 27 y
 6137  yarn application -list 
 6138  history | grep export
 6139  export HADOOP_CONF_DIR=~/configs/conf-prod
 6140  yarn application -list 
 6141  yarn application -movetoqueue application_1539207608922_258060 -queue root.default
 6142  yarn application -movetoqueue application_1539207608922_258067 -queue root.default
 6143  yarn application -movetoqueue application_1539207608922_258082 -queue root.default
 6144  yarn application -movetoqueue application_1539207608922_258090 -queue root.default
 6145  yarn application -movetoqueue application_1539207608922_258097 -queue root.default
 6146  yarn application -movetoqueue application_1539207608922_258075 -queue root.default
 6147  pyenv deactivate gpc-billing
 6148  git status
 6149  rm -rf go.mod go.sum
 6150  ls -l
 6151  git checkout mastr
 6152  git checkout master
 6153  git pull
 6154  git checkout feat/generate-anonymous-user-with-jwt 
 6155  git pull
 6156  make test
 6157  ls -l
 6158  cd ..
 6159  ls -l
 6160  cd ..
 6161  ls -l
 6162  pwd
 6163  ls -l
 6164  cd ..
 6165  ls -l
 6166  cd ..
 6167  ls -l
 6168  cd hydrogen
 6169  ls -l
 6170  git status
 6171  git checkout master
 6172  git pull
 6173  atom .
 6174  git status
 6175  ls -l
 6176  cd pipeline
 6177  ls -l
 6178  cd horizon-track-service
 6179  git status
 6180  git diff
 6181  make test
 6182  git status
 6183  git fetch
 6184  git branch -d fix/increase-user-frequency-resources
 6185  git branch -b fix/increase-user-frequency-resources
 6186  git checkout -b fix/increase-user-frequency-resources
 6187  git status
 6188  git diff
 6189  git add .
 6190  git commit -m "fix: increase users_frequency_mothly job resources"
 6191  git push origin fix/increase-user-frequency-resources 
 6192  make test
 6193  git status
 6194  git diff
 6195  make test
 6196  git statis
 6197  git status
 6198  git diff
 6199  git add .
 6200  git commit -m "feat: generate anonymous user with JWT"
 6201  git push origin feat/generate-anonymous-user-with-jwt 
 6202  yarn application -list | grep click
 6203  hdfs dfs -ls /warehouse/user-profile
 6204  hdfs dfs -ls /user/horizon/compress_signals_archive/parquet/postview/year=2016/month=3/day=20
 6205  hdfs dfs -ls /user/horizon/compress_signals_archive
 6206  hdfs dfs -ls /user/horizon/compress_signals_archive/parquet/postview
 6207  hdfs dfs -ls /user/horizon/compress_signals_archive/parquet/postview/year=2016
 6208  hdfs dfs -ls /user/horizon/compress_signals_archive/parquet/postview/year=2016/month=3
 6209  hdfs dfs -ls /user/horizon/compress_signals_archive/parquet/postview/year=2016/month=2
 6210  hdfs dfs -ls /tmp/user/horizon/compress_signals_archive/parquet/postview/year=2016/month=2
 6211  hdfs dfs -ls /tmp/user/horizon/compress_signals_archive/parquet/postview/year=2016
 6212  hdfs dfs -ls /user/horizon/compress_signals_archive//parquet/postview/year=2016/month=3/day=20
 6213  hdfs dfs -ls /
 6214  hdfs dfs -ls /parquet/postview/2016032400
 6215  hdfs dfs -ls /parquet/postview/20160324*
 6216  hdfs dfs -du -h /parquet/postview/2016032400
 6217  hdfs dfs -ls /tmp/test_compress/parquet/postview/year=2016/month=3/day=24
 6218  cd ~/
 6219  mkdir parquets
 6220  cd parquets
 6221  mkdir new
 6222  cd new
 6223  hdfs dfs -get /tmp/test_compress/parquet/postview/year=2016/month=3/day=24/part-00000-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet
 6224  hdfs dfs -get /tmp/test_compress/parquet/postview/year=2016/month=3/day=24/part-00001-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet
 6225  pwd
 6226  cd ..
 6227  ls -l
 6228  cd ..
 6229  ls -l
 6230  cd spark-2.4.0-bin-hadoop2.7
 6231  cd sbin
 6232  ls -l
 6233  cd ..
 6234  cd bin
 6235  ls -l
 6236  ./spark-shell
 6237  pwd
 6238  ./spark-shell --driver-memory 7g
 6239  ps aux | grep spark
 6240  top
 6241  kill -9 97717
 6242  ls -l
 6243  ps aux | grep spark
 6244  cd ..
 6245  ls -l
 6246  cd new
 6247  ls -l
 6248  cd ..
 6249  cd new2
 6250  ls -l
 6251  pwd
 6252  cd ..
 6253  git clone git@github.com:apache/parquet-mr.git
 6254  cd parquet-mr
 6255  ls -l
 6256  cd parquet-tools
 6257  mvn clean package -Plocal
 6258  brew install maven
 6259  mvn clean package -Plocal
 6260  git checkout parquet-1.7.0
 6261  mvn clean package -Plocal
 6262  cd ~/Downloads
 6263  ls -l
 6264  java -jar ./parquet-tools-1.8.0.jar --help
 6265  java -jar ./parquet-tools-1.8.0.jar help
 6266  java -jar ./parquet-tools-1.8.0.jar -help
 6267  java -jar ./parquet-tools-1.8.0.jar --help
 6268  java -jar ./parquet-tools-1.8.0.jar merge
 6269  java -jar ./parquet-tools-1.8.0.jar meta ~/parquets/new/part-00000-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet
 6270  java -jar ./parquet-tools-1.8.0.jar meta -n 100 ~/parquets/new/part-00000-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet
 6271  java -jar ./parquet-tools-1.8.0.jar meta -n100 ~/parquets/new/part-00000-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet
 6272  java -jar ./parquet-tools-1.8.0.jar meta ~/parquets/new/part-00000-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet -n100
 6273  java -jar ./parquet-tools-1.8.0.jar meta ~/parquets/new/part-00000-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet -n 100
 6274  java -jar ./parquet-tools-1.8.0.jar meta -n=10 ~/parquets/new/part-00000-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet
 6275  java -jar ./parquet-tools-1.8.0.jar meta -n 10 ~/parquets/new/part-00000-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet
 6276  java -jar ./parquet-tools-1.8.0.jar meta --debug ~/parquets/new/part-00000-696fa539-7883-44f8-9db3-4d33c55dc82e.snappy.parquet
 6277  cd ..
 6278  ls -l new3
 6279  ls -l new4
 6280  ls -l
 6281  cd ..
 6282  ls -l
 6283  cd ,,
 6284  ls -l
 6285  cd Projetos
 6286  ls -l
 6287  cd horizon_event_stream
 6288  git status
 6289  git pull
 6290  cd ..
 6291  cp horizon_event_stream horizon_user_resolver
 6292  cp -R horizon_event_stream horizon_user_resolver
 6293  cd horizon_user_resolver
 6294  atom .
 6295  rm -rf target
 6296  ls -l
 6297  rm -rf .git
 6298  ls -l
 6299  sbt clean compile
 6300  ls -l
 6301  rm -rf target
 6302  ls -la
 6303  rm -rf .idea
 6304  ls -la
 6305  cd project
 6306  ls -l
 6307  cd target
 6308  ls -l
 6309  cd ..
 6310  cd project
 6311  ls -l
 6312  cd ..
 6313  ls -l
 6314  cd ..
 6315  ls -l
 6316  vi project/Dependencies.scala
 6317  sbt clean compile
 6318  sbt clean assembly
 6319  echo $SPARK_HOME
 6320  cd ..
 6321  ls -l
 6322  cd spark-2.3.1-bin-hadoop2.7
 6323  ls -l
 6324  cd sbin
 6325  ls -l
 6326  history | grep export
 6327  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7"
 6328  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7"
 6329  ./user_resolver_local.sh
 6330  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7"
 6331  ./user_resolver_local.sh
 6332  mkdir /tmp/spark/logs
 6333  mkdir /tmp/spark
 6334  mkdir /tmp/spark/logs
 6335  ./user_resolver_local.sh
 6336  make build
 6337  nc -lk 9999
 6338  ./user_resolver_local.sh
 6339  nc -lk 9999
 6340  history | grep export
 6341  unset HADOOP_CONF_DIR
 6342  echo $HADOOP_CONF_DIR
 6343  echo $SPARK_HOME
 6344  echo $HADOOP_CONF_DIR
 6345  ./user_resolver_local.sh
 6346  make build
 6347  ./user_resolver_local.sh
 6348  sbt clean compile
 6349  cd ..
 6350  ls -l
 6351  cd redis-4.0.14
 6352  ls -l
 6353  cd src
 6354  ls -l
 6355  ./redis-se
 6356  ./redis-server
 6357  sbt clean compile
 6358  make build
 6359  ls -l
 6360  cd ..
 6361  cd redis-4.0.14
 6362  cd src
 6363  ./redis-c
 6364  ./redis-cli
 6365  ./user_resolver_local.sh
 6366  make build
 6367  ./user_resolver_local.sh
 6368  make build
 6369  ./user_resolver_local.sh
 6370  make build
 6371  ./user_resolver_local.sh
 6372  ls -l
 6373  cd kafka_2.11-0.10.1.1
 6374  ls -l
 6375  cd bin
 6376  ls -l
 6377  ./kafka-console-consumer.sh --broker-list kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hzt.g1 --from-beginning
 6378  ./kafka-console-consumer.sh --zookeeper kafka01.qa.globoi.com:2181,kafka02.qa.globoi.com:2181,kafka03.qa.globoi.com:2181 --topic hzt.g1 --from-beginning
 6379  ./kafka-console-consumer.sh --bootstrap-server kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hzt.g1 --from-beginning
 6380  ./kafka-console-consumer.sh --bootstrap-server kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hzt.ge --from-beginning
 6381  ./kafka-console-consumer.sh --bootstrap-server kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hzt.ge 
 6382  ./kafka-console-consumer.sh
 6383  ./kafka-console-consumer.sh --bootstrap-server kafka01.globoi.com:9092,kafka02.globoi.com:9092 --topic hzt.globolive --from-beginning
 6384  ./kafka-console-consumer.sh --bootstrap-server kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hzt.ab
 6385  ./kafka-console-consumer.sh --bootstrap-server kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hzt.g1 --from-beginning
 6386  curl -vvv 'https://horizon-track.qa.globo.com/event/g1' -H 'Referer: https://g1.globo.com/politica/noticia/2019/07/03/relator-da-previdencia-pode-fazer-ajustes-em-texto-diz-presidente-da-comissao.ghtml' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryEoJ2xvLuVkPZxIGW' --data-binary $'------WebKitFormBoundaryEoJ2xvLuVkPZxIGW\r\nContent-Disposition: form-data; name="data"\r\n\r\neyJob3Jpem9uQ2xpZW50VVVJRCI6IjRiZGE3NDY5LTlkYTgtNDBkOS1hYjFhLTZlNjhlNjYzYjYzYSIsImhvcml6b25DbGllbnRUZW5hbnQiOiJnMSIsImhvcml6b25DbGllbnRUcyI6MTU2MjE3OTMxNjYwNywiaG9yaXpvbkNsaWVudFR5cGUiOiJqcyIsImhvcml6b25DbGllbnREZXZpY2VHcm91cCI6ImRlc2t0b3AiLCJob3Jpem9uRGlzcGF0Y2hOdW1iZXIiOjYsImhvcml6b25BY3Rpb25Db3VudGVyIjoxOSwiaG9yaXpvbkVudmlyb25tZW50Ijoid2ViIiwiYWN0aW9ucyI6W3siaWQiOiJtdWx0aWNvbnRlbnQtY2h1bmstdmlldyIsInZlcnNpb24iOiIzLjAiLCJwcm9wZXJ0aWVzIjp7ImNodW5rVHlwZSI6InBhcmFncmFwaCIsImNodW5rUG9zaXRpb24iOjQsImNodW5rSW50ZXJhY3Rpb24iOnRydWUsInZpZXdlZFRpbWVNcyI6MTE1ODQsIndvcmRDb3VudCI6MzIsImhlaWdodCI6MTI4LCJ3aWR0aCI6NjgwfSwidXJsIjoiaHR0cHM6Ly9nMS5nbG9iby5jb20vcG9saXRpY2Evbm90aWNpYS8yMDE5LzA3LzAzL3JlbGF0b3ItZGEtcHJldmlkZW5jaWEtcG9kZS1mYXplci1hanVzdGVzLWVtLXRleHRvLWRpei1wcmVzaWRlbnRlLWRhLWNvbWlzc2FvLmdodG1sIiwiYWN0aW9uVHMiOjE1NjIxNzkzMTYxMzYsImhvcml6b25DbGllbnRWZXJzaW9uIjoiMS4wLjMiLCJob3Jpem9uQ2xpZW50UmVmZXJlciI6Imh0dHBzOi8vZzEuZ2xvYm8uY29tLyIsImNvbnRlbnRUeXBlIjoibXVsdGljb250ZW50In0seyJpZCI6Im11bHRpY29udGVudC1jaHVuay12aWV3IiwidmVyc2lvbiI6IjMuMCIsInByb3BlcnRpZXMiOnsiY2h1bmtUeXBlIjoicGFyYWdyYXBoIiwiY2h1bmtQb3NpdGlvbiI6NSwiY2h1bmtJbnRlcmFjdGlvbiI6ZmFsc2UsInZpZXdlZFRpbWVNcyI6MTE1ODUsIndvcmRDb3VudCI6NTIsImhlaWdodCI6MTI4LCJ3aWR0aCI6NjgwfSwidXJsIjoiaHR0cHM6Ly9nMS5nbG9iby5jb20vcG9saXRpY2Evbm90aWNpYS8yMDE5LzA3LzAzL3JlbGF0b3ItZGEtcHJldmlkZW5jaWEtcG9kZS1mYXplci1hanVzdGVzLWVtLXRleHRvLWRpei1wcmVzaWRlbnRlLWRhLWNvbWlzc2FvLmdodG1sIiwiYWN0aW9uVHMiOjE1NjIxNzkzMTYxMzYsImhvcml6b25DbGllbnRWZXJzaW9uIjoiMS4wLjMiLCJob3Jpem9uQ2xpZW50UmVmZXJlciI6Imh0dHBzOi8vZzEuZ2xvYm8uY29tLyIsImNvbnRlbnRUeXBlIjoibXVsdGljb250ZW50In0seyJpZCI6Im11bHRpY29udGVudC1jaHVuay12aWV3IiwidmVyc2lvbiI6IjMuMCIsInByb3BlcnRpZXMiOnsiY2h1bmtUeXBlIjoicGFyYWdyYXBoIiwiY2h1bmtQb3NpdGlvbiI6NiwiY2h1bmtJbnRlcmFjdGlvbiI6ZmFsc2UsInZpZXdlZFRpbWVNcyI6MTE1ODUsIndvcmRDb3VudCI6NDgsImhlaWdodCI6MTYwLCJ3aWR0aCI6NjgwfSwidXJsIjoiaHR0cHM6Ly9nMS5nbG9iby5jb20vcG9saXRpY2Evbm90aWNpYS8yMDE5LzA3LzAzL3JlbGF0b3ItZGEtcHJldmlkZW5jaWEtcG9kZS1mYXplci1hanVzdGVzLWVtLXRleHRvLWRpei1wcmVzaWRlbnRlLWRhLWNvbWlzc2FvLmdodG1sIiwiYWN0aW9uVHMiOjE1NjIxNzkzMTYxMzcsImhvcml6b25DbGllbnRWZXJzaW9uIjoiMS4wLjMiLCJob3Jpem9uQ2xpZW50UmVmZXJlciI6Imh0dHBzOi8vZzEuZ2xvYm8uY29tLyIsImNvbnRlbnRUeXBlIjoibXVsdGljb250ZW50In0seyJpZCI6Im11bHRpY29udGVudC1jaHVuay12aWV3IiwidmVyc2lvbiI6IjMuMCIsInByb3BlcnRpZXMiOnsiY2h1bmtUeXBlIjoicGFyYWdyYXBoIiwiY2h1bmtQb3NpdGlvbiI6NywiY2h1bmtJbnRlcmFjdGlvbiI6ZmFsc2UsInZpZXdlZFRpbWVNcyI6MTE1ODYsIndvcmRDb3VudCI6MjIsImhlaWdodCI6OTYsIndpZHRoIjo2ODB9LCJ1cmwiOiJodHRwczovL2cxLmdsb2JvLmNvbS9wb2xpdGljYS9ub3RpY2lhLzIwMTkvMDcvMDMvcmVsYXRvci1kYS1wcmV2aWRlbmNpYS1wb2RlLWZhemVyLWFqdXN0ZXMtZW0tdGV4dG8tZGl6LXByZXNpZGVudGUtZGEtY29taXNzYW8uZ2h0bWwiLCJhY3Rpb25UcyI6MTU2MjE3OTMxNjEzNywiaG9yaXpvbkNsaWVudFZlcnNpb24iOiIxLjAuMyIsImhvcml6b25DbGllbnRSZWZlcmVyIjoiaHR0cHM6Ly9nMS5nbG9iby5jb20vIiwiY29udGVudFR5cGUiOiJtdWx0aWNvbnRlbnQifSx7ImlkIjoibXVsdGljb250ZW50LXZpZXciLCJ2ZXJzaW9uIjoiNC4wIiwicHJvcGVydGllcyI6eyJmZWVkU2VlbiI6ZmFsc2UsInRpbWVPbk11bHRpY29udGVudCI6Mjk0NTN9LCJ1cmwiOiJodHRwczovL2cxLmdsb2JvLmNvbS9wb2xpdGljYS9ub3RpY2lhLzIwMTkvMDcvMDMvcmVsYXRvci1kYS1wcmV2aWRlbmNpYS1wb2RlLWZhemVyLWFqdXN0ZXMtZW0tdGV4dG8tZGl6LXByZXNpZGVudGUtZGEtY29taXNzYW8uZ2h0bWwiLCJhY3Rpb25UcyI6MTU2MjE3OTMxNjM0MCwiaG9yaXpvbkNsaWVudFZlcnNpb24iOiIxLjAuMyIsImhvcml6b25DbGllbnRSZWZlcmVyIjoiaHR0cHM6Ly9nMS5nbG9iby5jb20vIiwiY29udGVudFR5cGUiOiJtdWx0aWNvbnRlbnQifV19\r\n------WebKitFormBoundaryEoJ2xvLuVkPZxIGW\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryEoJ2xvLuVkPZxIGW--\r\n' --compressed
 6387  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'Referer: https://g1.globo.com/politica/noticia/2019/07/03/relator-da-previdencia-pode-fazer-ajustes-em-texto-diz-presidente-da-comissao.ghtml' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryEoJ2xvLuVkPZxIGW' --data-binary $'------WebKitFormBoundaryEoJ2xvLuVkPZxIGW\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryEoJ2xvLuVkPZxIGW\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryEoJ2xvLuVkPZxIGW--\r\n' --compressed
 6388  ls -ls
 6389  kafka-topics.sh
 6390  ./kafka-topics.sh
 6391  ./kafka-topics.sh --zookeeper kafka01.qa.globoi.com:2181,kafka02.qa.globoi.com:2181,kafka03.qa.globoi.com:2181 --list
 6392  ./kafka-topics.sh --list --zookeeper kafka01.qa.globoi.com:2181,kafka02.qa.globoi.com:2181,kafka03.qa.globoi.com:2181
 6393  ./kafka-console-consumer.sh --bootstrap-server kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hzt-qa.g1 --from-beginning
 6394  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'Referer: https://g1.globo.com/politica/noticia/2019/07/03/relator-da-previdencia-pode-fazer-ajustes-em-texto-diz-presidente-da-comissao.ghtml' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryEoJ2xvLuVkPZxIGW' --data-binary $'------WebKitFormBoundaryEoJ2xvLuVkPZxIGW\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryEoJ2xvLuVkPZxIGW\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryEoJ2xvLuVkPZxIGW--\r\n' --compressed
 6395  ls -l
 6396  cd spark-2.3.1-bin-hadoop2.7
 6397  ls -l
 6398  ./bin/spark-shell --packages "org.apache.kafka:kafka-streams:jar:0.10.1.1"
 6399  ./bin/spark-shell --packages "org.apache.kafka:kafka-streams:0.10.1.1"
 6400  ls -l
 6401  ls -la
 6402  vi .sbt
 6403  cd .sbt/0.13
 6404  ls -l
 6405  cd ..
 6406  ls -l
 6407  touch repositories
 6408  vi repositories
 6409  ./bin/spark-shell --packages "org.apache.kafka:kafka-streams:0.10.1.1"
 6410  ./bin/spark-shell --jar ~/Projetos/horizon_user_resolver/target/scala-2.11/horizon_user_resolver.jar
 6411  ./bin/spark-shell --jars ~/Projetos/horizon_user_resolver/target/scala-2.11/horizon_user_resolver.jar
 6412  ./bin/spark-shell --jars ~/Projetos/horizon_user_resolver/target/scala-2.11/horizon_user_resolver.jar,~/Downloads/spark-sql-kafka-0-10_2.11-2.3.0.jar
 6413  ./bin/spark-shell --jars ~/Downloads/spark-sql-kafka-0-10_2.11-2.3.0.jar
 6414  make build
 6415  ./bin/spark-shell --jars ~/Projetos/horizon_user_resolver/target/scala-2.11/horizon_user_resolver.jar
 6416  ./bin/spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.2.0
 6417  ./bin/spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0
 6418  cd ..
 6419  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/cluster_compressday.git
 6420  cd cluster_compressday
 6421  cd ..
 6422  git clone gitlab@gitlab.globoi.com:BigDataPipeline/hadoop2gcs.git
 6423  cd hadoop2gcs
 6424  git status
 6425  git pull
 6426  ls -l
 6427  cd ..
 6428  ls -l
 6429  cd ..
 6430  cd Projetos
 6431  ls -l
 6432  cd horizon-storage
 6433  atom .
 6434  cd ..
 6435  ls -l
 6436  cd cluster_compressday
 6437  make test
 6438  git status
 6439  git pull
 6440  git diff
 6441  git add .
 6442  git commit -m "feat: add measures"
 6443  git push origin master 
 6444  git status
 6445  git diff
 6446  git checkout src/main/scala/com/globo/cluster/CompressDay.scala
 6447  cd ..
 6448  ls -l
 6449  cd hadoop2gcs
 6450  git status
 6451  git diff
 6452  git add .
 6453  git commit -m "feat: add measures logs"
 6454  git push origin master
 6455  tsuru app-shell -a horizon-http-stream-prod
 6456  tsuru app-info -a horizon-http-stream-prod
 6457  history
 6458  cd ..
 6459  ls -l
 6460  cd ..
 6461  ls -l
 6462  cd spark-2.3.1-bin-hadoop2.7
 6463  ./bin/spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0
 6464  ps aux | grep 4040
 6465  ps aux | grep spark
 6466  kill -9 11074
 6467  ps aux | grep spark
 6468  kill -9 94116
 6469  ps aux | grep spark
 6470  ./bin/spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0
 6471  cd ..
 6472  ls -l
 6473  cd horizon_user_resolver
 6474  make build
 6475  history | grep echo
 6476  echo $SPARK_HOME
 6477  echo $HADOOP_CONF_DIR
 6478  echo $SPARK_HOME
 6479  pwd
 6480  cd /Users/leonardo.neuwald/Projetos/horizon_user_resolver
 6481  ls -l
 6482  ./user_resolver_local.sh
 6483  make build
 6484  ./user_resolver_local.sh
 6485  make build
 6486  ./user_resolver_local.sh
 6487  make build
 6488  ./user_resolver_local.sh
 6489  brew install htop
 6490  htop
 6491  yarn application -list | grep application_1539207608922_256055
 6492  yarn application -kill application_1539207608922_256055
 6493  ls -l
 6494  make build
 6495  ./user_resolver_local.sh
 6496  make build
 6497  ./user_resolver_local.sh
 6498  make build
 6499  ./user_resolver_local.sh
 6500  make build
 6501  ./user_resolver_local.sh
 6502  ls -l
 6503  cd ..
 6504  ls -l
 6505  cd ..
 6506  ls -l
 6507  cd ..
 6508  cd Projetos
 6509  ls -l
 6510  cd horizon_user_resolver
 6511  ls -l
 6512  cd redis-4.0.14
 6513  cd src
 6514  ./redis-cli
 6515  ./bin/spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0
 6516  ls -l
 6517  make build
 6518  ./user_resolver_local.sh
 6519  make build
 6520  ./user_resolver_local.sh
 6521  make build
 6522  ./user_resolver_local.sh
 6523  make build
 6524  history | grep tsuru
 6525  tsuru service instance status tsuru-dbaas-dev horizon_user_resolver_qa
 6526  tsuru service instance status tsuru-dbaas-dev horizon_user_mapping_qa
 6527  tsuru service instance info tsuru-dbaas-dev horizon_user_mapping_qa
 6528  tsuru service instance
 6529  tsuru service instance status
 6530  tsuru service instance status tsuru-dbaas-dev horizon_user_mapping_qa
 6531  ./redis-cli -u cluster://:SFZy6C4K9D@horizonuse-01-156235538264.dev.redis.globoi.com:6379,horizonuse-02-156235538264.dev.redis.globoi.com:6379,horizonuse-03-156235538264.dev.redis.globoi.com:6379,horizonuse-04-156235538264.dev.redis.globoi.com:6379,horizonuse-05-156235538264.dev.redis.globoi.com:6379,horizonuse-06-156235538264.dev.redis.globoi.com:6379/0
 6532  ./redis-cli -u cluster://SFZy6C4K9D@horizonuse-01-156235538264.dev.redis.globoi.com:6379,horizonuse-02-156235538264.dev.redis.globoi.com:6379,horizonuse-03-156235538264.dev.redis.globoi.com:6379,horizonuse-04-156235538264.dev.redis.globoi.com:6379,horizonuse-05-156235538264.dev.redis.globoi.com:6379,horizonuse-06-156235538264.dev.redis.globoi.com:6379/0
 6533  ./redis-cli -u redis://SFZy6C4K9D@horizonuse-01-156235538264.dev.redis.globoi.com:6379,horizonuse-02-156235538264.dev.redis.globoi.com:6379,horizonuse-03-156235538264.dev.redis.globoi.com:6379,horizonuse-04-156235538264.dev.redis.globoi.com:6379,horizonuse-05-156235538264.dev.redis.globoi.com:6379,horizonuse-06-156235538264.dev.redis.globoi.com:6379/0
 6534  ./redis-cli -c -h cluster://SFZy6C4K9D@horizonuse-01-156235538264.dev.redis.globoi.com:6379
 6535  ./redis-cli -u cluster://SFZy6C4K9D@horizonuse-01-156235538264.dev.redis.globoi.com:6379
 6536  ./redis-cli -u cluster://SFZy6C4K9D@horizonuse-01-156235538264.dev.redis.globoi.com:6379/0
 6537  ./redis-cli -u redis://SFZy6C4K9D@horizonuse-01-156235538264.dev.redis.globoi.com:6379/0
 6538  history | grep redis
 6539  ./redis-cli horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6540  ./redis-cli -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6541  ./redis-cli -x horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6542  ./redis-cli -c horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6543  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6544  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019/month=6/day=28
 6545  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019
 6546  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019/month=6/day=28
 6547  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=6/day=28
 6548  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=6
 6549  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=7
 6550  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019/month=6
 6551  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019/month=7
 6552  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=6
 6553  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=7
 6554  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=6/day=29
 6555  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=6/day=3
 6556  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=6/day=30
 6557  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=7/day=4
 6558  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=7/day=3
 6559  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=7/day=2
 6560  hdfs dfs -ls /warehouse/videosession/parquet/glb_product=canal_philos/year=2019/month=7/day=1
 6561  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019/month=7/day=1
 6562  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019/month=7/day=2
 6563  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019/month=7/day=3
 6564  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019/month=7/day=5
 6565  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=canal_philos/year=2019/month=7/day=4
 6566  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=6/day=28\n
 6567  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=6/day=29\n
 6568  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=6/day=30\n
 6569  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=7/day=1\n
 6570  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=7/day=2\n
 6571  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=7/day=3\n
 6572  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=7/day=5\n
 6573  hdfs dfs -ls /warehouse/videolivesession/parquet/glb_product=canal_philos/year=2019/month=7/day=4\n
 6574  tsuru app-info -a horizon-track-qa
 6575  history | grep echo
 6576  echo $SPARK_HOME
 6577  echo $HADOOP_CONF_DIR
 6578  ./user_resolver_local.sh
 6579  make build
 6580  sbt clean compile
 6581  make build
 6582  ls -l
 6583  ./user_resolver_local.sh
 6584  make build
 6585  ls -l
 6586  echo $HADOOP_CONF_DIR
 6587  cd Projetos
 6588  ls -l
 6589  cd horizon_user_resolver
 6590  make build
 6591  ./user_resolver_local.sh
 6592  history | grep SPARK_
 6593  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7"
 6594  ./user_resolver_local.sh
 6595  ls -l
 6596  make build
 6597  ./user_resolver_local.sh
 6598  ls -l file:/Users/leonardo.neuwald/Projetos/horizon_user_resolver/./target/scala-2.11/horizon_user_resolver.jar
 6599  ls -l file:/Users/leonardo.neuwald/Projetos/horizon_user_resolver/target/scala-2.11/horizon_user_resolver.jar
 6600  ls -l /Users/leonardo.neuwald/Projetos/horizon_user_resolver/target/scala-2.11/horizon_user_resolver.jar
 6601  ./user_resolver_local.sh
 6602  sbt clean assembly
 6603  ./user_resolver_local.sh
 6604  sbt clean assembly
 6605  ./user_resolver_local.sh
 6606  sbt clean assembly
 6607  ./user_resolver_local.sh
 6608  sbt clean assembly
 6609  ./user_resolver_local.sh
 6610  sbt clean assembly
 6611  ./user_resolver_local.sh
 6612  history | grep curl
 6613  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'Referer: https://g1.globo.com/politica/noticia/2019/07/03/relator-da-previdencia-pode-fazer-ajustes-em-texto-diz-presidente-da-comissao.ghtml' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryEoJ2xvLuVkPZxIGW' --data-binary $'------WebKitFormBoundaryEoJ2xvLuVkPZxIGW\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundaryEoJ2xvLuVkPZxIGW\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundaryEoJ2xvLuVkPZxIGW--\r\n' --compressed
 6614  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6615  ls -l
 6616  cd ..
 6617  ls -l
 6618  cd ..
 6619  ls -l
 6620  cd spark-2.3.1-bin-hadoop2.7
 6621  ls -l
 6622  cd bin
 6623  ls -l
 6624  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6625  l s-l
 6626  ls -l
 6627  pwd
 6628  cd ~/go/src/gitlab.globoi.com/bigdata/pipeline/horizon-user-resolver
 6629  code .
 6630  history | grep curl
 6631  ls -l
 6632  cd ..
 6633  cd ~/Projetos
 6634  ls -l
 6635  cd recommendation
 6636  cd ..
 6637  cd spark-2.3.1-bin-hadoop2.7
 6638  cd bin
 6639  history | grep spark-shell
 6640  ./bin/spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0
 6641  ./spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0
 6642  pwd
 6643  make test
 6644  mvn clean dependencyGraph > ferrou.txt
 6645  vi ferrou.txt
 6646  mvn clean dependencyGraph
 6647  sbt clean dependencyGraph 
 6648  sbt clean dependencyGraph > ferrou.txt
 6649  sbt clean test
 6650  ls -l
 6651  cd ..
 6652  ls -l
 6653  cd horizon_user_resolver
 6654  ls -l
 6655  pwd
 6656  cd ..
 6657  cd azkaban
 6658  ls -l
 6659  cd azkaban-gcp-billing
 6660  git status
 6661  history | grep pyenv
 6662  pyenv activate gpc-billing
 6663  python billing-gcs-companies-bigdata.py 2019 07 09 y
 6664  pyenv deactivate gpc-billing
 6665  cd ..
 6666  ls -l
 6667  cd horizon_avro_stream
 6668  atom .
 6669  ./spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0
 6670  pwd
 6671  cd ..
 6672  cd go
 6673  ls -l
 6674  cd src
 6675  ls -l
 6676  cd gitlab.globoi.com
 6677  ls -l
 6678  cd bigdata
 6679  ls -l
 6680  cd pipeline
 6681  ls -l
 6682  cd horizon-legacy-stream
 6683  code .
 6684  cd ..
 6685  git clone gitlab@gitlab.globoi.com:bigdata/anonymous-cipher-go.git
 6686  ls -l
 6687  cd anonymous-cipher-go
 6688  code .
 6689  tsuru env
 6690  tsuru env-get 
 6691  tsuru env-get --app horizon-track-service-prod
 6692  tsuru app-shell -a horizon-track-service-prod
 6693  cd ..
 6694  ls -l
 6695  cd ..
 6696  ls -l
 6697  cd Projetos
 6698  ls -l
 6699  cd horizon_user_resolver
 6700  ls -l
 6701  sbt clean test
 6702  make clean compile
 6703  sbt clean compile
 6704  sbt clean test
 6705  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6706  make build
 6707  ls -l
 6708  cd ..
 6709  ls l-
 6710  cd ..
 6711  cd leonardo.neuwald
 6712  ls -l
 6713  cd Projetos/
 6714  git clone gitlab@gitlab.globoi.com:bigdata/pipeline/horizon-user-mapping.git
 6715  cd horizon-user-mapping
 6716  git checkout -b feat/create-horizon-user-mapping
 6717  ./user_mapping_local.sh
 6718  echo $SPARH_HOME
 6719  history | grep HADOOP
 6720  echo $HADOOP_CONF_DIR
 6721  history | grep SPARK
 6722  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7"
 6723  ./user_mapping_local.sh
 6724  cd ..
 6725  pwd
 6726  ls -la
 6727  rm -rf .idea
 6728  rm -rf target
 6729  cd project
 6730  ls -l
 6731  ls -la project
 6732  ls -la target
 6733  cd ..
 6734  ls -l
 6735  cd project
 6736  rm -rf project
 6737  rm -rf target
 6738  ls -l 
 6739  cd .
 6740  cd ..
 6741  ls -l
 6742  rm -rf spark-warehouse
 6743  ls -l
 6744  cd horizon-user-mapping
 6745  ls -l
 6746  git status
 6747  cp .gitignore ../horizon-user-mapping/
 6748  cp .gitlab-ci.yml ../horizon-user-mapping/
 6749  git status
 6750  git add .
 6751  git commit -m "feat: create horizon-user-mapping project"
 6752  git status
 6753  git push origin feat/create-horizon-user-mapping 
 6754  uptime
 6755  cd ~/Downloads
 6756  hdfs dfs -ls /
 6757  history | grep export
 6758  export HADOOP_CONF_DIR=~/configs/conf-prod
 6759  hdfs dfs -ls /
 6760  ls -l 
 6761  history | grep export
 6762  export HADOOP_USER_NAME=hadoop
 6763  hdfs dfs -put redisclient_2.11-3.0.jar /spark
 6764  hdfs dfs -ls /
 6765  cd ..
 6766  cd Projetos
 6767  cd hydrogen/hydrogen.sales-data/
 6768  ls -l
 6769  history | grep export
 6770  export HADOOP_USER_NAME=horizon
 6771  hdfs dfs -ls /horizon/bin
 6772  hdfs dfs -put ojdbc8.jar /horizon/bin
 6773  hdfs dfs -ls /horizon/bin
 6774  history | grep redis
 6775  hdfs dfs -get /spark/spark-2.0.1.tar
 6776  ls -l
 6777  pwd
 6778  git status
 6779  cd ...
 6780  ls -l
 6781  cd Projetos
 6782  ls -l
 6783  cd horizon-user-mapping
 6784  git status
 6785  git pull
 6786  ./user_mapping_local.sh
 6787  sbt clean assembly
 6788  cd ..
 6789  ls -l
 6790  cd ..
 6791  ls -l
 6792  cd horizon_events_aggregator
 6793  ls -l
 6794  git pull
 6795  cd ~/Downloads
 6796  ls -l
 6797  ls -la | grep pes
 6798  mv tasks_agg-pes_v1.json agg-pes_v1.json
 6799  hdfs dfs -ls /user/actions/confs
 6800  export HADOOP_USER_NAME=actions
 6801  hdfs dfs -put agg-pes_v1.json /user/actions/confs
 6802  history | grep export
 6803  history | grep echo
 6804  echo $HADOOP_CONF_DIR
 6805  echo $SPARK_HOME
 6806  ./user_mapping_local.sh
 6807  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6808  curl --vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundarybhAuooAcX2qz7w1u' --data-binary $'------WebKitFormBoundarybhAuooAcX2qz7w1u\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundarybhAuooAcX2qz7w1u\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundarybhAuooAcX2qz7w1u--\r\n' --compressed
 6809  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'Referer: https://g1.globo.com/' -H 'Origin: https://g1.globo.com' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36' -H 'Content-Type: multipart/form-data; boundary=----WebKitFormBoundarybhAuooAcX2qz7w1u' --data-binary $'------WebKitFormBoundarybhAuooAcX2qz7w1u\r\nContent-Disposition: form-data; name="data"\r\n\r\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\r\n------WebKitFormBoundarybhAuooAcX2qz7w1u\r\nContent-Disposition: form-data; name="encoding"\r\n\r\nbase64\r\n------WebKitFormBoundarybhAuooAcX2qz7w1u--\r\n' --compressed
 6810  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiMGJmZWU3NzUtOGViMy00ZmU2LTk4OGYtODk5NmYxY2IzOTkyIn0.Nj08xR-vpm_r5AXV5IzR0rpsPx6ZDa438bsMSh2OrVd6nvZ3iFsLizEVJgl0qZXFkQz77Erf6qshOGGZyfZTkJm3iOQtU_TFmaZN3-PbRrqKpleu5tFKyTxiTyWkRT0a_kXV0cp4x3Focl-JLrmQPtwHGzGINkbSH_CTfP-H5nbhFLEb9L5J0a2AaccWODcTQFLoWKgG1FdB3Ydr8pxloOD5f_73jYe28wM6uO2hb6h1-d_C0iGghttam8bT1CkpKq9ZmwAi4NHrl6LhjOlUKmd5-Kp8DBXcMQ_yF9IQ8Mfwc9uRbQ31RFv0S_D19NNal5lPjPfrEqjqRwjv4Ed2Hg; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f00838$_sn:4$_ss:0$_st:1562943953137$_pn:3%3Bexp-session$ses_id:1562942004327%3Bexp-session; glb_uid="vmnqD5Xd1phDSloGpyXMvOHPcz5IqBGuAyNK8z__x8A="; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data ''
 6811  ./user_mapping_local.sh
 6812  sbt clean assembly
 6813  ./user_mapping_local.sh
 6814  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiMGJmZWU3NzUtOGViMy00ZmU2LTk4OGYtODk5NmYxY2IzOTkyIn0.Nj08xR-vpm_r5AXV5IzR0rpsPx6ZDa438bsMSh2OrVd6nvZ3iFsLizEVJgl0qZXFkQz77Erf6qshOGGZyfZTkJm3iOQtU_TFmaZN3-PbRrqKpleu5tFKyTxiTyWkRT0a_kXV0cp4x3Focl-JLrmQPtwHGzGINkbSH_CTfP-H5nbhFLEb9L5J0a2AaccWODcTQFLoWKgG1FdB3Ydr8pxloOD5f_73jYe28wM6uO2hb6h1-d_C0iGghttam8bT1CkpKq9ZmwAi4NHrl6LhjOlUKmd5-Kp8DBXcMQ_yF9IQ8Mfwc9uRbQ31RFv0S_D19NNal5lPjPfrEqjqRwjv4Ed2Hg; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f00838$_sn:4$_ss:0$_st:1562943953137$_pn:3%3Bexp-session$ses_id:1562942004327%3Bexp-session; glb_uid="vmnqD5Xd1phDSloGpyXMvOHPcz5IqBGuAyNK8z__x8A="; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data ''
 6815  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6816  sbt clean assembly
 6817  ./user_mapping_local.sh
 6818  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6819  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiMGJmZWU3NzUtOGViMy00ZmU2LTk4OGYtODk5NmYxY2IzOTkyIn0.Nj08xR-vpm_r5AXV5IzR0rpsPx6ZDa438bsMSh2OrVd6nvZ3iFsLizEVJgl0qZXFkQz77Erf6qshOGGZyfZTkJm3iOQtU_TFmaZN3-PbRrqKpleu5tFKyTxiTyWkRT0a_kXV0cp4x3Focl-JLrmQPtwHGzGINkbSH_CTfP-H5nbhFLEb9L5J0a2AaccWODcTQFLoWKgG1FdB3Ydr8pxloOD5f_73jYe28wM6uO2hb6h1-d_C0iGghttam8bT1CkpKq9ZmwAi4NHrl6LhjOlUKmd5-Kp8DBXcMQ_yF9IQ8Mfwc9uRbQ31RFv0S_D19NNal5lPjPfrEqjqRwjv4Ed2Hg; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f00838$_sn:4$_ss:0$_st:1562943953137$_pn:3%3Bexp-session$ses_id:1562942004327%3Bexp-session; glb_uid="vmnqD5Xd1phDSloGpyXMvOHPcz5IqBGuAyNK8z__x8A="; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data ''
 6820  sbt clean assembly
 6821  ./user_mapping_local.sh
 6822  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiMGJmZWU3NzUtOGViMy00ZmU2LTk4OGYtODk5NmYxY2IzOTkyIn0.Nj08xR-vpm_r5AXV5IzR0rpsPx6ZDa438bsMSh2OrVd6nvZ3iFsLizEVJgl0qZXFkQz77Erf6qshOGGZyfZTkJm3iOQtU_TFmaZN3-PbRrqKpleu5tFKyTxiTyWkRT0a_kXV0cp4x3Focl-JLrmQPtwHGzGINkbSH_CTfP-H5nbhFLEb9L5J0a2AaccWODcTQFLoWKgG1FdB3Ydr8pxloOD5f_73jYe28wM6uO2hb6h1-d_C0iGghttam8bT1CkpKq9ZmwAi4NHrl6LhjOlUKmd5-Kp8DBXcMQ_yF9IQ8Mfwc9uRbQ31RFv0S_D19NNal5lPjPfrEqjqRwjv4Ed2Hg; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f00838$_sn:4$_ss:0$_st:1562943953137$_pn:3%3Bexp-session$ses_id:1562942004327%3Bexp-session; glb_uid="vmnqD5Xd1phDSloGpyXMvOHPcz5IqBGuAyNK8z__x8A="; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data ''
 6823  sbt assembly
 6824  ./user_mapping_local.sh
 6825  sbt assembly
 6826  ./user_mapping_local.sh
 6827  sbt assembly
 6828  ./user_mapping_local.sh
 6829  sbt assembly
 6830  ./user_mapping_local.sh
 6831  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6832  vi ./user_mapping_local.sh
 6833  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com,horizonuse-02-156235538264.dev.redis.globoi.com,horizonuse-03-156235538264.dev.redis.globoi.com,horizonuse-04-156235538264.dev.redis.globoi.com,horizonuse-05-156235538264.dev.redis.globoi.com,horizonuse-06-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6834  ./redis-cli -c -h horizonuse-01-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6835  ./redis-cli -c -h horizonuse-02-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6836  ./redis-cli -c -h horizonuse-03-156235538264.dev.redis.globoi.com -a SFZy6C4K9D -p 6379
 6837  pwd
 6838  ./spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 6839  vi ./user_mapping_local.sh
 6840  git status
 6841  git diff
 6842  sbt clean assembly
 6843  pwd
 6844  cd ..
 6845  ls -l
 6846  cd Projetos
 6847  ls -l
 6848  cd azkaban
 6849  ls -l
 6850  cd pipeline-horizon-stream-ingest
 6851  git status
 6852  git checkout master
 6853  git pull
 6854  atom .
 6855  git status
 6856  git diff
 6857  make zip
 6858  yarn application -list | grep application_1539207608922_233304
 6859  yarn application -kill application_1539207608922_233304
 6860  history | grep queue
 6861  yarn application -movetoqueue application_1539207608922_285494 -queue root.actions
 6862  ls -l
 6863  git status
 6864  git diff
 6865  make zip
 6866  yarn application -list | grep application_1539207608922_259304
 6867  yarn application -kill application_1539207608922_259304
 6868  git status
 6869  git diff
 6870  git status
 6871  git fetch -all
 6872  git fetch --all
 6873  git status
 6874  git diff
 6875  git checkout -b fix/increase-ab-and-globosat-resources
 6876  git status
 6877  git diff
 6878  git status
 6879  git diff
 6880  git status
 6881  git add jobs/horizon-track-event-stream-flow/hzt.globosat.job
 6882  git commit -m "fix: increase hzt.globosat resources"
 6883  git add jobs/horizon-track-event-stream-flow/hzt.ab.job
 6884  git commit -m "fix: increase hzt.ab resources"
 6885  git add jobs/horizon-track-event-stream-flow/hzt.hdfs.checker.job
 6886  git status
 6887  git commit -m "fix: add hzt.ab to hdfs.checker"
 6888  git status
 6889  git commit -m "docs: update CHANGELOG"
 6890  git add .
 6891  git commit -m "docs: update CHANGELOG"
 6892  git status
 6893  git push origin fix/increase-ab-and-globosat-resources 
 6894  sbt clean assembly
 6895  cd ~/Desktop
 6896  ls -l
 6897  while IFS="" read -r p || [ -n "$p" ]\ndo\n  printf '%s\n' "$p"\ndone < glbid.txt
 6898  ./scala --jars /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 6899  scala --jars /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 6900  scala --jar /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 6901  scala -jar /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 6902  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 6903  pwd
 6904  yarn application -list | grep application_1539207608922_231877
 6905  yarn application -kill application_1539207608922_231877
 6906  git status
 6907  git checkout master
 6908  git pull
 6909  make zip
 6910  yarn application -list | grep application_1539207608922_285513
 6911  yarn application -kill application_1539207608922_285513
 6912  history | grep queue
 6913  yarn application -movetoqueue application_1539207608922_288168 -queue root.actions
 6914  yarn application -movetoqueue application_1539207608922_259667 -queue root.actions
 6915  yarn application -movetoqueue application_1539207608922_288176 -queue root.actions
 6916  git status
 6917  git diff jobs/horizon-track-event-stream-flow/hzt.globosat.job
 6918  git checkout jobs/horizon-track-event-stream-flow/hzt.globosat.job
 6919  git diff jobs/horizon-track-event-stream-flow/hzt.ab.job
 6920  git status
 6921  git checkout -b "fix/increase-hzt-resources"
 6922  git diff jobs/horizon-track-event-stream-flow/hzt.globoplay.job
 6923  git diff jobs/horizon-track-event-stream-flow/hzt.g1.job
 6924  make zip
 6925  git diff
 6926  yarn application -list | grep application_1539207608922_285494
 6927  yarn application -kill application_1539207608922_285494
 6928  yarn application -movetoqueue application_1539207608922_288192 -queue root.actions
 6929  yarn application -list | grep application_1539207608922_281356
 6930  yarn application -kill application_1539207608922_281356
 6931  git status
 6932  git diff
 6933  git add jobs/horizon-track-event-stream-flow/hzt.ab.job
 6934  git commit -m "fix: increase hzt.ab maxrateperpart"
 6935  yarn application -list | grep application_1539207608922_288168
 6936  git diff
 6937  yarn application -kill application_1539207608922_288168
 6938  make zip
 6939  git diff
 6940  git status
 6941  git diff
 6942  yarn application -kill application_1539207608922_288226
 6943  make zip
 6944  yarn application -movetoqueue application_1539207608922_288205 -queue root.actions
 6945  make zip
 6946  yarn application -list | grep application_1539207608922_288205
 6947  yarn application -kill application_1539207608922_288205
 6948  make zip
 6949  yarn application -movetoqueue application_1539207608922_288231 -queue root.actions
 6950  yarn application -movetoqueue application_1539207608922_278173 -queue root.actions
 6951  yarn application -movetoqueue application_1539207608922_259305 -queue root.actions
 6952  make zip
 6953  yarn application -kill application_1539207608922_233303
 6954  yarn application -kill application_1539207608922_288176
 6955  yarn application -movetoqueue application_1539207608922_258298 -queue root.actions
 6956  yarn application -movetoqueue application_1539207608922_258872 -queue root.actions
 6957  yarn application -kill application_1539207608922_288357
 6958  make zip
 6959  yarn application -movetoqueue application_1539207608922_288358 -queue root.actions
 6960  git status
 6961  git diff jobs/horizon-track-event-stream-flow/hzt.g1.job
 6962  git add jobs/horizon-track-event-stream-flow/hzt.g1.job
 6963  git commit -m "fix: increase hzt.g1 resources"
 6964  git status
 6965  git push origin fix/increase-hzt-resources 
 6966  git diff
 6967  git status
 6968  git diff
 6969  git status
 6970  git diff
 6971  git status
 6972  git add jobs/horizon-track-event-stream-flow/hzt.player.job
 6973  git commit -m "fix: decrease hzt.player resources"
 6974  git push origin fix/increase-hzt-resources 
 6975  git diff
 6976  git status
 6977  git add jobs/horizon-track-event-stream-flow/hzt.globoplay.job
 6978  git commit -m "fix: decrease hzt.globoplay resources"
 6979  git commit --amend
 6980  git status
 6981  git diff
 6982  git status
 6983  git push origin fix/increase-hzt-resources 
 6984  git status
 6985  git add jobs/horizon-track-event-stream-flow/hzt.globosat.job
 6986  git commit -m "fix: increase hzt.globosat resources"
 6987  history | grep docs
 6988  git commit -m "docs: update changelog"
 6989  git add .
 6990  git commit -m "docs: update changelog"
 6991  git status
 6992  git push origin fix/increase-hzt-resources 
 6993  yarn application -movetoqueue application_1539207608922_288318 -queue root.actions
 6994  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 6995  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiZWNmMzQ0MGUtMjkyMS00NmNlLWI2MDItZWMyODVmOGFiM2U4In0.RKdtgIp477-Ct2QA3Q_H-aLANPFF80cdaXSYcpLQy_wWQuE8iTR4MjMgkLGDxcGnxoohpN2FRAyyMPUm1WscYnrnkh6O3YKs5C5kpKbjm_RIhTZBs4t4_8otpGlVwhwENVT9Kyw5G8hWVRAJ8xkjTIcfs2Pzxp7ToHuPlV2U5WAEEVsmnFec9LSRvBc_n2xHPnNajLx97Li_tWPlYCR921tcNpmUGhvEenOCs_XtEjaIUmv3_XRfHG9TtocdShfp838XTBwg4Obonz5zpNS96BrreSx6-zC5KkzcKuuUfioYPX4-lXCDt0imZJUzFU8nCfp82wASDJPdpxT-J-rINA; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=FXsiSWpUCUPlbaCRhtbgPZ0Z6HbKQ0KJvMCGxBK-MfI=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data ''\ncurl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiM2EwN2E0OTUtNDlkOS00ZDY1LWI5OGUtYzIzOTQ3OGFjNTZiIn0.HXttBrpAJUfzlIWQTkcsKAlsOJNnGStK8_GtbK1sEdXYMR6IW7qRviXY7E39QcCc4OEhwMgktJmPC5bbJsLycmCIEvst3P13DL0_XylDH_AgbC-rMqfBFDbJrxjzUV5xVdUS7ahSxtw-Sl3erejpQVbDHDrGOih42C0oZxD25QxSat-4Drn3qdi_WwwzckKBzjJdpxQAwRStdHLtnUJ3YLrajbH1kky0a9EYQdQRIm1Ci8-qbxHCQqaTJ8asCCnt1cMQfbXNPjEJ5Kw0sLUMQGII5_XXeXdkWzevfnKC6uU1W1nVmBF-h2yrJKekSuMEOBgQX2kzXJ_98RUbkEW8WA; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=V2l-DP8mNMLOs_7MleB90Ug_w-zD5O2UOiPykSNLaFs=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data ''\ncurl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiMGYxNDA5NTctMzU4My00ZDQzLWFkMGYtMDQ0ZDQwYmJmMGY2In0.DdADTNhNfxNSoRkXe4fFrr9sAXMF6B8n-YYBXdJd0aQvyADm625ymwjIrHZahOOrUI90F8kKh9ZMb3VrjdSvig3wVAV52hZbc6gUQTYrjPpllpZtEyrUSTrqHZgsJf2tWbeBbdMHQ_oPO94zzyaM-uUHIzUyMMrYUgy8JQVAHE4x2w0wsJG3FH0rEqGELcZDvKc8sFvkqenO0mzs5ccGEK21FN33MS0J576aaONm8LwYuEMVD5HIYynVYGV3jEO-C1vnQp0VBgKJubM2br4aK3vue1RJVKLXdXx5RJg0xLGirlshHPYyH8Dea7PHgc2qtqYjne7HhWWR2P2De3j4kg; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=oyPCVXCewcq0ouDapqCjvjTZ5g1ksIq_nhjJyfI9nYc=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data ''
 6996  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 6997  exit
 6998  yarn application -movetoqueue application_1539207608922_288318 -queue root.default
 6999  sbt clean assembly
 7000  ./user_mapping_local.sh
 7001  while read line; do curl -vvv $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7002  pwd
 7003  history
 7004  vi /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7005  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiYzUwYzMxMmMtYzhjMi00N2UyLThjNjEtNDAwNGFiZjJhZDNmIn0.SAXh9VOoYN16mep7aHGJwYPc0oyq3Lo_HfQZ2HbZukjODRRO6BqhJu8WGaP1EiMUGUZGC03Gfz1MA9BlznOIFJ1tsUvF0w4q6Q6LQjBmSocc5flsY2b4BMYkUEqXSU7w4s16pgfuFTbantQVQ8SMF5OJTHwioXwfe5brMcoftUOL8eq3vwkILsnW5GihrLZN2FwK8mzEKqBWxrlhkJGP7qaizW412Yl4wCVb-FCK1FbE72xRwFrRecNc6c6Z9xklHndJKYMFzc8uzwKU1kNhjfoFnNj8KY6XqTN59xTRwanEtVrcoIo1yGxU81hu6iS_pGzcBayi2tTQM2FOq4FTvw; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=jpeWeMMCSIITrfKHtIg1-oOLVfE0jZM3RKTK6ICBABk=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data ''
 7006  while read line; do curl -vvv $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7007  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiYzUwYzMxMmMtYzhjMi00N2UyLThjNjEtNDAwNGFiZjJhZDNmIn0.SAXh9VOoYN16mep7aHGJwYPc0oyq3Lo_HfQZ2HbZukjODRRO6BqhJu8WGaP1EiMUGUZGC03Gfz1MA9BlznOIFJ1tsUvF0w4q6Q6LQjBmSocc5flsY2b4BMYkUEqXSU7w4s16pgfuFTbantQVQ8SMF5OJTHwioXwfe5brMcoftUOL8eq3vwkILsnW5GihrLZN2FwK8mzEKqBWxrlhkJGP7qaizW412Yl4wCVb-FCK1FbE72xRwFrRecNc6c6Z9xklHndJKYMFzc8uzwKU1kNhjfoFnNj8KY6XqTN59xTRwanEtVrcoIo1yGxU81hu6iS_pGzcBayi2tTQM2FOq4FTvw; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=jpeWeMMCSIITrfKHtIg1-oOLVfE0jZM3RKTK6ICBABk=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data '' 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiYzUwYzMxMmMtYzhjMi00N2UyLThjNjEtNDAwNGFiZjJhZDNmIn0.SAXh9VOoYN16mep7aHGJwYPc0oyq3Lo_HfQZ2HbZukjODRRO6BqhJu8WGaP1EiMUGUZGC03Gfz1MA9BlznOIFJ1tsUvF0w4q6Q6LQjBmSocc5flsY2b4BMYkUEqXSU7w4s16pgfuFTbantQVQ8SMF5OJTHwioXwfe5brMcoftUOL8eq3vwkILsnW5GihrLZN2FwK8mzEKqBWxrlhkJGP7qaizW412Yl4wCVb-FCK1FbE72xRwFrRecNc6c6Z9xklHndJKYMFzc8uzwKU1kNhjfoFnNj8KY6XqTN59xTRwanEtVrcoIo1yGxU81hu6iS_pGzcBayi2tTQM2FOq4FTvw; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=jpeWeMMCSIITrfKHtIg1-oOLVfE0jZM3RKTK6ICBABk=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data '' 
 7008  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiYzUwYzMxMmMtYzhjMi00N2UyLThjNjEtNDAwNGFiZjJhZDNmIn0.SAXh9VOoYN16mep7aHGJwYPc0oyq3Lo_HfQZ2HbZukjODRRO6BqhJu8WGaP1EiMUGUZGC03Gfz1MA9BlznOIFJ1tsUvF0w4q6Q6LQjBmSocc5flsY2b4BMYkUEqXSU7w4s16pgfuFTbantQVQ8SMF5OJTHwioXwfe5brMcoftUOL8eq3vwkILsnW5GihrLZN2FwK8mzEKqBWxrlhkJGP7qaizW412Yl4wCVb-FCK1FbE72xRwFrRecNc6c6Z9xklHndJKYMFzc8uzwKU1kNhjfoFnNj8KY6XqTN59xTRwanEtVrcoIo1yGxU81hu6iS_pGzcBayi2tTQM2FOq4FTvw; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=jpeWeMMCSIITrfKHtIg1-oOLVfE0jZM3RKTK6ICBABk=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data '' \ncurl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiYWEzNWQyN2MtM2QzOC00YjM3LWJkNDYtOTZlMTFkZDU0YTU1In0.Z8MU7xSPcmccZ0qt3sNzFPDj-GhVwU7FPWqW3-YGCB0SIMBGw3ZRnzyoeDdsJfEuQtx66ENXtTIQxUpD-0ARVDEz68pS_sf6kSAJW_R9ZWfCxUKxje9Tj_q8a1x3sQQO1LNFLBe9LlHHSfDvIJMO8biXzu2L2nDV8JEuSXFuIRtMeQ0LjXAB_DMNpqd4Ywbc6bvpuAqhyT86r6tGXsd_5iWrhhDqAUlh81q6Q0gcGstMIKJCGE9GiN89xQT-ME2WjY1Ga_HMwcE7ckQdbFD61A0MnCl4NaiFs-B4FfzbfjXaSRBeDwVkHm2aeCflefBDUAMPNy5rhgcf4xsduwJQdQ; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=Eyyyyeva3NvIlzYVE6CRZnD4jwNJNqpQijUtXf6RjJM=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data '' \ncurl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiNTgzYjVmMWEtMzNmYi00YTVjLTkwNGMtMmExYjkwYjY4NTc5In0.WzEbrzzJwIR4JXmYG-IjWKBejU_hoDZwij9GrCY3X8mBPRINj_zZQB9pOY7qi99LA9_EftMqQ-qHqFxEa8WsvymM0F29WkqnAPMuAu8W4kWoi-8rR3n8aIuBrbWyAsnqpQ9LHYcJC804sW4dM1rBKatkUjv-9syzncE9aou3ZzxCQdzvlBWgeYs9DfV38v3cQ9xOY8zkbRahd9xS-UPBPUuHWt44ZkgKhslu1hYeAnhaodQsqeqxHdq2HGZMZWrJguMG8rOIAYPzLBFlNlWAg6mHCTdIvmjhxCXPqn01KSgIuPgJQa_NcAzMDSSYAvnjm0Wp6jhF2yOfAADUvFHjaA; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=WnovrDpKoYnjLtrMHHmx9mDulgcG9h3JvhHd_fIe40o=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data '' \ncurl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiMWNhMTc4ZTgtZWIzOC00NzMwLTg1OGUtYjk2ODg1M2IxYzhhIn0.ClP2mdKiYhACdQXkFCZxq1WIAQUBnDbszzJk3ovtWZtw4qJFG7AW1tIzqMek0Sou32fbzUdG1qPPu-QeQWCwshfABCVOQVEdYYIMjFRaIbKm-tmqHUXGd1TghTHQ4iYCKfXI0Dgxbdq6od9kMA-b2rdMB8Nqxw5cqAN9Y0xhHVI1yRg53UWQqd6wDN3mZNh0mTsIwIcJzFdHtytaFUxvAQfjx8oUwyueTNllRMrfonKG_dGedXmGQAhSbTeW4f5X-AzVm61hfAT9Qs0B5CytvEnWF48fzaPFiMOkER7Kl_6ErxoxRXTFk2_2Qs5PCEArjN9BKV2mB-2YGUr-LRBSyw; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=cZgoOvVeqsB6V35pS4jXbg-_dK80LZr4aWh8BQ2YEAw=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data '' \ncurl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiM2ZhMjBjYjctOGE3My00NzQzLTg2NjMtYmQzY2M3M2ZmMmNhIn0.maszH-CVRXtltEr6SrOVXFeGbzRWpy5fEROdrFbRE1PpNjh9YN4K-5U4hGMfo5L64GUhO9Y62Ol2oYrALhFYrf9Q3SD6kHXAldiSCY0x1tHzkRkkrcev5j1oHu9ESOeuqH_Ue23PW-XGKoyth71RGFqNFa_suxHmoRkKfIIJa4fxEsdUfZpMJUu4BTgYMmqpJ9zDbKJdlm8W3Z7WPMWARr9FYb2h9JFPnZ7XoSVfE37Mf5tXTClxXtG8LmGlsQm5RXjuVpu5YzhFca8yZlme1dZoVMFe9IxMnNLuxgLq2zg8f4Ta5PkSCdmLcicf7jN-cphl4ttUFpOoaXH05sVoTw; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=iOQHF9D32Y0VvR2AmOc4nHtsci8O_iOgQszvk3gUWvM=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data '' \n
 7009  history | grep while
 7010  while read line; do curl -vvv $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7011  while read line; do echo $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7012  while read line; do sleep 1; curl -vvv $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7013  histor
 7014  history
 7015  ./configure --with-darwinssl\n
 7016  while read line; do sleep 1; curl -vvv $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7017  while read line; do sleep 1; curl -vvv -k $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7018  while read line; do sleep 1; echo $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7019  curl -vvv 'https://horizon-track.qa.globoi.com/event/g1' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:67.0) Gecko/20100101 Firefox/67.0' -H 'Accept: */*' -H 'Accept-Language: pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Referer: https://g1.globo.com/df/distrito-federal/noticia/2019/07/11/justica-do-df-arquiva-denuncia-de-jornalista-contra-eduardo-bolsonaro-por-ameaca-e-injuria.ghtml' -H 'Content-Type: multipart/form-data; boundary=---------------------------4384222775468166821265448861' -H 'Connection: keep-alive' -H 'Cookie: GLOBO_ID=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJnbG9ib0lkIjoiYzUwYzMxMmMtYzhjMi00N2UyLThjNjEtNDAwNGFiZjJhZDNmIn0.SAXh9VOoYN16mep7aHGJwYPc0oyq3Lo_HfQZ2HbZukjODRRO6BqhJu8WGaP1EiMUGUZGC03Gfz1MA9BlznOIFJ1tsUvF0w4q6Q6LQjBmSocc5flsY2b4BMYkUEqXSU7w4s16pgfuFTbantQVQ8SMF5OJTHwioXwfe5brMcoftUOL8eq3vwkILsnW5GihrLZN2FwK8mzEKqBWxrlhkJGP7qaizW412Yl4wCVb-FCK1FbE72xRwFrRecNc6c6Z9xklHndJKYMFzc8uzwKU1kNhjfoFnNj8KY6XqTN59xTRwanEtVrcoIo1yGxU81hu6iS_pGzcBayi2tTQM2FOq4FTvw; utag_main=v_id:016b2fe7c15d000e7dd186504b2700052001f00f07%3Bexp-session; glb_uid=jpeWeMMCSIITrfKHtIg1-oOLVfE0jZM3RKTK6ICBABk=; nav13574=a3c399ea990d3e5fdf35d0eb709|2_194_4:1:11:14:5:2_1:1:43:8-101:1:2; _fbp=fb.1.1559876862900.149599396; __gads=ID=a1142bd411f15c82:T=1559876871:S=ALNI_Mbuz1PYj699-ksIJUuU6pyQTS-I6w; _ga=GA1.2.2128295085.1559876922; __tbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; xbc=%7Bjbd%7DeyJ2IjozLCJwayI6InowY0RjZlVSd3pHQ2FLcWRxREE3MHR3eDdMU1NPdUxKTTUzQ2pNbnRiQTRVeGROTDJkTE5uOFBNb3RSNSIsInNrIjoiR1RDb3BJRGM1eiJ9; cto_lwid=49519559-aceb-4a75-a688-4471318be785; cto_idcpy=f1150aad-451b-4fca-a4ac-4d51bae0ed6d; hsid=4012b53f-5978-4b52-bd82-d94888b13638; _ttdmp=E:2|A:4|X:4|C:1|LS:|CA:CA18886,CA18895,CA18914,CA19015; _gid=GA1.2.1994763482.1562942023; _gat_tealium_0=1' --data '' 
 7020  while read line; do sleep 1; curl -vvv -k $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7021  pwd
 7022  history | grep scala
 7023  while read line; do sleep 1; bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7024  history
 7025  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7026  ./user_mapping_local.sh
 7027  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7028  sbt clean assembly
 7029  ./user_mapping_local.sh
 7030  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7031  ./user_mapping_local.sh
 7032  htop
 7033  ps aux | grep spark
 7034  javac
 7035  sbt clean assembly
 7036  ./user_mapping_local.sh
 7037  sbt clean assembly
 7038  ./user_mapping_local.sh
 7039  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7040  sbt clean assembly
 7041  ./user_mapping_local.sh
 7042  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7043  ls -l
 7044  cd ..
 7045  ls -l
 7046  cd pipeline
 7047  java
 7048  java -version
 7049  ./user_mapping_local.sh
 7050  ps aux | grep spark
 7051  ps -p 2575 -lfT | wc -l
 7052  ps aux | grep spark
 7053  ps -p 2575 -lfT | wc -l
 7054  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7055  ps -p 2575 -lfT | wc -l
 7056  htop
 7057  ps -p 2575 -lfT | wc -l
 7058  jstack -l 2575 | grep tid | wc -l
 7059  jstack -l 2575
 7060  jstack -l 2575 > ~/tdump.txt
 7061  jstack -l 2575 | grep tid | wc -l
 7062  sbt clean assembly
 7063  ./user_mapping_local.sh
 7064  jstack -l 2575 | grep tid | wc -l
 7065  htop
 7066  jstack -l 7101 | grep tid | wc -l
 7067  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7068  jstack -l 7101 | grep tid | wc -l
 7069  sbt clean assembly
 7070  ./user_mapping_local.sh
 7071  jstack -l 7101 | grep tid | wc -l
 7072  htop
 7073  jstack -l 10836 | grep tid | wc -l
 7074  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7075  jstack -l 10836 | grep tid | wc -l
 7076  ls -l
 7077  history | grep scala
 7078  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7079  jstack -l 10836 | grep tid | wc -l
 7080  tsuru app-log -a horizon-track-service-prod
 7081  tsuru app-log -f -a horizon-track-service-prod
 7082  tsuru app-log -f -a horizon-track-service-prod > ~/raw_requests.txt
 7083  history | grep spark-shell
 7084  echo $SPARK_HOME
 7085  hdfs dfs -ls /
 7086  hdfs dfs -ls /horizon/bin/hydrogen.user-frequency.jar
 7087  git status
 7088  git diff
 7089  git add .
 7090  git status
 7091  git reset src/main/scala/com/globo/bigdata/pipeline/mapping/source/KafkaSource.scala
 7092  git status
 7093  git reset test.txt requests.txt
 7094  git status
 7095  git reset src/main/scala/com/globo/bigdata/pipeline/mapping/extractor/UserExtractorByCookie.scala
 7096  git reset src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisClusterUserStorage.scala
 7097  git status
 7098  git reset src/main/scala/com/globo/bigdata/pipeline/mapping/sync/writer/UserForeachWriter.scala
 7099  git reset src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisUserStorage.scala
 7100  git status
 7101  git diff
 7102  git add src/main/scala/com/globo/bigdata/pipeline/mapping/extractor/UserExtractorByCookie.scala
 7103  git commit -m "style: remove underscore on filter"
 7104  git status
 7105  git add src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisClusterUserStorage.scala src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisUserStorage.scala
 7106  git add src/main/scala/com/globo/bigdata/pipeline/mapping/sync/writer/UserForeachWriter.scala
 7107  git commit -m "fix: connections open with redis"
 7108  git status
 7109  git push origin feat/create-horizon-user-mapping 
 7110  ps aux | grep spark
 7111  ps aux | grep scala
 7112  kill -9 19832
 7113  "zMi__u8gj4fq0hPVhzT0MtMbhyIC4JgNlggAbnJT6gI=",
 7114  "roKS8TU0vi9UpnU3ixTThyFImTdrKVJclIsnrV99MEQ=",
 7115  "z4w6RKGFmaW-Hg5q0PsqiE5Uo4tx09IrtNwfzJrYUzE=",
 7116  "A_vwIZ5AZ25ak3yyYV5Z27V2xSnKSiDU9yvXqNZnFh8=",
 7117  "qXpvzgrcwbrvwZ02SF3oaF9yC31xK8ikrcOzCCHFVuo=",
 7118  "q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTI4=",
 7119  "5ygTnXFMLkJcSD7ZIuvUOOAwu9ceYyRlB1S1RiI4yzc=",
 7120  "RkxEYmfnJhgSkKkVNHcQRwMPWvbYUVwju_FYfKBtDeI=",
 7121  "ZVzpM05KMDOBHis-Y8YABwVcOER3mSmqAqhwb3yliOU=",
 7122  "-CnjRY0Kx"roKS8TU0vi9UpnU3ixTThyFImTdrKVJclIsnrV99MEQ=",\n"z4w6RKGFmaW-Hg5q0PsqiE5Uo4tx09IrtNwfzJrYUzE=",\n"A_vwIZ5AZ25ak3yyYV5Z27V2xSnKSiDU9yvXqNZnFh8=",\n"qXpvzgrcwbrvwZ02SF3oaF9yC31xK8ikrcOzCCHFVuo=",\n"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTI4=",\n"5ygTnXFMLkJcSD7ZIuvUOOAwu9ceYyRlB1S1RiI4yzc=",\n"RkxEYmfnJhgSkKkVNHcQRwMPWvbYUVwju_FYfKBtDeI=",\n"ZVzpM05KMDOBHis-Y8YABwVcOER3mSmqAqhwb3yliOU=",\n"-CnjRY0Kx"roKS8TU0vi9UpnU3ixTThyFImTdrKVJclIsnrV99MEQ=",
 7123  "z4w6RKGFmaW-Hg5q0PsqiE5Uo4tx09IrtNwfzJrYUzE=",
 7124  "A_vwIZ5AZ25ak3yyYV5Z27V2xSnKSiDU9yvXqNZnFh8=",
 7125  "qXpvzgrcwbrvwZ02SF3oaF9yC31xK8ikrcOzCCHFVuo=",
 7126  "q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z4w6RKGFmaW-Hg5q0PsqiE5Uo4tx09IrtNwfo65Cn0v06ev"A_vwIZ5AZ25ak3yyYV5Z27V2xSnKSiDU9yvXqNZnFh8="Ye"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z_j"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z6f"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"zWj"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"m4v"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"zr1"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"zUp"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z4w6RKGFmaW-Hg5q0PsqiE5Uo4tx09IrtNwfo65Cn0v06ev"A_vwIZ5AZ25ak3yyYV5Z27V2xSnKSiDU9yvXqNZnFh8="Ye"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z_j"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z6f"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"zWj"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"m4v"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"zr1"q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"zUp"q2g3dwv8KMBsfYYU-355z\n""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7127  ""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7128  """q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7129  ""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n"""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7130  """q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7131  ""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n"""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7132  """q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7133  ""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n"""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7134  """q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7135  ""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n"""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7136  """q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7137  ""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n"""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z\n""q2=""""q2g3dwv8KMBsfYYU-355zND1WfcBp07d-l7lAzYWTrp"z
 7138  history
 7139  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7140  ps aux | grep scala
 7141  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7142  git status
 7143  sbt clean assembly
 7144  ./user_mapping_local.sh
 7145  history | grep bash
 7146  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests_1000000.txt
 7147  ls -l
 7148  cd ..
 7149  ls -l
 7150  cd Projetos
 7151  ls -l
 7152  cd horizon-user-mapping
 7153  sbt clean assembly
 7154  cd ..
 7155  ls -l
 7156  cd ..
 7157  ls -l
 7158  history | grep scala
 7159  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7160  ./user_mapping_local.sh
 7161  sbt clean assembly
 7162  ./user_mapping_local.sh
 7163  sbt clean assembly
 7164  ./user_mapping_local.sh
 7165  vi /tmp/user-mapping-offsets.txt
 7166  sbt clean assembly
 7167  ls -l /Users/leonardo.neuwald/.m2/repository/org/slf4j
 7168  ls -l /Users/leonardo.neuwald/.m2/repository/org/slf4j/slf4j-log4j12
 7169  rm -rf /Users/leonardo.neuwald/.m2/repository/org/slf4j/slf4j-log4j12
 7170  sbt clean assembly
 7171  ls -l /Users/leonardo.neuwald/.m2/repository/org/slf4j/slf4j-log4j12
 7172  ls -l /Users/leonardo.neuwald/.m2/repository/org/slf4j/
 7173  rm -rf ~/.ivy2/cache/org.slf4j/slf4j-log4j12
 7174  sbt clean assembly
 7175  vi /tmp/user-mapping-offsets.txt
 7176  ./user_mapping_local.sh
 7177  ls -l
 7178  vi ./user_mapping_local.sh
 7179  vi /tmp/user-mapping-offsets.txt
 7180  vi ./user_mapping_local.sh
 7181  ./user_mapping_local.sh
 7182  sbt clean assembly
 7183  rm -rf /tmp/user-mapping-offsets.txt
 7184  ./user_mapping_local.sh
 7185  vi /tmp/user-mapping-offsets.txt
 7186  cat /tmp/user-mapping-offsets.txt
 7187  vi /tmp/user-mapping-offsets.txt
 7188  cat /tmp/user-mapping-offsets.txt
 7189  ./user_mapping_local.sh
 7190  cat /tmp/user-mapping-offsets.txt
 7191  ci ./user_mapping_local.sh
 7192  vi ./user_mapping_local.sh
 7193  ./user_mapping_local.sh
 7194  cat /tmp/user-mapping-offsets.txt
 7195  sbt clean compile
 7196  git status
 7197  git add src/main/scala/com/globo/bigdata/pipeline/mapping/HorizonUserMapping.scala src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala src/main/scala/com/globo/bigdata/pipeline/mapping/source/KafkaSource.scala src/main/scala/com/globo/bigdata/pipeline/mapping/source/OffsetsCheckpoint.scala
 7198  git status
 7199  git add user_mapping_local.sh
 7200  git commit -m "feat: restart query from last written offset"
 7201  git push origin feat/create-horizon-user-mapping 
 7202  ls -l
 7203  cd Projetos
 7204  ls -l
 7205  cd horizon-user-mapping
 7206  ls -l
 7207  sbt clean assembly
 7208  ls -l
 7209  echo $HADOOP_CONF_DIR
 7210  history | grep HADOOP_CONF_DIR
 7211  ./user_mapping_qa.sh
 7212  history | grep SPARK_HOME
 7213  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7"
 7214  ./user_mapping_qa.sh
 7215  ls -l ~/configs/conf-${DATA_FROM}
 7216  ls -l ~/configs/
 7217  pwd ~/configs/
 7218  cd ~/configs/
 7219  ls -l
 7220  pwd
 7221  ./user_mapping_qa.sh
 7222  cd ..
 7223  ls -l
 7224  cd Projetos
 7225  ls -l
 7226  cd azkaban
 7227  atom .
 7228  ./user_mapping_qa.sh
 7229  git status
 7230  git pull
 7231  ls -l
 7232  cd pipeline-horizon-stream-ingest
 7233  git checkout master
 7234  git pull
 7235  telnet 10.225.66.206 6379
 7236  ssh hadoop6.cmal08be-1200.cp.globoi.com\n
 7237  history | grep while
 7238  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7239  history | grep export
 7240  export HADOOP_USER_NAME=hadoop
 7241  export HADOOP_CONF_DIR=~/configs/conf-qa
 7242  hdfs dfs -ls /hdpapps/hadoop/yarn/local/usercache
 7243  ./user_mapping_qa.sh
 7244  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7245  ./user_mapping_qa.sh
 7246  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7247  git status
 7248  git pull
 7249  make zip
 7250  sbt clean assembly
 7251  yarn application -list | grep application_1562607983561_0006
 7252  yarn application -kill application_1562607983561_0006
 7253  ./user_mapping_qa.sh
 7254  sbt clean assembly
 7255  ./user_mapping_qa.sh
 7256  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7257  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7258  export HADOOP_CONF_DIR=~/configs/conf-prod
 7259  yarn application -list | grep application_1539207608922_291143
 7260  yarn application -kill application_1539207608922_291143
 7261  make zip
 7262  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests_1000000.txt
 7263  export HADOOP_CONF_DIR=~/configs/conf-qa
 7264  yarn application -list | grep application_1562607983561_0008
 7265  yarn application -kill application_1562607983561_0008
 7266  ./user_mapping_qa.sh
 7267  yarn application -kill application_1562607983561_0009
 7268  sbt clean assembly
 7269  ./user_mapping_qa.sh
 7270  yarn application -list | grep application_1562607983561_0010
 7271  yarn application -kill application_1562607983561_0010
 7272  ./user_mapping_qa.sh
 7273  yarn application -list | grep application_1562607983561_0011
 7274  ./user_mapping_qa.sh
 7275  yarn application -kill application_1562607983561_0011
 7276  yarn application -kill application_1562607983561_0012
 7277  sbt clean assembly
 7278  yarn application -list | grep application_1539207608922_279033
 7279  history | grep prod
 7280  export HADOOP_CONF_DIR=~/configs/conf-prod
 7281  yarn application -list | grep application_1539207608922_279033
 7282  yarn application -kill application_1539207608922_279033
 7283  yarn application -kill application_1539207608922_279034
 7284  sbt clean assembly
 7285  ./user_mapping_qa.sh
 7286  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7287  export HADOOP_CONF_DIR=~/configs/conf-qa
 7288  yarn application -kill application_1562607983561_0013
 7289  yarn application -list | grep application_1562607983561_0013
 7290  yarn application -kill  application_1562607983561_0013
 7291  ./user_mapping_qa.sh
 7292  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests_1000000.txt
 7293  git status
 7294  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/resolver/GlbUidResolver.scala
 7295  git add src/main/scala/com/globo/bigdata/pipeline/mapping/resolver/GlbUidResolver.scala
 7296  git commit -m "fix: changes to make this class serializable"
 7297  git status
 7298  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala
 7299  git status
 7300  git add user_mapping_local.sh user_mapping_qa.sh
 7301  git commit -m "feat: add scripts to run the project"
 7302  git status
 7303  git diff project/Dependencies.scala
 7304  git status
 7305  git diff
 7306  git add project/Dependencies.scala
 7307  git commit -m 
 7308  git commit -m "chore: removed deprecated dependency"
 7309  git status
 7310  git diff
 7311  git status
 7312  git diff
 7313  git add src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala src/main/scala/com/globo/bigdata/pipeline/mapping/resolver/GlbUidResolver.scala src/test/scala/com/globo/bigdata/pipeline/mapping/resolver/GlbUidResolverTest.scala
 7314  git commit -m "fix: invert brace"
 7315  git status
 7316  git push origin feat/create-horizon-user-mapping 
 7317  sbt clean test
 7318  git status
 7319  git diff
 7320  git add src/test/scala/com/globo/bigdata/pipeline/mapping/resolver/GlbUidResolverTest.scala src/main/scala/com/globo/bigdata/pipeline/mapping/resolver/GloboIdResolver.scala src/main/scala/com/globo/bigdata/pipeline/mapping/resolver/GlbUidResolver.scala
 7321  git commit -m "fix: invert brace"
 7322  git diff
 7323  git status
 7324  git diff
 7325  git add src/main/scala/com/globo/bigdata/pipeline/mapping/source/RequestSource.scala
 7326  git commit -m "refactor: removed useless import"
 7327  git status
 7328  git diff
 7329  git commit -m "refactor: removed prints"
 7330  git add src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala src/main/scala/com/globo/bigdata/pipeline/mapping/source/KafkaSource.scala
 7331  git commit -m "refactor: removed prints"
 7332  git push origin feat/create-horizon-user-mapping 
 7333  git status
 7334  git diff
 7335  sbt clean assembly
 7336  yarn application -kill application_1562607983561_0014
 7337  git status
 7338  ./user_mapping_qa.sh
 7339  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests_1000000.txt
 7340  pwd
 7341  cd Projetos
 7342  ls -l
 7343  cd azkaban
 7344  ls -l
 7345  cd azkaban-gcp-billing
 7346  git status
 7347  git pull
 7348  history | grep pyenv
 7349  pyenv activate gpc-billing
 7350  python billing-gcs-companies-ga.py 2019 07 18 y
 7351  pyenv deactivate gpc-billing
 7352  sbt clean assembly
 7353  export HADOOP_CONF_DIR=~/configs/conf-qa
 7354  yarn application -list | grep application_1562607983561_0015
 7355  yarn application -kill application_1562607983561_0015
 7356  history | grep HORIZON
 7357  history | grep HADOOP
 7358  export HADOOP_USER_NAME=actions
 7359  make deploy-qa
 7360  ./user_mapping_qa.sh
 7361  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7362  export HADOOP_CONF_DIR=~/configs/conf-prod
 7363  yarn application -list | grep application_1539207608922_279050
 7364  yarn application -kill application_1539207608922_279050
 7365  tsuru app-log -f -a horizon-track-qa
 7366  tsuru app-log -f -a horizon-track-qa | grep 503
 7367  tsuru app-log -f -a horizon-track-qa
 7368  tsuru app-log -f -a horizon-track-service-prod | grep 503
 7369  wget horizon-track.qa.globoi.com
 7370  curl -vvv horizon-track.qa.globoi.com
 7371  tsuru app-log -f -a horizon-track-qa
 7372  tsuru app-log -f -a horizon-track-qa | grep 503
 7373  d ..
 7374  cd ..
 7375  ls -l
 7376  cd ..
 7377  ls -l
 7378  cd spark-2.3.1-bin-hadoop2.7
 7379  ls -l
 7380  history | grep echo
 7381  echo $HADOOP_CONF_DIR
 7382  unset HADOOP_CONF_DIR
 7383  echo $HADOOP_CONF_DIR
 7384  tsuru app-log -f -a horizon-track-qa
 7385  tsuru app-log -f -a horizon-track-qa | grep 503
 7386  history | grep spark
 7387  ./spark-shell --packages com.redislabs:spark-redis:2.3.0
 7388  ./bin/spark-shell --packages com.redislabs:spark-redis:2.3.0
 7389  tsuru app-log -f -a horizon-track-qa
 7390  tsuru app-log -f -a horizon-track-qa | grep 503
 7391  tsuru app-log -f -a horizon-track-qa
 7392  tsuru app-log -f -a horizon-track-qa | grep 503
 7393  tsuru app-log -f -a horizon-track-qa
 7394  tsuru app-log -f -a horizon-track-qa | grep 503
 7395  tsuru app-log -f -a horizon-track-qa
 7396  ./bin/spark-shell --packages com.redislabs:spark-redis:2.3.0 --jars ~/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar
 7397  ./bin/spark-shell --packages com.redislabs:spark-redis:2.3.0 --jars ~/Downloads/spark-redis-2.3.1-jar-with-dependencies.jar,~/Downloads/spark-redis-2.3.1.jar
 7398  ./bin/spark-shell --packages com.redislabs:spark-redis:2.3.0 --jars ~/Downloads/spark-redis-2.3.1-jar-with-dependencies.jar;~/Downloads/spark-redis-2.3.1.jar
 7399  ./bin/spark-shell --packages com.redislabs:spark-redis:2.3.0 --jars ~/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar;~/Downloads/spark-redis-2.3.1.jar
 7400  ./bin/spark-shell --jars ~/Downloads/spark-redis-2.3.1.jar
 7401  ./bin/spark-shell --jars ~/Downloads/spark-redis-2.3.1.jar,~/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar
 7402  ./bin/spark-shell --jars ~/Downloads/spark-redis-2.3.1.jar;~/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar
 7403  ./bin/spark-shell --jars ~/Downloads/spark-redis-2.3.1.jar:~/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar
 7404  ./bin/spark-shell --jars ~/Downloads/*.jar
 7405  ./bin/spark-shell --jars ~/Downloads/spark-redis-2.3.1.jar --driver-class-path ~/Downloads/spark-redis-2.3.1.jar:~/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar
 7406  ./bin/spark-shell --jars ~/Downloads/spark-redis-2.3.1.jar;~/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar --driver-class-path ~/Downloads/spark-redis-2.3.1.jar:~/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar
 7407  sbt clean compile
 7408  sbt clean assembly
 7409  pwd
 7410  ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7411  ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar --conf spark.executor.extraLibraryPath=/Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7412  ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar --conf spark.executor.extraLibraryPath=/Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar --conf spark.driver.extraClassPath=/Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7413  import com.redislabs.provider.redis.RedisEndpoint
 7414  import org.apache.spark.sql.types.StructField
 7415  import org.apache.spark.sql.types.StringType
 7416  import org.apache.spark.sql.types.StructType
 7417  val host = s"""horizonuse-01-156235538264.dev.redis.globoi.com,horizonuse-02-156235538264.dev.redis.globoi.com,horizonuse-03-156235538264.dev.redis.globoi.com,horizonuse-04-156235538264.dev.redis.globoi.com,horizonuse-05-156235538264.dev.redis.globoi.com,horizonuse-06-156235538264.dev.redis.globoi.com"""
 7418  val port = 6379
 7419  val password = "SFZy6C4K9D"
 7420  spark.conf.set("redis.host", "horizonuse-02-156235538264.dev.redis.globoi.com")
 7421  spark.conf.set("redis.port", "6379")
 7422  spark.conf.set("redis.auth", password)
 7423  val df = spark.read.format("org.apache.spark.sql.redis").schema(\n                StructType(Array(\n                  StructField("globo_id", StringType),\n                  StructField("glb_uid", StringType))\n                )\n              ).option("key.column", "globo_id").load()\n\n\n\n\n\t\n\n:qiit
 7424  ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar --conf spark.executor.extraLibraryPath=/Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar --conf spark.driver.extraClassPath=/Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7425  import com.redislabs.provider.redis.RedisEndpoint
 7426  import org.apache.spark.sql.types.StructField
 7427  import org.apache.spark.sql.types.StringType
 7428  import org.apache.spark.sql.types.StructType
 7429  val host = s"""horizonuse-01-156235538264.dev.redis.globoi.com,horizonuse-02-156235538264.dev.redis.globoi.com,horizonuse-03-156235538264.dev.redis.globoi.com,horizonuse-04-156235538264.dev.redis.globoi.com,horizonuse-05-156235538264.dev.redis.globoi.com,horizonuse-06-156235538264.dev.redis.globoi.com"""
 7430  val port = 6379
 7431  val password = "SFZy6C4K9D"
 7432  spark.conf.set("redis.host", "horizonuse-02-156235538264.dev.redis.globoi.com")
 7433  spark.conf.set("redis.port", "6379")
 7434  spark.conf.set("redis.auth", password)
 7435  val df = spark.read.format("org.apache.spark.sql.redis").schema(\n                StructType(Array(\n                  StructField("globo_id", StringType),\n                  StructField("glb_uid", StringType))\n                )\n              ).option("key.column", "globo_id").load()\n\n\n
 7436  ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar --conf spark.executor.extraClassPath=/Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar --conf spark.driver.extraClassPath=/Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7437  sbt clean assembly
 7438  ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar --conf spark.executor.extraClassPath=/Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7439  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar
 7440  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar
 7441  telnet horizonuse-01-156235538264.dev.redis.globoi.com 6379
 7442  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar
 7443  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar --conf "spark.executor.extraJavaOptions=-verbose:class"  --conf "spark.driver.extraJavaOptions=-verbose:class"\n
 7444  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar --conf "spark.redis.port=6379" --conf spark.redis.auth=SFZy6C4K9D" --conf "spark.redis.host=horizonuse-01-156235538264.dev.redis.globoi.com"\n\n\n\n\n\nq\nasd\nsair\nfugir
 7445  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar --conf "spark.redis.port=6379" --conf "spark.redis.auth=SFZy6C4K9D" --conf "spark.redis.host=horizonuse-01-156235538264.dev.redis.globoi.com"\n\n\n\n\n\nq\nasd\nsair\nfugir
 7446  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar --conf "spark.redis.port=6379" --conf spark.redis.auth=SFZy6C4K9D" --conf "spark.redis.host=horizonuse-01-156235538264.dev.redis.globoi.com"
 7447  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.0-jar-with-dependencies.jar --conf "spark.redis.port=6379" --conf "spark.redis.auth=SFZy6C4K9D" --conf "spark.redis.host=horizonuse-01-156235538264.dev.redis.globoi.com"
 7448  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.1-jar-with-dependencies.jar,/Users/leonardo.neuwald/Downloads/jedis-3.0.0-m1.jar  --conf "spark.redis.port=6379" --conf "spark.redis.auth=SFZy6C4K9D" --conf "spark.redis.host=horizonuse-01-156235538264.dev.redis.globoi.com"
 7449  ls -l
 7450  cd Projetos
 7451  ls -l
 7452  cd ..
 7453  cd spark-2.3.1-bin-hadoop2.7
 7454  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.1-jar-with-dependencies.jar,/Users/leonardo.neuwald/Downloads/jedis-3.0.0-m1.jar  --conf "spark.redis.port=6379" --conf "spark.redis.auth=SFZy6C4K9D" --conf "spark.redis.host=horizonuse-01-156235538264.dev.redis.globoi.com"
 7455  ./bin/spark-shell --jars /Users/leonardo.neuwald/Downloads/spark-redis-2.3.1.jar,/Users/leonardo.neuwald/Downloads/spark-redis-2.3.1-jar-with-dependencies.jar,/Users/leonardo.neuwald/Downloads/jedis-3.0.0-m1.jar --conf "spark.redis.port=6379" --conf "spark.redis.auth=SFZy6C4K9D" --conf "spark.redis.host=horizonuse-01-156235538264.dev.redis.globoi.com"
 7456  cd ..
 7457  ls -l
 7458  cd Projetos
 7459  cd azkaban/azkaban-gcp-billing
 7460  history | grep pyenv
 7461  pyenv activate gpc-billing
 7462  python billing-gcs-companies-bigdata.py 2019 07 21 y
 7463  pyenv deactivate gpc-billing
 7464  wget https://grafana.video.globoi.com/
 7465  curl -vvv https://grafana.video.globoi.com/
 7466  git status
 7467  git diff
 7468  git status
 7469  git diff
 7470  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala
 7471  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/source/KafkaSource.scala
 7472  sbt clean assembly
 7473  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7474  telnet horizonuse-01-156380504344.redis.globoi.com
 7475  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7476  ./user_mapping_prod.sh
 7477  ./user_mapping_prod.sh
 7478  yarn application -list | grep application_1539207608922_294416
 7479  ssh cmah13lb17.globoi.com
 7480  yarn application -kill application_1539207608922_294416
 7481  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7482  ls -l
 7483  cd personal
 7484  ls- l
 7485  ls -l
 7486  cd deeplearning-dl4j
 7487  sbt clean assembly
 7488  ls -la ~/.ivy2/
 7489  ls -la ~/.sbt/
 7490  vi ~/.sbt/repositories
 7491  mv ~/.sbt/repositories ~/.sbt/repositories_2
 7492  sbt clean assembly
 7493  cd ..
 7494  ls -l
 7495  cd Projetos
 7496  ls -l
 7497  git clone https://github.com/RedisLabs/spark-redis.git
 7498  cd spark-redis
 7499  make package
 7500  mvn clean package --skipTests
 7501  mvn clean package -skipTest=true
 7502  mvn clean package --skipTests=true
 7503  mvn clean package -DskipTests
 7504  ls -l /Users/leonardo.neuwald/Projetos/spark-redis/target/
 7505  ls -l
 7506  hdfs dfs -ls /
 7507  hdfs dfs -ls /tmp
 7508  hdfs dfs -ls /tmp/user-mapping-offsets.txt
 7509  history | grep export
 7510  history | grep echo
 7511  echo $HADOOP_CONF_DIR
 7512  ./user_mapping_prod.sh
 7513  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7514  git status
 7515  git diff
 7516  yarn application -list | grep application_1539207608922_295247
 7517  yarn application -kill application_1539207608922_295247
 7518  hdfs dfs -ls /tmp/user-mapping-offsets.txt
 7519  yarn application -list | grep application_1539207608922_295247
 7520  ./user_mapping_prod.sh
 7521  hdfs dfs -ls /tmp
 7522  hdfs dfs -ls /
 7523  hdfs dfs -ls /tmp
 7524  ~/.m2/settings.xml
 7525  vi ~/.m2/settings.xml
 7526  vi ~/.sbt/repositories_2
 7527  ls -la ~/.sbt/repositories_2
 7528  ls -la ~/.ivy2
 7529  ls -la ~/.sbt
 7530  vi ~/.sbt/.credentials
 7531  vi ~/.m2/settings.xml
 7532  vi ~/.sbt/.credentials
 7533  ls -l
 7534  cd ..
 7535  cd Projetos
 7536  ls -l
 7537  cd spark-redis
 7538  git status
 7539  git diff
 7540  vi Makefile
 7541  history | grep mvn 
 7542  mvn clean package -DskipTests
 7543  vi ~/.m2/settings.xml
 7544  mvn clean package -DskipTests
 7545  mvn clean compile
 7546  mvn clean compile -force
 7547  mvn clean compile -Dforce
 7548  mvn clean compile -U
 7549  vi ~/.m2/settings.xml
 7550  mvn clean compile -U
 7551  mvn clean deploy -DskipTest
 7552  mvn clean deploy -DskipTests
 7553  cd ..
 7554  ls -l
 7555  cd ..
 7556  ls -l
 7557  cd spark-2.3.1-bin-hadoop2.
 7558  cd spark-2.3.1-bin-hadoop2.7
 7559  ls -l
 7560  history | grep spark
 7561  ls -l /Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT-jar-with-dependencies.jar
 7562  ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT-jar-with-dependencies.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT.jar,/Users/leonardo.neuwald/Downloads/jedis-3.0.0-m1.jar  --conf "spark.redis.port=6379" --conf "spark.redis.auth=SFZy6C4K9D" --conf "spark.redis.host=horizonuse-01-156235538264.dev.redis.globoi.com"
 7563  ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT-jar-with-dependencies.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT.jar,/Users/leonardo.neuwald/Downloads/jedis-3.0.0-m1.jar  --conf "spark.redis.port=6379" --conf "spark.redis.auth=uEdjy6sRVW" --conf "spark.redis.host=horizonuse-01-156380504344.redis.globoi.com"
 7564  ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT-jar-with-dependencies.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT.jar,/Users/leonardo.neuwald/Downloads/jedis-3.0.0-m1.jar  --conf "spark.redis.port=6379" --conf "spark.redis.auth=uEdjy6sRVW" --conf "spark.redis.host=horizonuse-01-156380504344.redis.globoi.com" --conf "spark.redis.timeout=10000"
 7565  ls -l /tmp/testeneuwald
 7566  ls -l /tmp/testeneuwald/cutted=a0/
 7567  yarn application -list | grep application_1539207608922_295256
 7568  yarn application -kill grep application_1539207608922_295256
 7569  yarn application -kill application_1539207608922_295256
 7570  cd ..
 7571  cd personal
 7572  ls -l
 7573  cd deeplearning-dl4j
 7574  ls -l
 7575  cd ..
 7576  ls -l
 7577  cd ..
 7578  ls -l
 7579  cd spark-2.3.1-bin-hadoop2.7
 7580  ls -l
 7581  cd sbin
 7582  ls -la
 7583  ./start-master.sh
 7584  tail -f /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 7585  tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 7586  ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 7587  tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 7588  ./tinyImagenetTrain.sh
 7589  unset HADOOP_CONF_DIR
 7590  ./tinyImagenetTrain.sh
 7591  scala
 7592  ps aux | grep spark
 7593  kill -9 61004
 7594  ps aux | grep spark
 7595  sbt clean assembly
 7596  echo $HADOOP_CONF_DIR
 7597  export HADOOP_CONF_DIR=~/configs/conf-qa
 7598  yarn application -list
 7599  ./user_mapping_qa.sh
 7600  hdfs dfs -ls /tmp
 7601  yarn application -list
 7602  hdfs dfs -ls /
 7603  hdfs dfs -ls /tmp
 7604  history | grep scala
 7605  scala -cp /Users/leonardo.neuwald/Projetos/horizon-user-mapping/target/scala-2.11/horizon_user_mapping.jar
 7606  yarn application -list
 7607  ./user_mapping_qa.sh
 7608  hdfs dfs -ls /tmp
 7609  hdfs dfs -text /tmp/user-mapping-offsets.txt
 7610  yarn application -list
 7611  while read line; do bash -c $line; done < /Users/leonardo.neuwald/Projetos/horizon-user-mapping/requests.txt
 7612  hdfs dfs -ls /user
 7613  hdfs dfs -ls /user/actions/
 7614  hdfs dfs -ls /user/actions/confs
 7615  hdfs dfs -ls /user/actions/stream
 7616  hdfs dfs -ls /user/actions/stream/checkpoints
 7617  hdfs dfs -ls /user/actions/stream/checkpoints/player
 7618  hdfs dfs -mv /user/actions/stream/checkpoints/player/player_hhs.player_offsets.txt /user/actions/stream/checkpoints/player/player_hhs.player_offsets.txt_old
 7619  history | grep export
 7620  export HADOOP_USER_NAME=hadoop
 7621  hdfs dfs -mv /user/actions/stream/checkpoints/player/player_hhs.player_offsets.txt /user/actions/stream/checkpoints/player/player_hhs.player_offsets.txt_old
 7622  export HADOOP_USER_NAME=actions
 7623  hdfs dfs -mv /user/actions/stream/checkpoints/player/player_hhs.player_offsets.txt /user/actions/stream/checkpoints/player/player_hhs.player_offsets.txt_old
 7624  git status
 7625  git diff
 7626  git status
 7627  git diff README.md
 7628  git add README.md
 7629  git commit -m "docs: added config docs"
 7630  git status
 7631  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala
 7632  git diff src/test/scala/com/globo/bigdata/pipeline/mapping/config/SettingsTest.scala
 7633  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisUserStorage.scala
 7634  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala
 7635  git add src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala
 7636  git add src/test/scala/com/globo/bigdata/pipeline/mapping/config/SettingsTest.scala
 7637  git status
 7638  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/source/OffsetsCheckpoint.scala
 7639  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/storage/UserStorage.scala
 7640  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/sync/writer/UserForeachWriter.scala
 7641  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/source/KafkaSource.scala
 7642  git commit -m "test: create tests for settings class"
 7643  git push origin feat/create-horizon-user-mapping 
 7644  git status
 7645  git diff
 7646  git src/main/scala/com/globo/bigdata/pipeline/mapping/source/OffsetsCheckpoint.scala
 7647  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/source/OffsetsCheckpoint.scala
 7648  git add src/main/scala/com/globo/bigdata/pipeline/mapping/source/OffsetsCheckpoint.scala
 7649  git commit -m "fix: order of params"
 7650  git status
 7651  git diff
 7652  git add src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisClusterUserStorage.scala src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisUserStorage.scala src/main/scala/com/globo/bigdata/pipeline/mapping/storage/UserStorage.scala
 7653  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/sync/writer/UserForeachWriter.scala
 7654  git add src/main/scala/com/globo/bigdata/pipeline/mapping/sync/writer/UserForeachWriter.scala
 7655  git diff
 7656  git status
 7657  git commit -m "feat: persist operationTs in score field at redis"
 7658  git status
 7659  git push origin feat/create-horizon-user-mapping 
 7660  sbt clean test
 7661  ./start-master.sh
 7662  tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 7663  ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 7664  tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 7665  ./tinyImagenetTrain.sh
 7666  ls -l  /Users/leonardo.neuwald/Downloads/tiny-imagenet-200
 7667  ./tinyImagenetTrain.sh
 7668  ls -l  /Users/leonardo.neuwald/Downloads/tiny-imagenet-200/train/
 7669  ./tinyImagenetTrain.sh
 7670  sbt clean assembly
 7671  ./tinyImagenetTrain.sh
 7672  ps aux | grep spark
 7673  kill -9 83200
 7674  ps aux | grep spark
 7675  kill -9 83319
 7676  ps aux | grep spark
 7677  ls -l
 7678  cd ..
 7679  ls -l
 7680  cd go
 7681  ls -l
 7682  cd sc
 7683  cd src/gitlab.globoi.com/bigdata/pipeline/horizon-schemas-service/
 7684  git status
 7685  git pull
 7686  git status
 7687  rm -rf go.mod go.sum
 7688  git status
 7689  git pull
 7690  make submodule-update
 7691  make tsuru-deploy-dev
 7692  make tsuru-deploy-qa
 7693  tsuru app-info -a horizon-schemas-service-qa
 7694  tsuru app-info -a horizon-schemas-qa
 7695  git status
 7696  make submodule-update
 7697  git diff
 7698  code .
 7699  git status
 7700  git checkout -b feat/player-network-monitoring-schema
 7701  git status
 7702  git add .
 7703  git commit -m "feat: add new version of player-network-monitoring schema"
 7704  git push origin feat/player-network-monitoring-schema 
 7705  make tsuru-deploy-dev
 7706  tsuru app-info -a horizon-schemas-prod
 7707  tsuru app-info -a horizon-schemas-dev
 7708  make tsuru-deploy-qa
 7709  sbt clean dependencyGraph > libs.txt
 7710  sbt clean dependencyThree > libs.txt
 7711  sbt clean dependencyTree > libs.txt
 7712  ls -l
 7713  cd .
 7714  cd ..
 7715  pwd
 7716  cd ..
 7717  cd Projetos
 7718  ls -l
 7719  cd pipeline-jobs-commons
 7720  git status
 7721  git diff
 7722  git pull
 7723  cd ..
 7724  ls -lcd ..
 7725  cd ..
 7726  ls -l
 7727  cd ..
 7728  cd spark-2.3.1-bin-hadoop2.7
 7729  ls -l
 7730  cd bin
 7731  ls -l
 7732  ./spark-shell
 7733  hdfs dfs -ls /
 7734  export HADOOP_CONF_DIR=~/configs/conf-qa
 7735  hdfs dfs -ls /
 7736  ls -l
 7737  git status
 7738  ls -l
 7739  git status
 7740  git add .
 7741  git commit -m "feat: add hydrogen functions"
 7742  git push origin master
 7743  sbt clean release
 7744  cd ..
 7745  ls -l
 7746  htop
 7747  cd horizon-storage
 7748  git pull
 7749  git idf
 7750  git diff
 7751  htop
 7752  exit
 7753  ls -l
 7754  clear
 7755  cd spark-2.3.1-bin-hadoop2.7
 7756  ls -l
 7757  ./sbin/spark-shell
 7758  ./bin/spark-shell
 7759* ls -l ~/Downloads
 7760* ls -l
 7761* cd Downloads
 7762* ls -l
 7763* pwd
 7764* ls -l
 7765* clear
 7766* ls -l
 7767* clear
 7768* ls -l
 7769* cd spark-2.3.1-bin-hadoop2.7
 7770* ls -l
 7771* pwd
 7772* cd /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7
 7773* ls -l
 7774  cd ..
 7775  ls -l
 7776  cd Projetos/personal/deeplearning-dl4j
 7777  sbt clean assembly
 7778* cd sbin
 7779* ./start-master.sh
 7780* tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 7781* history
 7782* history | grep spark
 7783* history | grep start
 7784* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 7785* tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 7786* brew install bash-completion
 7787* brew cask install docker
 7788  ./tinyImagenetTrain.sh
 7789* brew install kubectl
 7790* brew cask install minikube
 7791* docker run -it --rm  -p 8080:8080 skymindops/zeppelin-dl4j:latest
 7792* docker
 7793* docker -version
 7794* docker version
 7795* Docker 
 7796* Docker.app
 7797* docker version
 7798* docker run -it --rm  -p 8080:8080 skymindops/zeppelin-dl4j:latest
 7799* docker run -it --rm  -p 8085:8085 skymindops/zeppelin-dl4j:latest
 7800* ps aux | grep zepplin
 7801* ps aux | grep docker
 7802* ps aux | grep 8085
 7803* docker run -it --rm  -p 8080:8085 skymindops/zeppelin-dl4j:latest
 7804* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 7805* tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 7806* tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 7807* tail -1000f /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 7808* \n
 7809* ps aux | grep spark
 7810* kill -9 26607
 7811* ps aux | grep spark
 7812* kill -9 8607
 7813* ps aux | grep spark
 7814* ls -l
 7815* cd Projetos
 7816* ls -l
 7817* cd horizon-storage
 7818* ls -l
 7819* git status
 7820* sbt clean deploy
 7821* sbt clean publish
 7822* sbt clean test
 7823* ps aux | grep spark
 7824* ps aux | grep hive
 7825* sbt clean test
 7826* ls -l
 7827* git status
 7828* rm -rf target
 7829* rm -rf project/target
 7830* ls -l
 7831* tail -f derby.log
 7832* ls -l
 7833* rm -rf derby.log
 7834* ps aux | grep derby
 7835* sbt clean test
 7836* sbt clean test > saida.txt
 7837* sbt clean test
 7838* sbt clean publish
 7839* sbt clean test
 7840* git status
 7841* git checkout -b feat/create-warehouse-writter
 7842* git status
 7843* git diff
 7844* git diff build.sbt
 7845* git status
 7846* git reset HEAD src/main/scala/com/globo/bigdata/pipeline/horizonstorage/conversor/Conversions.scala
 7847* git status
 7848* git commit -m "test: create package for stubs"
 7849* git status
 7850* git diff src/main/scala/com/globo/bigdata/pipeline/horizonstorage/Horizon.scala
 7851* git diff src/main/scala/com/globo/bigdata/pipeline/horizonstorage/config/HorizonConfiguration.scala
 7852* git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/config/HorizonConfiguration.scala
 7853* git commit -m "feat: create configurations for warehouse write operation"
 7854* git status
 7855* git diff src/test/scala/com/globo/bigdata/pipeline/horizonstorage/stubs/Classes.scala
 7856* git diff src/test/scala/com/globo/bigdata/pipeline/horizonstorage/stubs/HdfsCluster.scala
 7857* git diff src/main/scala/com/globo/bigdata/pipeline/horizonstorage/hadoop/Hdfs.scala
 7858* git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/conversor/
 7859* git status
 7860* git diff src/main/scala/com/globo/bigdata/pipeline/horizonstorage/Horizon.scala
 7861* git diff src/main/scala/com/globo/bigdata/pipeline/horizonstorage/hadoop/Hdfs.scala
 7862* git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/hadoop/Hdfs.scala
 7863* git status
 7864* git diff src/test/scala/com/globo/bigdata/pipeline/horizonstorage/stubs/Classes.scala
 7865* git status
 7866* git diff src/test/scala/com/globo/bigdata/pipeline/horizonstorage/hadoop/HdfsTest.scala
 7867* git add src/test/scala/com/globo/bigdata/pipeline/horizonstorage/hadoop/HdfsTest.scala
 7868* git status
 7869* git add src/test/scala/com/globo/bigdata/pipeline/horizonstorage/stubs/Classes.scala
 7870* git add src/test/scala/com/globo/bigdata/pipeline/horizonstorage/stubs/HdfsCluster.scala
 7871* git status
 7872* git diff src/main/scala/com/globo/bigdata/pipeline/horizonstorage/functions/
 7873* git diff
 7874* git status
 7875* git commit -m "feat: add hdfs list and move operations"
 7876* git status
 7877* git add src/test/scala/com/globo/bigdata/pipeline/horizonstorage/functions/ src/test/scala/com/globo/bigdata/pipeline/horizonstorage/exception/
 7878* git status
 7879* git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/functions/
 7880* git status
 7881* git add src/test/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonWriterTest.scala
 7882* git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/exception/ColumnNotFoundException.scala
 7883* git status
 7884* git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonWriter.scala
 7885* git status
 7886* git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/filter/PathHelper.scala
 7887* git add src/test/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonReaderTest.scala
 7888* git add src/test/scala/com/globo/bigdata/pipeline/horizonstorage/filter/LegacyFilterTest.scala
 7889* git status
 7890* git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/Horizon.scala
 7891* git commit -m "feat: create warehouse write operation"
 7892* git status
 7893* rm -rf saida.txt
 7894* git status
 7895* git diff CHANGELOG.md
 7896* git add build.sbt
 7897* git commit -m "test: turn off parallel execution of tests"
 7898* git status
 7899* git add CHANGELOG.md
 7900* git status
 7901* git add "docs: update changelog"
 7902* git commit -m "docs: update changelog"
 7903* git push origin feat/create-warehouse-writter 
 7904* git status
 7905* git checkout src/test/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonWriterTest.scala
 7906* git checkout README.md
 7907* git pull origin feat/create-warehouse-writter 
 7908* git status
 7909* sbt clean publish
 7910* git status
 7911* history | grep dockerp
 7912* history | grep docker
 7913* v
 7914* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 7915* ./start-master.sh
 7916* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 7917* tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 7918* tail -f /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 7919* ps aux | grep spark
 7920* kill -9 43638
 7921* ps aux | grep spark
 7922* kill -9 43725
 7923* ls -l
 7924* cd ..
 7925* ls -l
 7926* cd ..
 7927* ls -l
 7928* cd spark-2.1.1-bin-hadoop2.7
 7929* cd sbin
 7930* cd ..
 7931* ls -l
 7932* cd ..
 7933* ls -l
 7934* cd spark-2.1.1-bin-hadoop2.7
 7935* cd sbin
 7936* ./start-master.sh
 7937* tail -F /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 7938* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 7939* tail -F /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 7940* ./stop-master.sh
 7941* ./stop-slaves.sh
 7942* ./stop-slave.sh
 7943* ./start-master.sh
 7944* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 7945* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 7946* ps aux | grep spark
 7947* kill -9 46114
 7948* ps aux | grep spark
 7949  cd ..
 7950  ls -l
 7951  cd horizon-storage
 7952  git status
 7953  git checkout README.md
 7954  git pull
 7955  git pull origin feat/create-warehouse-writter 
 7956  git status
 7957  git diff
 7958  git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonWriter.scala
 7959  sbt clean test"
 7960  sbt clean test
 7961  git status
 7962  git add .
 7963  git commit -m "refactor: make code more readable"
 7964  git push origin feat/create-warehouse-writter 
 7965  sbt clean publish
 7966  git status
 7967  git add project/Dependencies.scala
 7968  git commit -m "chore: update measures version"
 7969  git diff
 7970  git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonWriter.scala
 7971  git commit -m "docs: add name param on javadocs"
 7972  git push origin feat/create-warehouse-writter 
 7973  sbt clean publish
 7974  cd ..
 7975  ls -l
 7976  cd horizon_user_resolver
 7977  cd ..
 7978  cd horizon-user-mapping
 7979  git status
 7980  git diff
 7981  git diff .gitlab-ci.yml
 7982  git build.sbt
 7983  git diff build.sbt
 7984  git checkout build.sbt
 7985  git diff project/Resolvers.scala
 7986  git reset HEAD src/test/scala/com/globo/bigdata/pipeline/mapping/source/KafkaSourceTest.scala
 7987  git status
 7988  git add project/Resolvers.scala
 7989  git commit -m "chore: add snapshot resolver"
 7990  git status
 7991  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/HorizonUserMapping.scala
 7992  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala
 7993  git add src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala
 7994  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/source/KafkaSource.scala
 7995  git add src/main/scala/com/globo/bigdata/pipeline/mapping/source/KafkaSource.scala
 7996  git status
 7997  git add src/main/scala/com/globo/bigdata/pipeline/mapping/source/OffsetsCheckpoint.scala
 7998  git status
 7999  git add src/test/scala/com/globo/bigdata/pipeline/mapping/source/
 8000  git status
 8001  git diff
 8002  git commit -m "test: create tests for KafkaSource and OffSetsCheckpoint"
 8003  git status
 8004  git diff user_mapping_prod.sh
 8005  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/HorizonUserMapping.scala
 8006  git push origin feat/create-horizon-user-mapping 
 8007  git status
 8008* cd ..
 8009* ls -l
 8010* cd Projetos
 8011* ls -l
 8012* cd horizon-storage
 8013* git status
 8014* git diff
 8015* sbt clean test
 8016* sbt clean deploy
 8017* sbt clean publish
 8018* git status
 8019* git add .
 8020* git commit -m "feat: change horizon writter to return List[Path]"
 8021* git push origin feat/create-warehouse-writter 
 8022* cd ..
 8023* ls -l
 8024* git clone https://gitlab.globoi.com/bigdata/pipeline/warehouse-pagetrack
 8025  history | grep export
 8026  export HADOOP_CONF_DIR=~/configs/conf-prod
 8027  export HADOOP_USER_NAME=hadoop
 8028  hdfs dfs -ls /
 8029  hdfs dfs -ls /tmp/warehouse
 8030  hdfs dfs -ls /tmp
 8031  hdfs dfs -chmod 777 /tmp/warehouse
 8032  hdfs dfs -ls /tmp
 8033  hdfs dfs -ls /
 8034  hdfs dfs -ls /warehouse
 8035  hdfs dfs -ls /warehouse/pagetrack
 8036  hdfs dfs -ls /warehouse/pagetrack/parquet
 8037  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=g1
 8038  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=g1/year=2019
 8039  hdfs dfs -ls /warehouse/pagetrack/parquet/glb_product=g1/year=2019/month=7
 8040* export HADOOP_CONF_DIR=~/configs/conf-qa
 8041* hdfs dfs -ls /warehouse/pagetrack
 8042* hdfs dfs -ls /warehouse
 8043* hdfs dfs -ls /parquet
 8044* hdfs dfs -mkdir /parquet/track/2019071700/201907170060
 8045* hdfs dfs -mkdir -p /parquet/track/2019071700/201907170060
 8046* hdfs dfs -ls /parquet/track/2019071700/201907170060
 8047* hdfs dfs -put ~/Downloads/part-00000-07867ea2-bb62-41b7-a46a-74876379b3a3.snappy.parquet /parquet/track/2019071700/201907170060
 8048* hdfs dfs -put ~/Downloads/part-00000-240e4566-0e1f-432d-934e-c9f9286e2179.snappy.parquet /parquet/track/2019071700/201907170060
 8049* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 8050* history | grep echo
 8051* echo $HADOOP_CONF_DIR
 8052* echo $SPARK_HOME
 8053* ./start-master.sh
 8054* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 8055* tail -F /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 8056* tail -F /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 8057* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 8058* kill -9 70314
 8059* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 8060* tail -F /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 8061* telnet deeplearning4j-resources.westus2.cloudapp.azure.com 80
 8062* vi /etc/hosts
 8063* sudo vi /etc/hosts
 8064  telnet deeplearning4j-resources.westus2.cloudapp.azure.com 80
 8065* ps aux | grep spark
 8066* kill -9 70235
 8067* ps aux | grep spark
 8068* kill -9 71007
 8069* ls -l
 8070* history | grep hdfs
 8071* hdfs dfs -ls /parquet/track/2019071700/201907170060
 8072* hdfs dfs -mkdir -p /parquet/horizon-pageview/2019071700/201907170060
 8073* export HADOOP_USER_NAME=horizon
 8074* hdfs dfs -mkdir -p /parquet/horizon-pageview/2019071700/201907170060
 8075* hdfs dfs -put ~/Downloads/part-00000-0275cb5b-1520-4970-b6df-bcfb6be1eccc.snappy.parquet /parquet/horizon-pageview/2019071700/201907170060
 8076* hdfs dfs -put ~/Downloads/part-00000-0c368a63-af95-43a4-b3b4-2a13f2dba664.snappy.parquet /parquet/horizon-pageview/2019071700/201907170060
 8077* ls -l
 8078* sbt clean assembly 
 8079* ./tasks/spark-submit/spark-submit.sh
 8080* yarn application -list | grep application_1562607983561_0050
 8081* yarn application -kill application_1562607983561_0050
 8082* ./tasks/spark-submit/spark-submit.sh
 8083* export HADOOP_USER_NAME=horizon
 8084* export HADOOP_USER_NAME=hdfs
 8085* hdfs dfs -ls /tmp/warehouse
 8086* hdfs dfs -chmod 777 /tmp/warehouse
 8087* hdfs dfs -ls /tmp/warehouse
 8088* hdfs dfs -ls /tmp
 8089* ./tasks/spark-submit/spark-submit.sh
 8090* hdfs dfs -ls /warehouse
 8091* hdfs dfs -mkdir /warehouse/pagetrack
 8092* hdfs dfs -ls -l /warehouse/pagetrack
 8093* hdfs dfs -ls /warehouse/pagetrack
 8094* hdfs dfs -ls /warehouse
 8095* hdfs dfs -chown horizon:hdfs /warehouse
 8096* hdfs dfs -ls /warehouse
 8097* hdfs dfs -chown horizon:hdfs /warehouse/pagetrack
 8098* hdfs dfs -ls /warehouse
 8099* ./tasks/spark-submit/spark-submit.sh
 8100* sbt clean assembly 
 8101  git status
 8102  cd ..
 8103  ls -l
 8104  cd horizon-storage
 8105  sbt clean compile deploy
 8106  sbt clean compile publish
 8107* sbt clean assembly 
 8108* sbt clean compile publish
 8109* sbt clean assembly
 8110* ./tasks/spark-submit/spark-submit.sh
 8111* sbt clean assembly
 8112* ls -l
 8113* ./tasks/spark-submit/spark-submit.sh
 8114* yarn application -kill application_1562607983561_0058
 8115* ./tasks/spark-submit/spark-submit.sh
 8116* yarn application -kill application_1562607983561_0059
 8117* ./tasks/spark-submit/spark-submit-local.sh
 8118* yarn application -kill application_1562607983561_0060
 8119* unset HADOOP_CONF_DIR
 8120  ls -l
 8121  ls -l /tmp
 8122  mkdir /tmp/spark
 8123  ls -l /tmp/spark
 8124* history | grep hdfs
 8125  mkdir /tmp/spark/parquet/track/2019071700/201907170060
 8126  mkdir -p /tmp/spark/parquet/track/2019071700/201907170060
 8127  mkdir -p /tmp/spark/parquet/horizon-pageview/2019071700/201907170060
 8128  mv ~/Downloads/part-00000-0275cb5b-1520-4970-b6df-bcfb6be1eccc.snappy.parquet /tmp/spark/parquet/horizon-pageview/2019071700/201907170060
 8129  mv ~/Downloads/part-00000-0c368a63-af95-43a4-b3b4-2a13f2dba664.snappy.parquet /tmp/spark/parquet/horizon-pageview/2019071700/201907170060
 8130  mv ~/Downloads/part-00000-07867ea2-bb62-41b7-a46a-74876379b3a3.snappy.parquet /tmp/spark/parquet/track/2019071700/201907170060
 8131  mv ~/Downloads/part-00000-240e4566-0e1f-432d-934e-c9f9286e2179.snappy.parquet /tmp/spark/parquet/track/2019071700/201907170060
 8132  ls -l
 8133  mkdir /tmp/spark/warehouse
 8134  mkdir /tmp/spark/tmp/warehouse
 8135  mkdir -p /tmp/spark/tmp/warehouse
 8136  ls -l /tmp/spark/tmp/warehouse
 8137  ls -l /tmp/spark/tmp
 8138  chmod 777 /tmp/spark/tmp/warehouse
 8139  chmod 777 /tmp/spark/warehouse
 8140* ./tasks/spark-submit/spark-submit-local.sh
 8141* jar -xf target/scala-2.11/warehouse-pagetrack.jar
 8142* ls -l
 8143* git status
 8144* rm -rf LICENSE_kafka-clients-0.10.0.1 Log4j-*
 8145* ls -l
 8146* git status
 8147* rm -rf com/
 8148* git status scala
 8149* git checkout scala/
 8150* git checkout scala
 8151* git checkout scala/
 8152* git diff tasks/spark-submit/spark-submit-local.sh
 8153* rm -rf LICENSE_kafka_2.11-0.10.0.1 NOTICE_*
 8154* rm -rf google compiler.properties com
 8155* git status
 8156* rm -rf scala org
 8157* rm -rf META-INF darwin images kafka linux mozilla
 8158* git status
 8159* rm -rf decoder.properties interactive.properties library.properties reflect.properties
 8160* ls -l
 8161* git status
 8162* ls -l
 8163* rm -rf scala
 8164* ls -l
 8165* git status
 8166* rm -rf win32 scalap.properties scaladoc.properties scala-xml.properties scala-parser-combinators.properties
 8167* git status
 8168* rm -rf repl-jline.properties  repl.properties rootdoc.txt scala-asm.properties
 8169* git status
 8170* rm -rf scalac-plugin.xml
 8171* git status
 8172* git diff
 8173* vi backstage.qa.properties
 8174* sbt clean assembly
 8175* ./tasks/spark-submit/spark-submit-local.sh
 8176  ls -l /tmp/spark/tmp/warehouse
 8177  sbt clean assembly
 8178  sbt clean publish
 8179* sbt clean assembly
 8180* ./tasks/spark-submit/spark-submit-local.sh
 8181* sbt clean assembly
 8182* ./tasks/spark-submit/spark-submit-local.sh
 8183* sbt clean assembly
 8184* ./tasks/spark-submit/spark-submit-local.sh
 8185  ls -l
 8186  git status
 8187  git diff
 8188  sbt clean test
 8189* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=techtudo/year=2019/month=7
 8190* ls -l
 8191* cd ..
 8192* cd bin
 8193* ./spark-shell
 8194  pwd
 8195  ls -l target/scala-2.11/
 8196  wget https://artifactory.globoi.com/artifactory/libs-snapshot-local/com/globo/bigdata/pipeline/horizon-storage_2.11/0.2.3-SNAPSHOT/horizon-storage_2.11-0.2.3-SNAPSHOT.jar
 8197  curl -vvv https://artifactory.globoi.com/artifactory/libs-snapshot-local/com/globo/bigdata/pipeline/horizon-storage_2.11/0.2.3-SNAPSHOT/horizon-storage_2.11-0.2.3-SNAPSHOT.jar
 8198  ls -l
 8199  brew install wget
 8200  wget https://artifactory.globoi.com/artifactory/libs-snapshot-local/com/globo/bigdata/pipeline/horizon-storage_2.11/0.2.3-SNAPSHOT/horizon-storage_2.11-0.2.3-SNAPSHOT.jar
 8201  pwd
 8202* ./spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-storage
 8203* ./spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-storage/horizon-storage_2.11-0.2.3-SNAPSHOT.jar
 8204  ls -l /Users/leonardo.neuwald/Projetos/horizon-storage
 8205  ls -l /tmp/spark/tmp/warehouse/14d9a0cd-3046-45d2-b38c-4c2e86037285/
 8206  ls -l /tmp/spark/warehouse/pagetrack/parquet
 8207* ls -l
 8208* ls -l /tmp/spark/warehouse/pagetrack/parquet
 8209* rm -rf /tmp/spark/warehouse/pagetrack/parquet
 8210* ls -l /tmp/spark/warehouse/pagetrack/parquet
 8211* ls -l /tmp/spark/warehouse/pagetrack
 8212* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=ana_maria_braga/year=2019/month=7
 8213* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=ana_maria_braga/year=2019
 8214* ls -l /tmp/spark/tmp/warehouse/217017f6-2f19-42bf-afb3-f10cd5c4e543/glb_product=ana_maria_braga/year=2019/month=7/day=17
 8215* mkdir /tmp/spark/warehouse/pagetrack/parquet/glb_product=ana_maria_braga/year=2019/month=7/day=1
 8216* touch /tmp/spark/warehouse/pagetrack/parquet/glb_product=ana_maria_braga/year=2019/month=7/day=1/file1.txt
 8217* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=ana_maria_braga
 8218* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=ana_maria_braga/year=2019
 8219* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=ana_maria_braga/year=2019/day=1
 8220* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=cbn/year=2019/month=7
 8221* /tmp/spark/tmp/warehouse/14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7
 8222* ls -l/tmp/spark/tmp/warehouse/14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7
 8223* ls -l /tmp/spark/tmp/warehouse/14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7
 8224* cd ..
 8225* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=ana_maria_braga/year=2019
 8226* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=ana_maria_braga/year=2019/month=7
 8227* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=educacao
 8228* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=educacao/year=2019
 8229* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=educacao/year=2019/month=7
 8230* ls -l
 8231* cd ..
 8232* ls -l
 8233* cd ..
 8234* ls -l
 8235* ls -l 14d9a0cd-3046-45d2-b38c-4c2e86037285
 8236* mkdir 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7/day=1
 8237* mkdir 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7/day=1/file.2
 8238* touch 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7/day=1/file.2
 8239* ls -l
 8240* ls -l 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7/day=1/file.2
 8241* rm -rf 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7/day=1/file.2
 8242* touch 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7/day=1/file.2
 8243* ls -l 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7/day=1
 8244* pwd
 8245* ls -l 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7
 8246* ls -l 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019
 8247* ls -l 14d9a0cd-3046-45d2-b38c-4c2e86037285/glb_product=cbn/year=2019/month=7
 8248* ls -l
 8249* ls -l 217017f6-2f19-42bf-afb3-f10cd5c4e543
 8250* ls -l
 8251* cd .
 8252* cd ..
 8253* ls -l
 8254* cd ..
 8255* ls -l
 8256* pwd
 8257* rm -rf warehouse
 8258* cd ..
 8259* ls -l
 8260* chmod 777 spark
 8261* cd spark
 8262* ls -l
 8263  git status
 8264  rm -rf horizon-storage_2.11-0.2.3-SNAPSHOT.jar
 8265  ls -l
 8266  git status
 8267  sbt clean test
 8268  ls -l
 8269  git status
 8270  git diff
 8271  sbt clean package
 8272* ./spark-shell --jars /Users/leonardo.neuwald/Projetos/horizon-storage/target/scala-2.11/horizon-storage_2.11-0.2.3-SNAPSHOT.jar
 8273* ls -l
 8274* mkdir warehouse
 8275* ls -l
 8276* mkdir tmp/warehouse/889f9ec1-f1f6-4757-b064-c88c5c7c0d76/glb_product=cartola/year=2019/month=7/day=1
 8277* touch tmp/warehouse/889f9ec1-f1f6-4757-b064-c88c5c7c0d76/glb_product=cartola/year=2019/month=7/day=1/file1.txt
 8278* touch tmp/warehouse/889f9ec1-f1f6-4757-b064-c88c5c7c0d76/glb_product=cartola/year=2019/month=7/day=1/file2.txt
 8279* pwd
 8280* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=cartola/year=2019/month=7/day=1
 8281  git status
 8282  sbt clean test
 8283* pwd
 8284* ls -l
 8285* ls -l warehouse/pagetrack/parquet/glb_product=cartola/year=2019
 8286* ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=cartola/year=2019/month=7
 8287  sbt clean test
 8288  git diff
 8289  git status
 8290  git diff
 8291  git checkout src/main/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonWriter.scala
 8292  git status
 8293  git diff src/main/scala/com/globo/bigdata/pipeline/horizonstorage/hadoop/Hdfs.scala
 8294  git status
 8295  git diff
 8296  sbt clean publish
 8297* git status
 8298* git diff
 8299  ls -l
 8300  ls -l /tmp/spark
 8301  cd /tmp/spark
 8302  ls -l tmp
 8303  cd warehouse
 8304  ls -l
 8305  ls -l pagetrack
 8306  ls -l 
 8307  ls -l pagetrack/
 8308  pwd
 8309  ls -l
 8310  rm -rf pagetrack
 8311  ls -l
 8312  cd ..
 8313  ls -l 
 8314  ls -l tmp
 8315  cd tmp
 8316  ls -l
 8317  cd warehouse
 8318  ls -l
 8319  rm -rf 14d9a0cd-3046-45d2-b38c-4c2e86037285 217017f6-2f19-42bf-afb3-f10cd5c4e543 824a602e-69e0-4915-86fc-a194822df6cd 889f9ec1-f1f6-4757-b064-c88c5c7c0d76
 8320  ls -l
 8321  cd ..
 8322  ls -l
 8323* cd ..
 8324  ls -l
 8325  cd ..
 8326  ls -l
 8327  cd ~/Projetos/horizon-storage
 8328  git status
 8329  sbt clean publish
 8330* sbt clean assembly
 8331* ./tasks/spark-submit/spark-submit.sh
 8332* yarn application -list | grep application_1562607983561_0061
 8333* history | grep export
 8334* export HADOOP_CONF_DIR=~/configs/conf-qa
 8335* yarn application -list | grep application_1562607983561_0061
 8336* yarn application -kill application_1562607983561_0061
 8337* unset HADOOP_CONF_DIR
 8338* ./tasks/spark-submit/spark-submit-local.sh
 8339  ls -l /tmp/spark/warehouse/pagetrack/parquet/glb_product=vogue/year=2019/month=7/day=17
 8340  git status
 8341  git diff
 8342  git checkout version.sbt
 8343  git diff
 8344  git add src/main/scala/com/globo/bigdata/pipeline/horizonstorage/hadoop/Hdfs.scala src/test/scala/com/globo/bigdata/pipeline/horizonstorage/hadoop/HdfsTest.scala
 8345  git commit -m "fix: delete directory only if exists"
 8346  git status
 8347  git push origin feat/create-warehouse-writter 
 8348* ls -l
 8349* cd ..
 8350* ls -l
 8351* cd ~/
 8352* ls -l
 8353* cd Projetos
 8354* ls -l
 8355* git clone gitlab@gitlab.globoi.com:bigdata/pipeline/pipeline-document-ingest-service.git
 8356* cd pipeline-document-ingest-service
 8357* code .
 8358* git status
 8359* cd ..
 8360* ls -l
 8361* cd ..
 8362* ls -l
 8363* cd ..
 8364* ls -l
 8365* cd ..
 8366* ls -l
 8367* pwd
 8368* cd ..
 8369* cd ~
 8370* ls -l
 8371* pwd
 8372* cd go/src/gitlab.globoi.com/bigdata/pipeline/horizon-schemas-service
 8373* git status
 8374* git pull
 8375* cd ..
 8376* cd horizon-schemas-service
 8377* git checkout master
 8378* git status
 8379* git pull
 8380* git status
 8381* git checkout -b "feat/ab-and-mab-schemas"
 8382* code .
 8383* git status
 8384* make submodule-update
 8385* git status
 8386* git add .
 8387* git commit -m "feat: add new AB schemas: ab-conversion-2.0 and ab-impression-2.0"
 8388* git status
 8389* git push origin feat/ab-and-mab-schemas 
 8390* git status
 8391* git pull
 8392* git pull origin feat/ab-and-mab-schemas 
 8393* make tsuru-deploy-dev
 8394* make tsuru-deploy-qa
 8395* tsuru app-info -a horizon-schemas-service-qa
 8396* tsuru app-info -a horizon-schemas-qa
 8397  cd ..
 8398  ls -l
 8399  cd horizon-user-mapping
 8400  git status
 8401  sbt clean compile
 8402  ls -l /tmp
 8403  ls -l /tmp/
 8404  cd ..
 8405  ls -l
 8406  git status
 8407  cd horizon-storage
 8408  git status
 8409  git diff
 8410  git add src/test/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonReaderTest.scala
 8411  git commit -m "style: change to camelCase"
 8412  git status
 8413  git add src/test/scala/com/globo/bigdata/pipeline/horizonstorage/HorizonWriterTest.scala
 8414  git status
 8415  git commit -m "chore: fix words"
 8416  git push origin feat/create-warehouse-writter 
 8417  git pull
 8418  git pull origin feat/create-warehouse-writter 
 8419  git status
 8420  git push origin feat/create-warehouse-writter 
 8421  cd ..
 8422  cd horizon-storage
 8423  git checkout master 
 8424  git status
 8425  git pull
 8426  make release
 8427  git status
 8428  rm -rf src/test/scala/com/globo/bigdata/pipeline/horizonstorage/hadoop/HdfsTestTest.scala
 8429  git pull
 8430  make release
 8431  cd ..
 8432  ls -l
 8433  cd warehouse-pagetrack
 8434  git status
 8435  git pull
 8436  git diff src/main/scala/com/globo/pipeline/warehouse/pagetrack/Warehouse_PageTrack.scala
 8437  git diff
 8438  git diff tasks/spark-submit/spark-submit.sh
 8439  git checkout tasks/spark-submit/spark-submit.sh
 8440  git satus
 8441  git status
 8442  git add project/Dependencies.scala src/main/scala/com/globo/pipeline/warehouse/pagetrack/Warehouse_PageTrack.scala tasks/spark-submit/spark-submit.sh
 8443  git status
 8444  git commit -m "update horizon-storage to 0.3.0"
 8445  git push origin master
 8446  cd ..
 8447  ls -l
 8448  cd horizon-user-mapping
 8449  git status
 8450  sbt clean compile
 8451  rm -rf libs.txt
 8452  vi test.txt
 8453  ls -l
 8454  git status
 8455* ps aux | grep redis
 8456* kill -9 17303
 8457  make test
 8458* ps aux | grep redis
 8459  make test
 8460* ps aux | grep redis
 8461  make test
 8462* ls -l
 8463* cd .
 8464* .ls -l
 8465* cd ..
 8466* ls -l
 8467* cd personal/deeplearning-dl4j/
 8468* ls -l
 8469* ls -l target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar
 8470* ls -l -h target/scala-2.11/deeplearning-dl4j-assembly-0.1.jar
 8471  ls -l
 8472  cd ..
 8473  ls l-
 8474  ls -l
 8475* cd horizon-schemas-service
 8476* ls -l
 8477* git status
 8478* git checkout master
 8479* git pull
 8480* make tsuru-deploy-prod
 8481* ls -l
 8482* vi hzs/version.go
 8483* git tag v0.21.0
 8484* history | grep tag
 8485* git push --tags 
 8486* make tsuru-deploy-prod
 8487* tsuru app-info -a horizon-schemas
 8488* tail -f /var/log/system.log
 8489* ps aux | grep redis
 8490* kill -9 20760 20759 20763
 8491* ps aux | grep redis
 8492* kill -9 20762
 8493* ps aux | grep redis
 8494* kill -9  23319 23320 23321 23322
 8495* ps aux | grep redis
 8496* kill -9 23317 23318 23324 23323 23505
 8497* ps aux | grep redis
 8498* kill -9 23317 23318 23324 23323 23505
 8499* ps aux | grep redis
 8500* history | grep export
 8501* export HADOOP_CONF_DIR=~/configs/conf-qa
 8502* hdfs dfs -du -h /
 8503* hdfs dfs -du -h /warehouse
 8504* hdfs dfs -du -h /warehouse/object-md
 8505* hdfs dfs -du -h /warehouse/object-md/20190626
 8506* history | grep hadoop
 8507* export HADOOP_USER_NAME=hdfs
 8508* hdfs dfs -du -h /
 8509* hdfs dfs -du -h /user
 8510* hdfs dfs -du -h /user/actions
 8511* hdfs dfs -du -h /user/warehouse
 8512* hdfs dfs -du -h /
 8513* hdfs dfs -du -h /warehouse
 8514* hdfs dfs -du -h /
 8515* hdfs dfs -du -h /warehouse
 8516* hdfs dfs -du -h /spark
 8517* hdfs dfs -du -h /user
 8518* hdfs dfs -du -h /user/hadoop
 8519* hdfs dfs -du -h /user/actions
 8520* hdfs dfs -du -h /user/actions/stream
 8521* hdfs dfs -ls /warehouse
 8522* hdfs dfs -ls /warehouse/object-md
 8523* hdfs dfs -ls /warehouse/object-md/20190626
 8524* hdfs dfs -du -h /
 8525* ps aux | grep redis
 8526* kill -9 23648 23649 23645 23646 23647 23651
 8527* ps aux | grep redis
 8528* kill -9 23652  23650
 8529* ps aux | grep redis
 8530* kill -9 25629 25635 25631 25630 25660
 8531* ps aux | grep redis
 8532* kill -9 25632  25634 25633 25636
 8533* ps aux | grep redis
 8534* kill -9 25940 25941  25946  25944 25942 25943 25947 25945
 8535* ps aux | grep redis
 8536* hdfs dfs -ls /
 8537* hdfs dfs -ls /user/actions
 8538* hdfs dfs -ls /user/actions/stream
 8539* hdfs dfs -ls /user/actions/stream/checkpoints
 8540* hdfs dfs -ls /user/actions/stream/checkpoints/player
 8541* hdfs dfs -rm -rf /user/actions/stream/checkpoints/player/player_hhs-qa.player_offsets.txt
 8542* hdfs dfs -rm -r /user/actions/stream/checkpoints/player/player_hhs-qa.player_offsets.txt
 8543* ps aux | grep redis
 8544* kill -9 26116 26117 26118 26119 26115 26114
 8545* ps aux | grep redis
 8546  cd horizon_user_resolver
 8547  git status
 8548  cd ..
 8549  cd horizon-user-mapping
 8550  git status
 8551  git diff project/Dependencies.scala
 8552  git diff src/main/scala/com/globo/bigdata/pipeline/mapping/HorizonUserMapping.scala
 8553  git add src/test/scala/com/globo/bigdata/pipeline/mapping/storage/
 8554  git status
 8555  git add src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisUserStorage.scala
 8556  git add src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisClusterUserStorage.scala
 8557  git status
 8558  git add project/Dependencies.scala
 8559  git status
 8560  git commit -m "test: create tests for storage classes"
 8561  git push origin feat/create-horizon-user-mapping 
 8562  git checkout .gitlab-ci.yml
 8563  git status
 8564  vi .gitlab-ci.yml
 8565  git status
 8566  git add .gitlab-ci.yml
 8567* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 8568* pwd
 8569* cd /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/sbin
 8570* unset HADOOP_CONF_DIR
 8571* \n
 8572* ./start-master.sh
 8573* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 8574* tail -f /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 8575* tail -f /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 8576* ps aux | grep spark
 8577* pwd
 8578* unset HADOOP_CONF_DIR
 8579* tail -f /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 8580* tail -f /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 8581* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 8582* export ZEPPELIN_INTP_MEM="-Xmx10g"\n
 8583* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 8584* ps aux | grep spark
 8585* kill -9 30715
 8586* history | grep export
 8587* export HADOOP_CONF_DIR=~/configs/conf-prod
 8588* yarn application -list | grep application_1539207608922_302465
 8589* yarn application -kill application_1539207608922_302465
 8590  cd ..
 8591  ls -l
 8592  cd azkaban
 8593  ls -l
 8594  cd pipeline-horizon-stream-ingest
 8595  git status
 8596  git diff
 8597  git pull
 8598  git checkout jobs/horizon-track-event-stream-flow/hzt.gshow.job
 8599  git status
 8600  git pull
 8601  git statud
 8602  git status
 8603  git checkout -b "fix/change-ab-version"
 8604  git status
 8605  code .
 8606  atom .
 8607  git status
 8608  git diff
 8609  git status
 8610  git diff
 8611  git commit -m "fix: change hdfs path for ab-impression checker"
 8612  git add .
 8613  git commit -m "fix: change hdfs path for ab-impression checker"
 8614  git push origin fix/change-ab-version 
 8615  make zip
 8616  cd ..
 8617  ls -l
 8618  cd ..
 8619  ls -l
 8620  cd horizon_event_stream
 8621  git status
 8622  git pull
 8623* cd ..
 8624* ls -l
 8625* unset HADOOP_CONF_DIR
 8626* history | grep kafka
 8627* ls -l
 8628* cd ..
 8629* ls -l
 8630* cd spark-2.3.1-bin-hadoop2.
 8631* cd spark-2.3.1-bin-hadoop2.7
 8632* ls -l
 8633* ./bin/spark-shell --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0
 8634* history | grep list
 8635* history | grep consumer
 8636* cd ..
 8637* ls -l
 8638* cd ..
 8639* ls -l
 8640* cd kafka_2.11-0.10.1.1
 8641* ls -l
 8642* ./kafka-console-consumer.sh --bootstrap-server kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hhs-qa.g1 --from-beginning
 8643* s -l
 8644* ls -l
 8645* cd bin
 8646* ./kafka-console-consumer.sh --bootstrap-server kafka01.qa.globoi.com:9092,kafka02.qa.globoi.com:9092,kafka03.qa.globoi.com:9092 --topic hhs-qa.g1 --from-beginning
 8647  ls -l
 8648  make test
 8649  make build
 8650* ls -l
 8651* cd ..
 8652* ls -l
 8653* cd ..
 8654* ls -l
 8655* cd go
 8656* ls -l
 8657* cd src/gitlab.globoi.com/bigdata/pipeline/horizon-http-stream
 8658* code .
 8659  sbt 'set test in assembly := {}' clean assembly\n
 8660* make test
 8661  ls -l
 8662  git status
 8663  git diff event_stream_local.sh
 8664  unset HADOOP_CONF_DIR
 8665  ./event_stream_local.sh
 8666  ls -l
 8667  history | grep HADOOP_CONF_DIR
 8668  history | grep SPARK
 8669  ls -l /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7
 8670  export SPARK_HOME="/Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7"
 8671  ./event_stream_local.sh
 8672  ls -l /tmp/spark/logs
 8673  mkdir /tmp/spark/logs
 8674  ./event_stream_local.sh
 8675  vi ./event_stream_local.sh
 8676  ./event_stream_local.sh
 8677* ls -l
 8678* ls -l /tmp
 8679  sbt 'set test in assembly := {}' clean assembly\n
 8680  ./event_stream_local.sh
 8681* ls -l /tmp/stream/tenant=g1/actionContentType=common/actionId=common-screentime/actionVersion=1.0/year=2019/month=8/day=6
 8682* ./event_stream_local.sh
 8683* ls -l /tmp/stream/tenant=g1/actionContentType=common/actionId=common-screentime/actionVersion=1.0/year=2019/month=8/day=6
 8684  git status
 8685  git diff
 8686  git status
 8687  git src/main/scala/com/globo/pipeline/horizoneventstream/HorizonEventStreamMain.scala
 8688  git diff src/main/scala/com/globo/pipeline/horizoneventstream/HorizonEventStreamMain.scala
 8689  git checkout src/main/scala/com/globo/pipeline/horizoneventstream/HorizonEventStreamMain.scala
 8690  git status
 8691  git diff
 8692  git status
 8693  git diff
 8694  git add event_stream_local.sh
 8695  git status
 8696  git checkout -b "feat/add-horizon-environment-column"
 8697  git status
 8698  git commit -m "chore: fix script to run event-stream at local environment"
 8699  git status
 8700  git diff
 8701  make test
 8702  ls -la
 8703  history | grep brew
 8704  git status
 8705  git diff
 8706  git add .
 8707  git commit -m "feat: persist horizonEnvironment at parquet"
 8708  git push origin feat/add-horizon-environment-column 
 8709  make build
 8710  make test
 8711* history | grep export
 8712* export HADOOP_CONF_DIR=~/configs/conf-prod
 8713* hdfs dfs -ls /tmp/warehouse/
 8714* hdfs dfs -chmod 775 /tmp/warehouse/parquet
 8715* export HADOOP_USER_NAME=hadoop
 8716* hdfs dfs -chmod 775 /tmp/warehouse/parquet
 8717* hdfs dfs -ls /tmp/warehouse/
 8718* hdfs dfs -ls /tmp/warehouse/parquet
 8719* unset HADOOP_CONF_DIR
 8720  make test
 8721  git status
 8722  git add .
 8723  git commit -m "fix: add null horizonEnvironment for protocol V1"
 8724  git push origin feat/add-horizon-environment-column 
 8725  make build
 8726  make test
 8727  make build
 8728* export HADOOP_CONF_DIR=~/configs/conf-prod
 8729* yarn application -list | grep application_1539207608922_302464
 8730* yarn application -kill application_1539207608922_302464
 8731* unset HADOOP_CONF_DIR
 8732* ls -l
 8733* cd sbin
 8734* pwd
 8735* /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/sbin
 8736* ls -l
 8737* /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/sbin
 8738* unset HADOOP_CONF_DIR
 8739* /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/sbin
 8740* ./start-master.sh
 8741* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 8742* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 8743* tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 8744* tail -F /Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 8745* ps aux | grep spark
 8746* kill -9 55216
 8747* kill -9 55139
 8748* ps aux | grep spark
 8749* pwd
 8750* cd ..
 8751* cd spark-2.1.1-bin-hadoop2.7
 8752* cd sbin
 8753* cd spark-2.1.1-bin-hadoop2.7/sbin
 8754* unset HADOOP_CONF_DIR
 8755* ./start-master.sh
 8756* ./start-slave.sh spark://Administrators-MacBook-Pro-3.local:7077
 8757* tail -F /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.master.Master-1-Administrators-MacBook-Pro-3.local.out
 8758* tail -F /Users/leonardo.neuwald/spark-2.1.1-bin-hadoop2.7/logs/spark-leonardo.neuwald-org.apache.spark.deploy.worker.Worker-1-Administrators-MacBook-Pro-3.local.out
 8759* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 8760  ifconfig
 8761  ssh -i ~/Downloads/tcc.pem -ND 8157 hadoop@18.228.30.227\n
 8762* ssh -i ~/tcc.pem -ND 8890 hadoop@18.228.30.227\n
 8763* ssh -i ~/Downloads/tcc.pem -ND 8890 hadoop@18.228.30.227\n
 8764* ps aux | grep spark
 8765* kill -9 56694
 8766* kill -9 56616
 8767* ps aux | grep spark
 8768* ls -l
 8769  make build
 8770  git status
 8771  make deploy-qa
 8772* export HADOOP_CONF_DIR=~/configs/conf-qa
 8773* history | grep movequeue
 8774* history | grep move
 8775* yarn application -movetoqueue application_1565036570928_0003 -queue root.hadoop
 8776* ls -l
 8777* cd ..
 8778* cd azkaban
 8779* ls -l
 8780* cd pipeline-horizon-stream-ingest
 8781* ls -l
 8782* git status
 8783* git diff
 8784* make zip
 8785* yarn aplication -list | grep application_1565036570928_0003
 8786* yarn application -list | grep application_1565036570928_0003
 8787* yarn aplication -kill application_1565036570928_0003
 8788* yarn application -kill grep application_1565036570928_0003
 8789* yarn application -kill application_1565036570928_0003
 8790* yarn application -kill application_1565036570928_0001
 8791* ls -l
 8792* hdfs dfs -ls /
 8793* hdfs dfs -ls /user
 8794* hdfs dfs -ls /user/actions/stream
 8795* hdfs dfs -ls /user/actions/stream/checkpoints
 8796* hdfs dfs -ls /user/actions/stream/checkpointsab
 8797* hdfs dfs -ls /user/actions/stream/checkpoints/ab
 8798* hdfs dfs -rm -rf /user/actions/stream/checkpoints/ab
 8799* hdfs dfs -rm -r /user/actions/stream/checkpoints/ab/ab_hhs-qa.ab_offsets.txt
 8800* export HADOOP_USER_NAME=hdfs
 8801* hdfs dfs -rm -r /user/actions/stream/checkpoints/ab/ab_hhs-qa.ab_offsets.txt
 8802* make zip
 8803* yarn application -list | grep application_1565036570928_0008
 8804* yarn application -kill application_1565036570928_0008
 8805* make zip
 8806* git status
 8807* git diff
 8808* make zip
 8809* yarn application -kill application_1565036570928_0007
 8810  ps aux | grep redis
 8811  kill -9 26113 26112
 8812  ps aux | grep redis
 8813* yarn application -kill application_1565036570928_0011
 8814  git status
 8815  git checkout master
 8816  git pull
 8817  vi Makefile
 8818  make deploy
 8819* ps aux | grep redis
 8820  git status
 8821  git diff
 8822  git log
 8823  ps aux | grep kafka
 8824  make deploy
 8825  git status
 8826  history | grep HADOOP
 8827  unset HADOOP_USER_NAME
 8828  echo $HADOOP_USER_NAME
 8829  cd ..
 8830  ls -l
 8831  rm -rf horizon_event_stream
 8832  git clone gitlab@gitlab.globoi.com:BigDataPipeline/horizon_event_stream.git
 8833  cd horizon_event_stream
 8834  make deploy
 8835  git status
 8836  cd ..
 8837  rm -rf horizon_event_stream
 8838  git clone gitlab@gitlab.globoi.com:BigDataPipeline/horizon_event_stream.git
 8839  make test
 8840  cd horizon_event_stream
 8841  git status
 8842  make test
 8843  git status
 8844  git checkout build.sbt
 8845  git status
 8846  make deploy
 8847  git status
 8848  cd ..
 8849  rm -rf horizon_event_stream
 8850  git clone gitlab@gitlab.globoi.com:BigDataPipeline/horizon_event_stream.git
 8851  cd horizon_event_stream
 8852  git status
 8853  history | grep assembly
 8854  sbt 'set test in assembly := {}' clean assembly
 8855* yarn application -list
 8856* yarn application -kill application_1565036570928_0012
 8857  cd ..
 8858  mkdir candidatos
 8859  cd candidatos
 8860  git clone git@github.com:SelecaoGlobocom/joao_pedro_pinheiro.git
 8861  cd joao_pedro_pinheiro
 8862  make setup
 8863  make run
 8864* curl -d "user=neuwald" http://localhost:5000/www.neuwald.com
 8865* curl -d "user=neuwald" http://localhost:5000/www.neuwald.com/view
 8866* curl -d "user=neuwald" http://localhost:5000/www.neuwald.com/view/
 8867* curl -d "user=neuwald" http://localhost:5000/www.alves.com/view/
 8868* curl http://localhost:5000/www.alves.com/similar
 8869* curl http://localhost:5000/www.alves.com/similar/
 8870* curl -X "DELETE" http://localhost:5000/
 8871* curl -d "user=neuwald" http://localhost:5000/www.alves.com/view/
 8872* curl -d "user=neuwald" http://localhost:5000/www.neuwald.com/view/
 8873* curl -d "user=neuwald" http://localhost:5000/www.neuwald.com/view
 8874* curl -d "user=neuwald" http://localhost:5000/www.neuwald.com/similar/
 8875* curl http://localhost:5000/www.neuwald.com/similar/
 8876* curl http://localhost:5000/www.neuwald.com/similar
 8877* curl http://localhost:5000/www.neuwald.com/similar/
 8878* history | grep hdfs
 8879* hdfs dfs -ls /user/actions/stream/checkpoints/ab/ab_hhs-qa.ab_offsets.txt
 8880* hdfs dfs -rm -r /user/actions/stream/checkpoints/ab/ab_hhs-qa.ab_offsets.txt
 8881* cd ..
 8882* ls -l
 8883* cd candidatos
 8884* ls -l
 8885* cd joao_pedro_pinheiro
 8886* atom .
 8887* cd /Users/leonardo.neuwald/Projetos/horizon_event_stream
 8888* sbt deployProd
 8889* history | grep sbt
 8890* sbt 'set test in assembly := {}' deployProd
 8891* hdfs dfs -ls /user/actions/stream/checkpoints/ab/ab_hhs-qa.ab_offsets.txt
 8892* hdfs dfs -ls /user/actions/stream/checkpoints/ab
 8893* hdfs dfs -ls /user/actions/stream/checkpoints
 8894* history | grep export
 8895* export HADOOP_CONF_DIR=~/configs/conf-qa
 8896* hdfs dfs -ls /user/actions/stream/checkpoints
 8897* hdfs dfs -ls /user/actions/stream/checkpoints/ab
 8898* hdfs dfs -rm -r /user/actions/stream/checkpoints/ab
 8899* yarn application -list | grep application_1565036570928_0016
 8900* yarn application -kill application_1565036570928_0016
 8901* hdfs dfs -rm -r /user/actions/stream/checkpoints/ab
 8902* hdfs dfs -ls /user/actions/stream/checkpoints/ab
 8903* hdfs dfs -ls /user/actions/stream/checkpoints
 8904* yarn application -list 
 8905* yarn application -list
 8906* export HADOOP_CONF_DIR=~/configs/conf-prod
 8907* yarn application -list | grep application_1539207608922_302474
 8908* yarn application -kill application_1539207608922_302474
 8909* yarn application -list | grep application_1539207608922_302489
 8910* yarn application -kill application_1539207608922_302489
 8911* unset HADOOP_CONF_DIR
 8912  make run
 8913* yarn application -list
 8914* curl -d "user=neuwald1" http://localhost:5000/www.globoplay.com/v/0101/view/
 8915* curl -d "user=neuwald2" http://localhost:5000/www.globoplay.com/v/0101/view/
 8916* curl -d "user=neuwald3" http://localhost:5000/www.globoplay.com/v/0101/view/
 8917* hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.1/year=2019/month=8
 8918* export HADOOP_CONF_DIR=~/configs/conf-prod
 8919* hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.1/year=2019/month=8
 8920* hdfs dfs -chown actions:hdfs /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.1/year=2019/month=8/day=8
 8921* export HADOOP_USER_NAME=hadoop
 8922* hdfs dfs -chown actions:hdfs /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.1/year=2019/month=8/day=8
 8923* hdfs dfs -ls /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-impression/actionVersion=2.1/year=2019/month=8
 8924* hdfs dfs -chown actions:hdfs /user/actions/stream/tenant=ab/actionContentType=ab/actionId=ab-conversion/actionVersion=2.1/year=2019/month=8/day=8
 8925* curl -d "user=neuwald4" http://localhost:5000/www.globoplay.com/v/0101/view/
 8926* curl -X "DELETE" http://localhost:5000/
 8927* curl -d "user=neuwald1" http://localhost:5000/www.globoplay.com/v/0101/view/
 8928* curl -d "user=neuwald2" http://localhost:5000/www.globoplay.com/v/0101/view/
 8929* curl -d "user=neuwald2" http://localhost:5000/www.globoplay.com/v/0202/view/
 8930* curl -d "user=neuwald1" http://localhost:5000/www.globoplay.com/v/0202/view/
 8931* curl http://localhost:8080/www.globoplay.com/v/0202/similar/
 8932* curl http://localhost:5000/www.globoplay.com/v/0202/similar/
 8933* curl http://localhost:5000/www.globoplay.com/v/020/similar/
 8934* curl -d "user=diego" http://localhost:5000/www.globoplay.com/v/0303/view/
 8935* curl -d "user=digor" http://localhost:5000/www.globoplay.com/v/0303/view/
 8936* curl http://localhost:5000/www.globoplay.com/v/030/similar/
 8937* curl http://localhost:5000/www.globoplay.com/v/0303/similar/
 8938* cd ..
 8939* pyenv activate gpc-billing
 8940* python
 8941  make test
 8942  make setup
 8943  make test
 8944  git status
 8945  ks 0k
 8946  ls -l
 8947  make test
 8948  make setup
 8949  make test
 8950  docker ps -a
 8951  docker rm joao_pedro_pinheiro_test
 8952  docker rm d7e3e99c1f87
 8953  make test
 8954  docker ps -a
 8955  docker rm b73db29784cb
 8956  docker rm dba2d5320ebe
 8957  docker ps -a
 8958  make setup
 8959  make test
 8960  make run
 8961  make test
 8962  cd ..
 8963  ls -l
 8964  cd azkaban
 8965  ls -l
 8966  cd pipeline-document-ingest
 8967  cd ..
 8968  cd azkaban-gcp-billing
 8969  git pull
 8970  ls -l
 8971  pyenv activate gpc-billing
 8972  python billing-gcs-companies-ga.py 2019 08 08 y
 8973  pyenv deactivate gpc-billing
 8974* ps aux | grep redis
 8975* kill -9 88907
 8976* pyenv deactivate gpc-billing
 8977* ls -l
 8978* cd horizon-user-mapping
 8979* ls -l
 8980* git status
 8981* git diff
 8982* ls -l src/test/resources/
 8983* ls -l src/test/resources/fixtures/
 8984* ls -l src/test/resources/fixtures/list-of-users
 8985* git diff
 8986* hdfs dfs -ls /spark
 8987* sbt clean test
 8988* git status
 8989* git diff .gitlab-ci.yml
 8990* git checkout src/test/scala/com/globo/bigdata/pipeline/mapping/sync/RedisSyncTest.scala
 8991* git checkout CHANGELOG.md
 8992* git status
 8993* git diff
 8994* git diff CHANGELOG.md
 8995* git add CHANGELOG.md
 8996* git status
 8997* git diff
 8998* git checkout src/test/scala/com/globo/bigdata/pipeline/mapping/sync/RedisSyncTest.scala
 8999* git status
 9000* git add .gitlab-ci.yml
 9001* git status
 9002* git reset src/test/scala/com/globo/bigdata/pipeline/mapping/sync/RedisSyncTest.scala
 9003* git status
 9004* git commit -m "docs: add CHANGELOG.md"
 9005* git status
 9006* git diff src/main/scala/com/globo/bigdata/pipeline/mapping/HorizonUserMapping.scala
 9007* git add src/main/scala/com/globo/bigdata/pipeline/mapping/config/Settings.scala
 9008* git add src/test/scala/com/globo/bigdata/pipeline/mapping/config/SettingsTest.scala
 9009* git status
 9010* git commit -m "feat: add measures settings"
 9011* git status
 9012* git add src/test/scala/com/globo/bigdata/pipeline/mapping/sync/
 9013* git status
 9014* git commit -m "test: create unit test for redis sync"
 9015* git status
 9016* git add src/main/scala/com/globo/bigdata/pipeline/mapping/HorizonUserMapping.scala
 9017* git commit -m "feat: add StreamingQueryListener"
 9018* git status
 9019* git push origin feat/create-horizon-user-mapping 
 9020* gcloud
 9021* gcloud config
 9022* gcloud config list
 9023* wget https://raw.githubusercontent.com/GoogleCloudPlatform/dataproc-initialization-actions/master/zeppelin/zeppelin.sh
 9024* gcloud compute ssh ufrgs2-m \\n  --project=hidden-analyzer-249419 \\n  --zone=southamerica-east1-b -- -D 1080 -N
 9025* gcloud auth activate-service-account --key-file=/Users/leonardo.neuwald/Downloads/hidden-analyzer-249419-08231f2fba56.json
 9026* gcloud init --console-only
 9027* gcloud compute ssh ufrgs2-m \\n  --project=hidden-analyzer-249419 \\n  --zone=southamerica-east1-b -- -D 1080 -N
 9028* "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome" \\n  --proxy-server="socks5://localhost:1080" \\n  --user-data-dir="/tmp/ufrgs2-m" http://ufrgs2-m:8088
 9029* git status
 9030* vi .gitlab-ci.yml
 9031* git push origin feat/create-horizon-user-mapping 
 9032* vi .gitlab-ci.yml
 9033* git status
 9034* git add .gitlab-ci.yml
 9035* git commit -m "chore: update gitlab-ci"
 9036* git push origin feat/create-horizon-user-mapping 
 9037* vi Makefile
 9038* vi project/build.properties
 9039* vi project/deploy_hdfs.sh
 9040* git status
 9041* git add Makefile project/build.properties project/deploy_hdfs.sh
 9042* git commit -m "style: add newline at end of files"
 9043* git push origin feat/create-horizon-user-mapping 
 9044* cd ..
 9045* ls -l
 9046* cookiecutter gitlab@gitlab.globoi.com:BigDataPipeline/cookiecutter-pipeline-spark.git
 9047* ls -l
 9048* ls-l 
 9049* ls -l
 9050* ls -l Redis2Parquet
 9051* cd Redis2Parquet
 9052* git status
 9053* cd ..
 9054* mv Redis2Parquet redis2parquet
 9055* ls -l
 9056* cd redis2parquet
 9057* ls -l
 9058* git init\n
 9059* git remote add origin gitlab@gitlab.globoi.com:leonardo.neuwald/redis2parquet.git\n
 9060* git add .
 9061  history | grep host
 9062  vi /etc/hosts
 9063* git commit -m "feat: create project"
 9064* git status
 9065* git push origin master
 9066* git checkout -b feat/create-redis2parquet-project
 9067* git status
 9068* cd ..
 9069* ls -l
 9070* gcloud compute ssh ufrgs2-m \\n  --project=hidden-analyzer-249419 \\n  --zone=southamerica-east1-b -- -D 1080 -N
 9071* cd ..
 9072* ls -l
 9073* cd ..
 9074* ls -l
 9075* cd Projetos
 9076* ls -l
 9077* cd spark-redis-old
 9078* git status
 9079* git diff
 9080* cd ..
 9081* ls -l
 9082* cd spark-redis
 9083* git status
 9084* cd ..
 9085* cd spark-redis-old
 9086* git diff
 9087* cd ..
 9088* ls -l
 9089* cd spark-redis
 9090* git status
 9091* mvn clean compile
 9092* mvn clean test
 9093* ps aux | grep 7379
 9094* "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome" \\n  --proxy-server="socks5://localhost:1080" \\n  --user-data-dir="/tmp/ufrgs2-m" http://ufrgs2-m:8088
 9095* mvn clean test
 9096* htop
 9097* git status
 9098* git fetch && git fetch --tags\n
 9099* git checkout v2.4.0
 9100* git status
 9101* git checkout -b feat/operations-returning-keys
 9102* git status
 9103* mvn clean test
 9104  ls -l
 9105  cd ..
 9106  ls -l
 9107  cd ..
 9108  ls -l
 9109  cd ..
 9110  ls -l
 9111  cd redis-4.0.14
 9112  ls -l
 9113  cd src
 9114  ls -l
 9115  cd ..
 9116  ls -l
 9117  history | grep redis
 9118  ls -l
 9119  cd src
 9120  ./redis-server
 9121* git status
 9122* git diff
 9123* git status
 9124* git checkout v2.3.1
 9125* git status
 9126* cd ..
 9127* git clone git@github.com:RedisLabs/spark-redis.git spark-redis-2.3
 9128* cd spark-redis-2.3
 9129* cd spark-redis
 9130* ls -l
 9131* git status
 9132* git fetch && git fetch --tags\n
 9133* git checkout v2.3.1
 9134* git loh
 9135* git log
 9136* git checkout -b return-keys-on-rdd-operations
 9137* git log
 9138* git diff src/main/scala/com/redislabs/provider/redis/rdd/RedisRDD.scala
 9139* git diff src/main/scala/com/redislabs/provider/redis/redisFunctions.scala
 9140* git diff src/test/scala/com/redislabs/provider/redis/env/RedisStandaloneEnv.scala
 9141* src/test/scala/com/redislabs/provider/redis/rdd/RedisRddSuite.scala
 9142* git diff src/test/scala/com/redislabs/provider/redis/rdd/RedisRddSuite.scala
 9143* git status
 9144* git add src/main/scala/com/redislabs/provider/redis/rdd/RedisRDD.scala src/main/scala/com/redislabs/provider/redis/redisFunctions.scala src/test/scala/com/redislabs/provider/redis/rdd/RedisRddSuite.scala
 9145* git commit -m "create fromRedisZSetWithKeyAndScore operation"
 9146* git push origin feat/operations-returning-keys 
 9147* git status
 9148* git add src/main/scala/com/redislabs/provider/redis/rdd/RedisRDD.scala src/main/scala/com/redislabs/provider/redis/redisFunctions.scala src/test/scala/com/redislabs/provider/redis/rdd/RedisRddSuite.scala
 9149* git commit -m "create fromRedisZSetWithKeyAndScore operation"
 9150* git push origin return-keys-on-rdd-operations 
 9151* git config --get remote.origin.url\n
 9152* git remote show origin
 9153* git remote set-url git@github.com:leoneuwald/spark-redis.git
 9154* git remote set-url origin git@github.com:leoneuwald/spark-redis.git
 9155* git status
 9156* git config --get remote.origin.url\n
 9157* git push origin return-keys-on-rdd-operations 
 9158* history | grep mvn
 9159* mvn clean deploy -DskipTests
 9160* cd ..
 9161* ls -l
 9162* cd spark-redis-old
 9163* git status
 9164* git diff pom.xml
 9165* history | grep mvn
 9166* mvn clean package -DskipTests
 9167* ls -l
 9168* ls -l /Users/leonardo.neuwald/Projetos/spark-redis-2.3/target
 9169* mvn clean package -DskipTests
 9170* cd ..
 9171* ls -l
 9172* cd redis2parquet
 9173* git status
 9174* sbt clean compile
 9175* git status
 9176* git add .
 9177* git commit -m "feat: update dependencies"
 9178* git status
 9179* git push origin feat/create-redis2parquet-project 
 9180* sbt clean test
 9181* git status
 9182* git add .
 9183* git diff
 9184* git commit -m "test: change test description"
 9185* git status
 9186* ssh cmah14lb17.globoi.com
 9187* history | grep curl
 9188* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 12_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 [FBAN/FBIOS;FBAV/202.0.0.55.99;FBBV/135472877;FBDV/iPhone9,3;FBMD/iPhone;FBSN/iOS;FBSV/12.3.1;FBSS/2;FBCR/TIM;FBID/phone;FBLC/en_US;FBOP/5;FBRV/137762727]'
 9189* telnet pipeline-user-agent-discovery-service.globoi.com 80
 9190* gcloud compute ssh ufrgs2-m \\n  --project=hidden-analyzer-249419 \\n  --zone=southamerica-east1-b -- -D 1080 -N
 9191* "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome" \\n  --proxy-server="socks5://localhost:1080" \\n  --user-data-dir="/tmp/ufrgs2-m" http://ufrgs2-m:8088
 9192* ssh cmaq15lb28.globoi.com
 9193* ssh cmah14lb17.globoi.com
 9194* sbt clean compile
 9195* cd ..
 9196* ls -l
 9197* cd .
 9198* cd ..
 9199* ls -l
 9200* cd horizon-user-mapping
 9201* sbt clean test
 9202* git statu
 9203* git status
 9204* sbt clean compile
 9205* sbt clean publishLocal
 9206* git status
 9207* git diff
 9208* git diff build.sbt
 9209* history | grep add
 9210* git add -p
 9211* git status
 9212* git commit -m "fix: typo on build.sbt"
 9213* git status
 9214* git add -p
 9215* git status
 9216* git commit -m "chore: remove useless code"
 9217* git status
 9218* git diff
 9219* git add src/test/scala/com/globo/bigdata/pipeline/mapping/sync/RedisSyncTest.scala
 9220* git commit -m "test: create unit test for RedisSync"
 9221* git status
 9222* git diff
 9223* git add src/main/scala/com/globo/bigdata/pipeline/mapping/extractor/UserExtractorByCookie.scala src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisClusterUserStorage.scala src/main/scala/com/globo/bigdata/pipeline/mapping/storage/RedisUserStorage.scala
 9224* git status
 9225* git commit -m "refactor: make code more readable"
 9226* git status
 9227* git push origin feat/create-horizon-user-mapping 
 9228* git add src/test/resources/
 9229* git status
 9230* git commit -m "test: created file with a list of users"
 9231* git push origin feat/create-horizon-user-mapping 
 9232* git status
 9233* sbt clean publishLocal
 9234* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 12_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 [FBAN/FBIOS;FBDV/iPhone10,4;FBMD/iPhone;FBSN/iOS;FBSV/12.4;FBSS/2;FBID/phone;FBLC/en_US;FBOP/5;FBCR/Vodafone.de]'
 9235* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 12_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 [FBAN/FBIOS;FBAV/202.0.0.55.99;FBBV/135472877;FBDV/iPhone9,3;FBMD/iPhone;FBSN/iOS;FBSV/12.3.1;FBSS/2;FBCR/TIM;FBID/phone;FBLC/en_US;FBOP/5;FBRV/137762727]'
 9236* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 12_4 like Mac OS X) AppleWebKit/604.1.34 (KHTML, like Gecko) CriOS/65.0.3325.112 Mobile/16G77 Safari/604.1\n'
 9237* make zip
 9238* git status
 9239* git diff
 9240* git add src/main/scala/com/globo/bigdata/pipeline/mapping/HorizonUserMapping.scala
 9241* git add src/main/scala/com/globo/bigdata/pipeline/mapping/listener/
 9242* git commit -m "refactor: separate OffsetsListener of HorizonUserMapping"
 9243* git push origin feat/create-horizon-user-mapping 
 9244* hdfs dfs -ls /
 9245* hdfs dfs -ls /warehouse
 9246* export HADOOP_CONF_DIR=~/configs/conf-prod
 9247* hdfs dfs -ls /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-load/actionVersion=3.0/year=2019/month=8
 9248* hdfs dfs -du -h /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-load/actionVersion=3.0/year=2019/month=8
 9249* hdfs dfs -du -h /user/actions/stream/tenant=g1/actionContentType=multicontent/actionId=multicontent-chunk-view/actionVersion=3.0/year=2019/month=8
 9250* unset HADOOP_CONF_DIR
 9251* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 12_3_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 [FBAN/FBIOS;FBAV/202.0.0.55.99;FBBV/135472877;FBDV/iPhone9,3;FBMD/iPhone;FBSN/iOS;FBSV/12.3.1;FBSS/2;FBCR/TIM;FBID/phone;FBLC/en_US;FBOP/5;FBRV/137762727]'
 9252* cd ..
 9253* ls -l
 9254* cd ..
 9255* ls -l
 9256* cd spark-2.3.1-bin-hadoop2.7
 9257* history | grep spark
 9258* history | grep spark-shell
 9259* ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT-jar-with-dependencies.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT.jar,/Users/leonardo.neuwald/Downloads/jedis-3.0.0-m1.jar  --conf "spark.redis.port=6379" --conf "spark.redis.auth=uEdjy6sRVW" --conf "spark.redis.host=horizonuse-01-156380504344.redis.globoi.com" --conf "spark.redis.timeout=10000"
 9260* ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/spark-redis/target/spark-redis-gb-2.4.0-SNAPSHOT-jar-with-dependencies.jar,/Users/leonardo.neuwald/Downloads/jedis-2.9.0.jar,/Users/leonardo.neuwald/Downloads/spark-redis-gb-2.3.1-20190813.182505-1.jar,/Users/leonardo.neuwald/Downloads/jedis-3.0.0-m1.jar  --conf "spark.redis.port=6379" --conf "spark.redis.auth=uEdjy6sRVW" --conf "spark.redis.host=horizonuse-01-156380504344.redis.globoi.com" --conf "spark.redis.timeout=10000"
 9261* sbt clean assembly
 9262* ls -l
 9263* cd ..
 9264* ls -l
 9265* cd ..
 9266* ls -l
 9267* cd Projetos
 9268* ls -l
 9269* cd spark-redis
 9270* ls -l
 9271* git status
 9272* cd ..
 9273* mv spark-redis spark-redis-old
 9274* git clone git@github.com:leoneuwald/spark-redis.git
 9275* cd spark-redis
 9276* cd ..
 9277* ls -l
 9278* cd azkaban
 9279* git status
 9280* ls -l
 9281* git clone gitlab@gitlab.globoi.com:bigdata/pipeline/azkaban/pipeline-user-agent-mapper.git
 9282* cd pipeline-user-agent-mapper
 9283* git status
 9284* git pull
 9285* atom .
 9286* make zip
 9287* git status
 9288* git checkout -b feat/change-action-read
 9289* make zip
 9290* history | grep curl
 9291* git status
 9292* git diff
 9293* atom .
 9294* cd ..
 9295* atom .
 9296* cd pipeline-user-agent-mapper
 9297* git dif
 9298* git diff
 9299* git status
 9300* git add jobs/default.properties
 9301* git commit -m "feat: increase resources"
 9302* git status
 9303* git add CHANGELOG.md
 9304* git commit -m "docs: update changelog"
 9305* git add .
 9306* git commit -m "feat: create arguments action.content.type, action-id and action-version"
 9307* git push origin feat/change-action-read 
 9308* history | grep docker
 9309* docker run -it --rm  -p 8085:8080 skymindops/zeppelin-dl4j:latest
 9310* sbt clean assembly
 9311* ./bin/spark-shell --jars /Users/leonardo.neuwald/Projetos/redis2parquet/target/scala-2.11/redis2parquet.jar  --conf "spark.redis.port=6379" --conf "spark.redis.auth=uEdjy6sRVW" --conf "spark.redis.host=horizonuse-01-156380504344.redis.globoi.com" --conf "spark.redis.timeout=10000"
 9312* yarn application -list
 9313* yarn application -list | grep gshow
 9314* yarn application -kill application_1539207608922_302475
 9315* \n
 9316* git status
 9317* git reset src/main/scala/com/globo/bigdata/pipeline/redis2parquet/model/RedisZSet.scala
 9318* git status
 9319* git reset src/main/scala/com/globo/bigdata/pipeline/redis2parquet/source/Reader.scala
 9320* git status
 9321* history | grep curl
 9322* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'Mozilla/5.0 (Linux; U; Android 4.2.2; pt-br; GT-S7273T Build/JDQ39) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30 [FBIA/FB4A;FBAV/234.0.0.30.115;]'
 9323* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'Mozilla/5.0 (Linux; Android 7.1.2; GT-I9300 Build/NJH47F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.97 Mobile Safari/537.36'
 9324* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'Mozilla/5.0 (Linux; Android 7.1.1; Nokia 2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.111 Mobile Safari/537.36'
 9325* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'User-Agent: Mozilla/5.0 (Linux; Android 7.1.1; Nokia 2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.111 Mobile Safari/537.36'
 9326* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'User-Agent: Mozilla/5.0 (Linux; U; Android 4.2.2; pt-br; GT-S7273T Build/JDQ39) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30 [FBIA/FB4A;FBAV/234.0.0.30.115;]'
 9327* git status
 9328* git add  src/test/scala/com/globo/bigdata/pipeline/redis2parquet/config/SettingsTest.scala
 9329* git add src/main/scala/com/globo/bigdata/pipeline/redis2parquet/config/Settings.scala
 9330* git status
 9331* git commit -m "feat: add new options to settings"
 9332* git push origin feat/create-redis2parquet-project 
 9333* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'User-Agent: Mozilla/5.0 (Linux; U; Android 4.2.2; pt-br; GT-S7273T Build/JDQ39) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30 [FBIA/FB4A;FBAV/234.0.0.30.115;]'
 9334* gcloud compute ssh ufrgs2-m \\n  --project=hidden-analyzer-249419 \\n  --zone=southamerica-east1-b -- -D 1080 -N
 9335* /usr/bin/google-chrome \\n  --proxy-server="socks5://localhost:1080" \\n  --user-data-dir="/tmp/ufrgs2-m" http://ufrgs2-m:8088
 9336* "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome" \\n  --proxy-server="socks5://localhost:1080" \\n  --user-data-dir="/tmp/ufrgs2-m" http://ufrgs2-m:8088
 9337* gcloud config set project hidden-analyzer-249419
 9338* gcloud dataproc clusters create tcc --initialization-actions gs://ufrgsneuwald/zeppelin/zeppelin.sh \\n--zone southamerica-east1-b --master-machine-type n1-standard-2 \\n--master-boot-disk-size 25 --num-workers 3 \\n--worker-machine-type n1-standard-2 \\n--worker-boot-disk-size 25 --image-version 1.1
 9339* gcloud compute ssh tcc-m \\n  --project=hidden-analyzer-249419 \\n  --zone=southamerica-east1-b -- -D 1080 -N
 9340* "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome" \\n  --proxy-server="socks5://localhost:1080" \\n  --user-data-dir="/tmp/tcc-m" http://tcc-m:8088
 9341* vi /etc/hosts
 9342* htop
 9343* yarn application -list
 9344* yarn application -list | grep PipelineUserAgentMapper
 9345* yarn application -kill application_1539207608922_323233
 9346* yarn application -list | grep PipelineUserAgentMapper
 9347* yarn application -kill application_1539207608922_323252
 9348* curl -v http://pipeline-user-agent-discovery-service.globoi.com/detailed_detection.xpto -H 'X-Forwarded-For: 100.17.12.198' -H 'User-Agent: Mozilla/5.0 (Linux; U; Android 4.2.2; pt-br; GT-S7273T Build/JDQ39) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30 [FBIA/FB4A;FBAV/234.0.0.30.115;]'
 9349* history | grep brew
 9350  \n
 9351  echo $SHELL
 9352  ls ~/
 9353  ls -a ~/
 9354  history | grep horizon-track
 9355  java -version
 9356* cd ..
 9357* ls -l
 9358* cd candidatos
 9359* ls -l
 9360* cd joao_pedro_pinheiro
 9361* atom .
 9362* cd ..
 9363* ls -l
 9364* cd ..
 9365* ls -l
 9366* cd redis2parquet
 9367* git status
 9368* git add .
 9369* git commit -m "feat: creating unit tests"
 9370* git status
 9371* git push origin feat/create-redis2parquet-project 
 9372* git status
 9373* git add .
 9374* git commit -m "refactor: remove unseless method"
 9375* git push origin feat/create-redis2parquet-project 
 9376  ls -l
 9377* git status
 9378* ls -l
 9379* cd tasks
 9380* ls -l
 9381* cd spark-submit
 9382* ls -l
 9383* ./run_qa.sh
 9384* export SPARK_HOME="/Users/leonardo.neuwald/spark-2.3.1-bin-hadoop2.7"
 9385* ./run_qa.sh
 9386* ls -l ~/configs/conf-qa
 9387* export HADOOP_CONF_DIR="~/configs/conf-qa"
 9388* export HADOOP_CONF_DIR=~/configs/conf-qa
 9389* unset HADOOP_CONF_DIR
 9390* ./run_qa.sh
 9391* sbt clean assembly
 9392* sbt clean publishLocal
 9393* cd ..
 9394* ls -l
 9395* sbt clean publishLocal
 9396* ./tasks/spark-submit/run_qa.sh
 9397* /tasks/spark-submit/run_qa.sh
 9398* ./tasks/spark-submit/run_qa.sh
 9399* ls -l /Users/leonardo.neuwald/Projetos/redis2parquet/target/scala-2.11/redis2parquet.jar
 9400* sbt clean assembly
 9401* history | grep assembly
 9402* sbt 'set test in assembly := {}' clean assembly
 9403* ./tasks/spark-submit/run_qa.sh
 9404* yarn application -list | grep application_1565036570928_0026
 9405* export HADOOP_CONF_DIR=~/configs/conf-qa
 9406* yarn application -list | grep application_1565036570928_0026
 9407* yarn application -kill application_1565036570928_0026
 9408* ./tasks/spark-submit/run_qa.sh
 9409* yarn application -list | application_1565036570928_0020
 9410* yarn application -list | grep application_1565036570928_0020
 9411* export HADOOP_CONF_DIR=~/configs/conf-qa
 9412* yarn application -list | grep application_1565036570928_0020
 9413* yarn application -kill application_1565036570928_0020
 9414* ./tasks/spark-submit/run_qa.sh
 9415* ./tasks/spark-submit/run_prod.sh
 9416* git status
 9417* git diff src/main/scala/com/globo/bigdata/pipeline/redis2parquet/Redis2Parquet.scala
 9418* git add src/main/scala/com/globo/bigdata/pipeline/redis2parquet/Redis2Parquet.scala
 9419* git commit -m "style: remove blank line"
 9420* git status
 9421* git add tasks/
 9422* git status
 9423* git commit -m "feat: add spark-submit scripts"
 9424* git push origin feat/create-redis2parquet-project 
 9425* sbt clean test
 9426  ls -l
 9427  cd ..
 9428  ls -l
 9429  cd ..
 9430  ls -l
 9431  cd Projetos/azkaban/
 9432  LS -L
 9433  ls -l
 9434  cp -r pipeline-user-agent-mapper pipeline-user-mapping
 9435  ls -l
 9436  cd pipeline-user-mapping
 9437  git status
 9438  ls -l
 9439  rm -rf .git
 9440  rm -rf dist
 9441  ls -l
 9442  atom .
 9443  cd ..
 9444  ls -l
 9445  cd pipeline-horizon-stream-ingest
 9446  ls -l
 9447  cd jobs
 9448  ls -l
 9449  cd ..
 9450  ls -l
 9451  cd ..
 9452  ls -l
 9453  cd pipeline-horizon-stream-ingest
 9454  ls -l
 9455  git checkout master
 9456  git pull
 9457  atom .
 9458  cd ..
 9459  ls -l
 9460  cd pipeline-document-ingest
 9461  git checkout master
 9462  atom .
 9463* make test
 9464* ps aux | grep redis
 9465* kill -9 42105
 9466* ps aux | grep redis
 9467* make test
 9468* ps aux | grep redis
 9469* kill -9 76559
 9470* make test
 9471  vi ~/.zshenv
 9472  vi ~/.zshrc
 9473  vi ~/.zshenv
 9474  vi ~/.bash_profile
 9475  vi ~/.zshenv
 9476  vi ~/.zshrc
 9477  ls -l ~/Downloads
 9478  ls -l
 9479  cd ~/Downloads
 9480  ls -l
 9481  ls -l | 10
 9482  \n
 9483  ls -l | grep 10
 9484  history | grep gcloud
 9485* export HADOOP_CONF_DIR=~/configs/conf-prod
 9486* yarn application -list | grep application_1539207608922_316977
 9487* yarn application -kill grep application_1539207608922_316977
 9488* yarn application -kill application_1539207608922_316977
 9489* ls -l
 9490  ls -l | grep json
 9491  vi /etc/hosts
 9492  ls -l
 9493  cd ..
 9494  ls -l
 9495  cd Projetos
 9496  ls -l
 9497  cd azkaban
 9498  git status
 9499  ls -l
 9500* cd ..
 9501* ls -l
 9502* yarn applicaton -list | grep rede
 9503* yarn application -list | grep red
 9504* history | grep export
 9505* make test
 9506* ps aux | grep redis
 9507* kill -9 95630
 9508* ps aux | grep redis
 9509* make test
 9510* ps aux | grep redis
 9511* make test
 9512* ps aux | grep redis
 9513* make test
 9514* ps aux | grep redis
 9515* git status
 9516* git diff
 9517* git satus
 9518* git status
 9519* make test
 9520  ls -l
 9521  cd ..
 9522  ls -l
 9523  cd ..
 9524  ls -l
 9525* ps aux | grep redis
 9526* git status
 9527* git diff
 9528* git add .
 9529* git commit -m "fix: add shutdown hook to close redis server after all tests"
 9530* git push origin feat/create-redis2parquet-project 
 9531* git remote set-url origin gitlab@gitlab.globoi.com:bigdata/pipeline/redis2parquet.git
 9532* history | grep feat
 9533* ls -l
 9534* cd ~/.sbt
 9535* ls -l
 9536* cd 0.13
 9537* ls -l
 9538* cd plugins
 9539* ls -l
 9540* cd ..
 9541* ls -l
 9542* vi repositories_2
 9543* cd boot
 9544* ls -l
 9545* cd ..
 9546* ls -l
 9547* cd preloaded
 9548* ls l-
 9549* ls -l
 9550* history | grep HADOOP
 9551* history | grep PATH
 9552* vi ~/.bash_profile
 9553* history | grep HADOOP
 9554* history | grep curl
 9555* ls -l ~/.sbt
 9556* ls -al ~/.sbt
 9557* ls -la ~/.sbt
 9558* vi ~/.sbt/.credentials
 9559  ps aux | grep robot
 9560  ps aux | grep robo
 9561  history | grep GO
 9562  history | grep go
 9563  history | grep brew
 9564  history | grep go
 9565  go -version
 9566  go version
 9567  vi ~/.bash_profile
